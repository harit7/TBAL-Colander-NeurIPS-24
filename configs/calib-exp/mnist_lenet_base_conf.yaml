
random_seed : 0
device: "cuda:0"

data_conf: 
  name: "mnist"
  dimension: 784
  random_state: 0
  data_path: "../data/"
  val_fraction: 0.2
  num_hyp_val_samples: 500
  flatten: False
  num_classes: 10 

model_conf:
  name: "lenet"
  #input_dimension: 784
  #model_name: 'lenet'
  num_classes: 10
  fit_intercept: True
  lib: "pytorch"


training_conf: 
  loss_function: "std_cross_entropy"
  optimizer: "sgd"
  learning_rate: 0.05
  loss_tolerance: 1e-6
  max_epochs: 50
  batch_size: 32
  train_err_tol: -1 
  weight_decay: 0
  use_lr_schedule: True 
  momentum: 0.9
  log_batch_loss_freq:  -1
  
  #stopping_criterion: "val_err_threshold"
  #val_err_threshold: 0.05

  ckpt_load_path: None  
  ckpt_save_path: None
  train_from_scratch: True
  train_from_ckpt: False

inference_conf:
  device: "cuda:0"
  shuffle: False
  batch_size: 512


train_pts_query_conf:
  seed_train_size: 10
  query_strategy_name: "margin_random_v2" 
  margin_random_v2_constant: 2
  query_batch_size: 10
  max_num_train_pts: 50

val_pts_query_conf:
  query_strategy_name: "random"
  max_num_val_pts : 5000

calib_conf: null  

auto_lbl_conf:
  method_name: "selective"  # options "all" | "selective"
  #score_type: "abs_logit"  # options "confidence" | "margin"
  score_type: "confidence"
  class_wise: "independent" # options "joint" | "independent" #makes sense only when using selective 
  auto_label_err_threshold: 0.05 # only for method_name: "selective"
  C_1: 0.25
  ucb: 'sigma'


stopping_criterion: "max_num_train_pts"
store_model_weights_in_mem: False 

run_dir: "../../temp/" 
out_file_path: "../../temp/out.log"

