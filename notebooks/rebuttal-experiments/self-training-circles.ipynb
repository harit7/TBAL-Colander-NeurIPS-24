{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from src.core.passive_learning import *\n",
    "from src.core.auto_labeling import *\n",
    "from src.utils.logging_utils import * \n",
    "from src.data_layer.datasets.dataset_factory import * \n",
    "from src.data_layer.dataset_utils import * \n",
    "from src.utils.counting_utils import *  #\n",
    "from src.utils.common_utils import * \n",
    "from src.utils.vis_utils import *\n",
    "#from src.core.run_lib import * \n",
    "from src.core.self_training import * \n",
    "import copy \n",
    "import random \n",
    "\n",
    "config_file = '../../configs/self-training/circles_base_conf.yaml'\n",
    "conf = OmegaConf.load(config_file)\n",
    "\n",
    "logger = get_logger('../../temp/logs/self-training-circles.log','PL',level=logging.DEBUG)\n",
    "#logger = get_logger('../../temp/logs/pl.log','PL')\n",
    "\n",
    "conf['eval'] = 'full'\n",
    "conf['calib_conf'] = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_conf = conf[\"train_pts_query_conf\"] \n",
    "q_conf['seed_train_size'] = 50\n",
    "q_conf['max_num_train_pts'] = 1000\n",
    "q_conf['include_auto_labeled'] = False \n",
    "q_conf['enable_active_querying'] = True \n",
    "\n",
    "q_conf['query_batch_size'] = 8\n",
    "#conf['stopping_criterion'] = \"max_epochs\"\n",
    "\n",
    "conf['training_conf']['log_batch_loss_freq'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_lbl_conf = conf[\"auto_lbl_conf\"] \n",
    "\n",
    "auto_lbl_conf['threshold_estimation'] = 'val_estimate'\n",
    "\n",
    "#auto_lbl_conf['threshold_estimation'] = 'fixed'\n",
    "#auto_lbl_conf['fixed_threshold'] = 0.6\n",
    "\n",
    "\n",
    "pseudo_lbl_conf = conf[\"pseudo_lbl_conf\"] \n",
    "\n",
    "pseudo_lbl_conf['threshold_estimation'] = 'val_estimate'\n",
    "#pseudo_lbl_conf['threshold_estimation'] = 'fixed'\n",
    "#pseudo_lbl_conf['fixed_threshold'] = 0.95\n",
    "\n",
    "#auto_lbl_conf['threshold_estimation'] = 'fixed'\n",
    "#auto_lbl_conf['fixed_threshold'] = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/02/2024 09:06:51 PM : DEBUG : data_manag : ] : (8000, 2)\n",
      "[04/02/2024 09:06:51 PM : INFO  : data_manag : ] : Loaded dataset synth_concenteric_circles\n",
      "[04/02/2024 09:06:51 PM : INFO  : data_manag : ] : Std train size: 8000 and Std. Val. Size:2000\n",
      "[04/02/2024 09:06:51 PM : INFO  : 187494373 : ] : Loaded dataset synth_concenteric_circles\n",
      "[04/02/2024 09:06:51 PM : INFO  : 187494373 : ] :  std_train_size : 8000 and  std_val_size: 2000\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : xxxxxxxxxxxxxxxxxxxxx  Running TBAL with evaluation (auto-labeling) on the full unlabeled data   xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 8000\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : cur_query_count= 0 and max_query_count=1000\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 0 ============================\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : Number of unalabeled points  :8000\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : Querying first batches of training and validation samples.\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : Querying 50 seed training points\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : Queried 50 seed points for training\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : Validation Data Size :2000\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:06:51 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7950\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : Training data size : 50\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1}\n",
      "[04/02/2024 09:06:51 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:06:51 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 50}\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:51 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.4000 , Training Loss : 0.0141\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.4200 , Training Loss : 0.0140\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.4200 , Training Loss : 0.0140\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.4200 , Training Loss : 0.0140\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.4200 , Training Loss : 0.0140\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.4200 , Training Loss : 0.0140\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.4200 , Training Loss : 0.0140\n",
      "[04/02/2024 09:06:52 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.4200 , Training Loss : 0.0140\n",
      "[04/02/2024 09:06:53 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.4200 , Training Loss : 0.0140\n",
      "[04/02/2024 09:06:53 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.4200 , Training Loss : 0.0139\n",
      "[04/02/2024 09:06:53 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.4200 , Training Loss : 0.0139\n",
      "[04/02/2024 09:06:53 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.4200 , Training Loss : 0.0139\n",
      "[04/02/2024 09:06:53 PM : DEBUG : model_trai : ] : Average training loss : 0.013362750269117806\n",
      "[04/02/2024 09:06:53 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:06:53 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:06:53 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4895\n",
      "[04/02/2024 09:06:53 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4895\n",
      "[04/02/2024 09:06:53 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:06:53 PM : INFO  : self_train : ] : Training error of trained model : 42.00\n",
      "[04/02/2024 09:06:53 PM : INFO  : self_train : ] : Test error of the model         : 48.75\n",
      "[04/02/2024 09:06:53 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:06:53 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:06:53 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:06:53 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:06:53 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:06:53 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:06:53 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:06:53 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:06:53 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7950\n",
      "[04/02/2024 09:06:53 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:06:53 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:06:53 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.10385869085788726\n",
      "[04/02/2024 09:06:53 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:06:53 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:06:53 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:06:53 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.614538311958313 for class 0   \n",
      "[04/02/2024 09:06:53 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:06:53 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:06:53 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.6145383, inf]\n",
      "[04/02/2024 09:06:54 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1200 \n",
      "[04/02/2024 09:06:54 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:06:54 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : =============================== END Epoch 0 =======================\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.995, 'coverage_1': 0.15, 'coverage_2': 0}\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7950\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : cur_query_count= 50 and max_query_count=1000\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 1 ============================\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : Number of unalabeled points  :7950\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : Current Available Query Budget: 950\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:06:54 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:06:54 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7942\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : Training data size : 1258\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 50}\n",
      "[04/02/2024 09:06:54 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:06:54 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:06:54 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1258}\n",
      "[04/02/2024 09:06:54 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:06:54 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:06:54 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3124 , Training Loss : 0.0088\n",
      "[04/02/2024 09:06:54 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0270 , Training Loss : 0.0031\n",
      "[04/02/2024 09:06:54 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0262 , Training Loss : 0.0019\n",
      "[04/02/2024 09:06:54 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0262 , Training Loss : 0.0017\n",
      "[04/02/2024 09:06:54 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0254 , Training Loss : 0.0016\n",
      "[04/02/2024 09:06:55 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0254 , Training Loss : 0.0015\n",
      "[04/02/2024 09:06:55 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0262 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:55 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0262 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:55 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0262 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:55 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0262 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:55 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0262 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:55 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0262 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:56 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0254 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:56 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0246 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:56 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0246 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:56 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0238 , Training Loss : 0.0013\n",
      "[04/02/2024 09:06:56 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0238 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:56 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0238 , Training Loss : 0.0013\n",
      "[04/02/2024 09:06:56 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0238 , Training Loss : 0.0013\n",
      "[04/02/2024 09:06:57 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0231 , Training Loss : 0.0013\n",
      "[04/02/2024 09:06:57 PM : DEBUG : model_trai : ] : Average training loss : 0.0018035909582601514\n",
      "[04/02/2024 09:06:57 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:06:57 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:06:57 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4895\n",
      "[04/02/2024 09:06:57 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4895\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : Training error of trained model : 2.38\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : Test error of the model         : 48.70\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:06:57 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7942\n",
      "[04/02/2024 09:06:57 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:06:57 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.35622440999746324\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:06:57 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:06:57 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.939365804195404 for class 0   \n",
      "[04/02/2024 09:06:57 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:06:57 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.9393658, inf]\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1202 \n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:06:57 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:06:57 PM : DEBUG : self_train : ] : =============================== END Epoch 1 =======================\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950083194675541, 'coverage_1': 0.15025, 'coverage_2': 0}\n",
      "[04/02/2024 09:06:57 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7942\n",
      "[04/02/2024 09:06:57 PM : DEBUG : self_train : ] : cur_query_count= 58 and max_query_count=1000\n",
      "[04/02/2024 09:06:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:06:57 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 2 ============================\n",
      "[04/02/2024 09:06:57 PM : DEBUG : self_train : ] : Number of unalabeled points  :7942\n",
      "[04/02/2024 09:06:57 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:06:57 PM : DEBUG : self_train : ] : Current Available Query Budget: 942\n",
      "[04/02/2024 09:06:57 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:06:57 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:06:58 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:06:58 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:06:58 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7934\n",
      "[04/02/2024 09:06:58 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:06:58 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:06:58 PM : INFO  : self_train : ] : Training data size : 1268\n",
      "[04/02/2024 09:06:58 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:06:58 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1258}\n",
      "[04/02/2024 09:06:58 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:06:58 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1268}\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.0276 , Training Loss : 0.0036\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0268 , Training Loss : 0.0024\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0276 , Training Loss : 0.0019\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0276 , Training Loss : 0.0017\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0276 , Training Loss : 0.0016\n",
      "[04/02/2024 09:06:58 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0276 , Training Loss : 0.0015\n",
      "[04/02/2024 09:06:59 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0268 , Training Loss : 0.0015\n",
      "[04/02/2024 09:06:59 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0260 , Training Loss : 0.0015\n",
      "[04/02/2024 09:06:59 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0268 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:59 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0284 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:59 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0276 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:59 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0268 , Training Loss : 0.0014\n",
      "[04/02/2024 09:06:59 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0268 , Training Loss : 0.0014\n",
      "[04/02/2024 09:07:00 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0268 , Training Loss : 0.0014\n",
      "[04/02/2024 09:07:00 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0276 , Training Loss : 0.0014\n",
      "[04/02/2024 09:07:00 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0276 , Training Loss : 0.0014\n",
      "[04/02/2024 09:07:00 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0284 , Training Loss : 0.0014\n",
      "[04/02/2024 09:07:00 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0284 , Training Loss : 0.0014\n",
      "[04/02/2024 09:07:00 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0284 , Training Loss : 0.0014\n",
      "[04/02/2024 09:07:01 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0284 , Training Loss : 0.0014\n",
      "[04/02/2024 09:07:01 PM : DEBUG : model_trai : ] : Average training loss : 0.0015613913849590463\n",
      "[04/02/2024 09:07:01 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:01 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:01 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4895\n",
      "[04/02/2024 09:07:01 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4895\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : Training error of trained model : 2.60\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : Test error of the model         : 48.70\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:01 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7934\n",
      "[04/02/2024 09:07:01 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:01 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.34339106863737107\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:01 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:01 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.925203800201416 for class 0   \n",
      "[04/02/2024 09:07:01 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:01 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.9252038, inf]\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1202 \n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:07:01 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : =============================== END Epoch 2 =======================\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950083194675541, 'coverage_1': 0.15025, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7934\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : cur_query_count= 66 and max_query_count=1000\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 3 ============================\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : Number of unalabeled points  :7934\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : Current Available Query Budget: 934\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:01 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:01 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7926\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : Training data size : 1276\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1268}\n",
      "[04/02/2024 09:07:01 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:01 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:01 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1276}\n",
      "[04/02/2024 09:07:01 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:01 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:01 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.0541 , Training Loss : 0.0054\n",
      "[04/02/2024 09:07:02 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0306 , Training Loss : 0.0028\n",
      "[04/02/2024 09:07:02 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0306 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:02 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0298 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:02 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0290 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:02 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0290 , Training Loss : 0.0016\n",
      "[04/02/2024 09:07:02 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0298 , Training Loss : 0.0016\n",
      "[04/02/2024 09:07:02 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0298 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:03 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0298 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:03 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0298 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:03 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0298 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:03 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0298 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:03 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0298 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:03 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0298 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0306 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0313 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0313 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0321 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0321 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0321 , Training Loss : 0.0015\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Average training loss : 0.0017139255069196224\n",
      "[04/02/2024 09:07:04 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:04 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.489\n",
      "[04/02/2024 09:07:04 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.489\n",
      "[04/02/2024 09:07:04 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : Training error of trained model : 3.06\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : Test error of the model         : 49.20\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:05 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7926\n",
      "[04/02/2024 09:07:05 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:05 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2785517112314701\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:05 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8398119807243347 for class 0   \n",
      "[04/02/2024 09:07:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:05 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.839812, inf]\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1221 \n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:07:05 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : =============================== END Epoch 3 =======================\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9860769860769861, 'coverage_1': 0.152625, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7926\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : cur_query_count= 74 and max_query_count=1000\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 4 ============================\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : Number of unalabeled points  :7926\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : Current Available Query Budget: 926\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:05 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:05 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7918\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : Training data size : 1303\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1276}\n",
      "[04/02/2024 09:07:05 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:05 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:05 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1303}\n",
      "[04/02/2024 09:07:05 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:05 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:05 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.0921 , Training Loss : 0.0064\n",
      "[04/02/2024 09:07:05 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0445 , Training Loss : 0.0031\n",
      "[04/02/2024 09:07:06 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0414 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:06 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0422 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:06 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0430 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:06 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0430 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:06 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0430 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:06 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0430 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:06 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0430 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:07 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0430 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:07 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0430 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:07 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0437 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:07 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0437 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:07 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0437 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:07 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0437 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:08 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0437 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:08 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0437 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:08 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0430 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:08 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0430 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:08 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0437 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:08 PM : DEBUG : model_trai : ] : Average training loss : 0.0021693801124586776\n",
      "[04/02/2024 09:07:08 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:08 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:08 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.487\n",
      "[04/02/2024 09:07:08 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.487\n",
      "[04/02/2024 09:07:08 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:08 PM : INFO  : self_train : ] : Training error of trained model : 4.30\n",
      "[04/02/2024 09:07:08 PM : INFO  : self_train : ] : Test error of the model         : 49.00\n",
      "[04/02/2024 09:07:08 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:08 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:08 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:08 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:08 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:08 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:08 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:08 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:08 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7918\n",
      "[04/02/2024 09:07:09 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:09 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:09 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.33212215328216554\n",
      "[04/02/2024 09:07:09 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:09 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:09 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:09 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9070208072662354 for class 0   \n",
      "[04/02/2024 09:07:09 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:09 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.156\n",
      "[04/02/2024 09:07:09 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.9070208, inf]\n",
      "[04/02/2024 09:07:09 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1211 \n",
      "[04/02/2024 09:07:09 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 312\n",
      "[04/02/2024 09:07:09 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : =============================== END Epoch 4 =======================\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9892650701899257, 'coverage_1': 0.151375, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7918\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : cur_query_count= 82 and max_query_count=1000\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 5 ============================\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : Number of unalabeled points  :7918\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : Current Available Query Budget: 918\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:09 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:09 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7910\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : Training data size : 1301\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1303}\n",
      "[04/02/2024 09:07:09 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:09 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:09 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1301}\n",
      "[04/02/2024 09:07:09 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:09 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:09 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.0423 , Training Loss : 0.0064\n",
      "[04/02/2024 09:07:09 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0415 , Training Loss : 0.0031\n",
      "[04/02/2024 09:07:09 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0392 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:10 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0392 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:10 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0392 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:10 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0400 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:10 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0407 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:10 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0407 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:10 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0407 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:11 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0407 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:11 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0415 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:11 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0407 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:11 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0407 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:11 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0407 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:11 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0407 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:12 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0407 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:12 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0415 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:12 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0407 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:12 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0415 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:12 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0415 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:12 PM : DEBUG : model_trai : ] : Average training loss : 0.0021297611365171344\n",
      "[04/02/2024 09:07:12 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:12 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:12 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4875\n",
      "[04/02/2024 09:07:12 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4875\n",
      "[04/02/2024 09:07:12 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:12 PM : INFO  : self_train : ] : Training error of trained model : 4.07\n",
      "[04/02/2024 09:07:12 PM : INFO  : self_train : ] : Test error of the model         : 48.65\n",
      "[04/02/2024 09:07:12 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:12 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:12 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:12 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:12 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:13 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7910\n",
      "[04/02/2024 09:07:13 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:13 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.206416433095932\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:13 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:13 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7442514300346375 for class 0   \n",
      "[04/02/2024 09:07:13 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:13 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.153\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.74425143, inf]\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1202 \n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 306\n",
      "[04/02/2024 09:07:13 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : =============================== END Epoch 5 =======================\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9916805324459235, 'coverage_1': 0.15025, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7910\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : cur_query_count= 90 and max_query_count=1000\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 6 ============================\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : Number of unalabeled points  :7910\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : Current Available Query Budget: 910\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:13 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:13 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7902\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : Training data size : 1300\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1301}\n",
      "[04/02/2024 09:07:13 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:13 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:13 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1300}\n",
      "[04/02/2024 09:07:13 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:13 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:13 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3131 , Training Loss : 0.0094\n",
      "[04/02/2024 09:07:13 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0408 , Training Loss : 0.0033\n",
      "[04/02/2024 09:07:13 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0408 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:14 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0423 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:14 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0431 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:14 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0423 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:14 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0438 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:14 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0431 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:14 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0423 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:14 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0415 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:15 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0423 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:15 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0423 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:15 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0415 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:15 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0415 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:15 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0415 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:15 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0423 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:16 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0415 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:16 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0446 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:16 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0438 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:16 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0446 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:16 PM : DEBUG : model_trai : ] : Average training loss : 0.002240079943527341\n",
      "[04/02/2024 09:07:16 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:16 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:16 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.49\n",
      "[04/02/2024 09:07:16 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.49\n",
      "[04/02/2024 09:07:16 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:16 PM : INFO  : self_train : ] : Training error of trained model : 4.15\n",
      "[04/02/2024 09:07:16 PM : INFO  : self_train : ] : Test error of the model         : 48.70\n",
      "[04/02/2024 09:07:16 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:16 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:16 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:16 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:16 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:16 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:16 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:16 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:16 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7902\n",
      "[04/02/2024 09:07:16 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:16 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:17 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.3445317004621029\n",
      "[04/02/2024 09:07:17 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:17 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:17 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:17 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9267881512641907 for class 0   \n",
      "[04/02/2024 09:07:17 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:17 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:07:17 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.92678815, inf]\n",
      "[04/02/2024 09:07:17 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1204 \n",
      "[04/02/2024 09:07:17 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:07:17 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : =============================== END Epoch 6 =======================\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950166112956811, 'coverage_1': 0.1505, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7902\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : cur_query_count= 98 and max_query_count=1000\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 7 ============================\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : Number of unalabeled points  :7902\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : Current Available Query Budget: 902\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:17 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:17 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7894\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : Training data size : 1310\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1300}\n",
      "[04/02/2024 09:07:17 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:17 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:17 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1310}\n",
      "[04/02/2024 09:07:17 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:17 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:17 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3534 , Training Loss : 0.0095\n",
      "[04/02/2024 09:07:17 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0397 , Training Loss : 0.0032\n",
      "[04/02/2024 09:07:17 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0405 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:17 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0382 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:18 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0397 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:18 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0389 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:18 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0405 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:18 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0412 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:18 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0420 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:18 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0420 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:19 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0420 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:19 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0412 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:19 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0412 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:19 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0420 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:19 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0412 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:19 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0412 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:19 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0405 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:20 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0405 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:20 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0412 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:20 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0405 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:20 PM : DEBUG : model_trai : ] : Average training loss : 0.0021482866463261225\n",
      "[04/02/2024 09:07:20 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:20 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:20 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.49\n",
      "[04/02/2024 09:07:20 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.49\n",
      "[04/02/2024 09:07:20 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:20 PM : INFO  : self_train : ] : Training error of trained model : 4.05\n",
      "[04/02/2024 09:07:20 PM : INFO  : self_train : ] : Test error of the model         : 48.70\n",
      "[04/02/2024 09:07:20 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:20 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:20 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:20 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:20 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:20 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:20 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:20 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:20 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7894\n",
      "[04/02/2024 09:07:20 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:20 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:20 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.3579338578879833\n",
      "[04/02/2024 09:07:20 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:20 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:20 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:21 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.941474437713623 for class 0   \n",
      "[04/02/2024 09:07:21 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:21 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:07:21 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.94147444, inf]\n",
      "[04/02/2024 09:07:21 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1204 \n",
      "[04/02/2024 09:07:21 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:07:21 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : =============================== END Epoch 7 =======================\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950166112956811, 'coverage_1': 0.1505, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7894\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : cur_query_count= 106 and max_query_count=1000\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 8 ============================\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : Number of unalabeled points  :7894\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : Current Available Query Budget: 894\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:21 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:21 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7886\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : Training data size : 1318\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1310}\n",
      "[04/02/2024 09:07:21 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:21 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:21 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1318}\n",
      "[04/02/2024 09:07:21 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:21 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:21 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3528 , Training Loss : 0.0097\n",
      "[04/02/2024 09:07:21 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0470 , Training Loss : 0.0034\n",
      "[04/02/2024 09:07:21 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0448 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:21 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0448 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:22 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0455 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:22 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0455 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:22 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0470 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:22 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0478 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:22 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0470 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:22 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0448 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:22 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0440 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:23 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0448 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:23 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0455 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:23 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0455 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:23 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0463 , Training Loss : 0.0017\n",
      "[04/02/2024 09:07:23 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0440 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:23 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0432 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:24 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0440 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:24 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0440 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:24 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0432 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:24 PM : DEBUG : model_trai : ] : Average training loss : 0.002205770858659381\n",
      "[04/02/2024 09:07:24 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:24 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:24 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4895\n",
      "[04/02/2024 09:07:24 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4895\n",
      "[04/02/2024 09:07:24 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:24 PM : INFO  : self_train : ] : Training error of trained model : 4.63\n",
      "[04/02/2024 09:07:24 PM : INFO  : self_train : ] : Test error of the model         : 48.75\n",
      "[04/02/2024 09:07:24 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:24 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:24 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:24 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:24 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:24 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:24 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:24 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:24 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7886\n",
      "[04/02/2024 09:07:24 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:24 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:24 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.356773188740015\n",
      "[04/02/2024 09:07:24 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:24 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:24 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:24 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9396132826805115 for class 0   \n",
      "[04/02/2024 09:07:24 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:24 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:07:24 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.9396133, inf]\n",
      "[04/02/2024 09:07:25 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1202 \n",
      "[04/02/2024 09:07:25 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:07:25 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : =============================== END Epoch 8 =======================\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950083194675541, 'coverage_1': 0.15025, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7886\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : cur_query_count= 114 and max_query_count=1000\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 9 ============================\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : Number of unalabeled points  :7886\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : Current Available Query Budget: 886\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:25 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:25 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7878\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : Training data size : 1324\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1318}\n",
      "[04/02/2024 09:07:25 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:25 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:25 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1324}\n",
      "[04/02/2024 09:07:25 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:25 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:25 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3927 , Training Loss : 0.0096\n",
      "[04/02/2024 09:07:25 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0468 , Training Loss : 0.0034\n",
      "[04/02/2024 09:07:25 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0461 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:25 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0461 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:25 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0483 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:26 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0491 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:26 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0483 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:26 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0483 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:26 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0483 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:26 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0483 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:26 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0483 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:27 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0483 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:27 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0491 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:27 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0476 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:27 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0476 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:27 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0468 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:27 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0476 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:28 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0468 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:28 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0468 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:28 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0476 , Training Loss : 0.0018\n",
      "[04/02/2024 09:07:28 PM : DEBUG : model_trai : ] : Average training loss : 0.002247605314635039\n",
      "[04/02/2024 09:07:28 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:28 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:28 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.489\n",
      "[04/02/2024 09:07:28 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.489\n",
      "[04/02/2024 09:07:28 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:28 PM : INFO  : self_train : ] : Training error of trained model : 4.76\n",
      "[04/02/2024 09:07:28 PM : INFO  : self_train : ] : Test error of the model         : 48.75\n",
      "[04/02/2024 09:07:28 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:28 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:28 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:28 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:28 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:28 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:28 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:28 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:28 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7878\n",
      "[04/02/2024 09:07:28 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:28 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:28 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.35967782709002494\n",
      "[04/02/2024 09:07:28 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:28 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:28 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:28 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9420137405395508 for class 0   \n",
      "[04/02/2024 09:07:28 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:28 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1545\n",
      "[04/02/2024 09:07:28 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.94201374, inf]\n",
      "[04/02/2024 09:07:29 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1203 \n",
      "[04/02/2024 09:07:29 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 309\n",
      "[04/02/2024 09:07:29 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : =============================== END Epoch 9 =======================\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9941812136325852, 'coverage_1': 0.150375, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7878\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : cur_query_count= 122 and max_query_count=1000\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 10 ============================\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : Number of unalabeled points  :7878\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : Current Available Query Budget: 878\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:29 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:29 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7870\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : Training data size : 1333\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1324}\n",
      "[04/02/2024 09:07:29 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:29 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:29 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1333}\n",
      "[04/02/2024 09:07:29 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:29 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:29 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.6437 , Training Loss : 0.0143\n",
      "[04/02/2024 09:07:29 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0518 , Training Loss : 0.0037\n",
      "[04/02/2024 09:07:29 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0488 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:29 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0503 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:30 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0495 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:30 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0503 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:30 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0510 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:30 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0510 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:30 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0510 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:30 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0518 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:31 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0510 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:31 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0510 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:31 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0510 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:31 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0503 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:31 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0503 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:31 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0495 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:31 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0488 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:32 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0488 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:32 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0488 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:32 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0495 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:32 PM : DEBUG : model_trai : ] : Average training loss : 0.00254481717766085\n",
      "[04/02/2024 09:07:32 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:32 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:32 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4895\n",
      "[04/02/2024 09:07:32 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4895\n",
      "[04/02/2024 09:07:32 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:32 PM : INFO  : self_train : ] : Training error of trained model : 4.95\n",
      "[04/02/2024 09:07:32 PM : INFO  : self_train : ] : Test error of the model         : 48.70\n",
      "[04/02/2024 09:07:32 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:32 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:32 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:32 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:32 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:32 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:32 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:32 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:32 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7870\n",
      "[04/02/2024 09:07:32 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:32 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:32 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.3068050798177719\n",
      "[04/02/2024 09:07:32 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:32 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:32 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:32 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8804938197135925 for class 0   \n",
      "[04/02/2024 09:07:32 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:32 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:07:32 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8804938, inf]\n",
      "[04/02/2024 09:07:33 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1203 \n",
      "[04/02/2024 09:07:33 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:07:33 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : =============================== END Epoch 10 =======================\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950124688279302, 'coverage_1': 0.150375, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7870\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : cur_query_count= 130 and max_query_count=1000\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 11 ============================\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : Number of unalabeled points  :7870\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : Current Available Query Budget: 870\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:33 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:33 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7862\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : Training data size : 1341\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1333}\n",
      "[04/02/2024 09:07:33 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:33 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:33 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1341}\n",
      "[04/02/2024 09:07:33 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:33 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:33 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.0507 , Training Loss : 0.0041\n",
      "[04/02/2024 09:07:33 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0522 , Training Loss : 0.0029\n",
      "[04/02/2024 09:07:33 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0537 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:33 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0552 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:34 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0544 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:34 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0559 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:34 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0544 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:34 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0544 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:34 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0544 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:34 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0544 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:35 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0537 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:35 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0537 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:35 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0537 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:35 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0537 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:35 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0552 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:35 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0544 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:36 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0544 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:36 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0537 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:36 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0552 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:36 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0544 , Training Loss : 0.0019\n",
      "[04/02/2024 09:07:36 PM : DEBUG : model_trai : ] : Average training loss : 0.002036039512287651\n",
      "[04/02/2024 09:07:36 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:36 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:36 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4885\n",
      "[04/02/2024 09:07:36 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4885\n",
      "[04/02/2024 09:07:36 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:36 PM : INFO  : self_train : ] : Training error of trained model : 5.52\n",
      "[04/02/2024 09:07:36 PM : INFO  : self_train : ] : Test error of the model         : 48.80\n",
      "[04/02/2024 09:07:36 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:36 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:36 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:36 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:36 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:36 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:36 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:36 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7862\n",
      "[04/02/2024 09:07:36 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:36 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:36 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.3435312210023403\n",
      "[04/02/2024 09:07:36 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:36 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:36 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:36 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9235708117485046 for class 0   \n",
      "[04/02/2024 09:07:36 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:36 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1545\n",
      "[04/02/2024 09:07:36 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.9235708, inf]\n",
      "[04/02/2024 09:07:37 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1203 \n",
      "[04/02/2024 09:07:37 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 309\n",
      "[04/02/2024 09:07:37 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : =============================== END Epoch 11 =======================\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9941812136325852, 'coverage_1': 0.150375, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7862\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : cur_query_count= 138 and max_query_count=1000\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 12 ============================\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : Number of unalabeled points  :7862\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : Current Available Query Budget: 862\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:37 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:37 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7854\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : Training data size : 1349\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1341}\n",
      "[04/02/2024 09:07:37 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:37 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:37 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1349}\n",
      "[04/02/2024 09:07:37 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:37 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:37 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3951 , Training Loss : 0.0102\n",
      "[04/02/2024 09:07:37 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0578 , Training Loss : 0.0035\n",
      "[04/02/2024 09:07:37 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0549 , Training Loss : 0.0026\n",
      "[04/02/2024 09:07:37 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0549 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:38 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0549 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:38 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0549 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:38 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0549 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:38 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0556 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:38 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0563 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:38 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0578 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:39 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0593 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:39 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0586 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:39 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0593 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:39 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0586 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:39 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0578 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:39 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0593 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:39 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0578 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:40 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0578 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:40 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0593 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:40 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0586 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:40 PM : DEBUG : model_trai : ] : Average training loss : 0.002499018557146946\n",
      "[04/02/2024 09:07:40 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:40 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:40 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4885\n",
      "[04/02/2024 09:07:40 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4885\n",
      "[04/02/2024 09:07:40 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:40 PM : INFO  : self_train : ] : Training error of trained model : 5.93\n",
      "[04/02/2024 09:07:40 PM : INFO  : self_train : ] : Test error of the model         : 48.80\n",
      "[04/02/2024 09:07:40 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:40 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:40 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:40 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:40 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:40 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:40 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:40 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7854\n",
      "[04/02/2024 09:07:40 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:40 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:40 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.354620513767004\n",
      "[04/02/2024 09:07:40 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:40 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:40 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9365264773368835 for class 0   \n",
      "[04/02/2024 09:07:41 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:41 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.154\n",
      "[04/02/2024 09:07:41 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.9365265, inf]\n",
      "[04/02/2024 09:07:41 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1199 \n",
      "[04/02/2024 09:07:41 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 308\n",
      "[04/02/2024 09:07:41 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : =============================== END Epoch 12 =======================\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.994161801501251, 'coverage_1': 0.149875, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7854\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : cur_query_count= 146 and max_query_count=1000\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 13 ============================\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : Number of unalabeled points  :7854\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : Current Available Query Budget: 854\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:41 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:41 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7846\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : Training data size : 1353\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1349}\n",
      "[04/02/2024 09:07:41 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:41 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:41 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1353}\n",
      "[04/02/2024 09:07:41 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:41 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:41 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.6829 , Training Loss : 0.0157\n",
      "[04/02/2024 09:07:41 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0576 , Training Loss : 0.0039\n",
      "[04/02/2024 09:07:41 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0599 , Training Loss : 0.0025\n",
      "[04/02/2024 09:07:42 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0591 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:42 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0606 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:42 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0591 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:42 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0562 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:42 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0569 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:42 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0569 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:42 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0562 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:43 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0569 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:43 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0569 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:43 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0540 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:43 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0569 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:43 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0569 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:43 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0554 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:44 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0554 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:44 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0569 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:44 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0576 , Training Loss : 0.0020\n",
      "[04/02/2024 09:07:44 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0576 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:44 PM : DEBUG : model_trai : ] : Average training loss : 0.0028045464682575055\n",
      "[04/02/2024 09:07:44 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:44 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:44 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.49\n",
      "[04/02/2024 09:07:44 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.49\n",
      "[04/02/2024 09:07:44 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:44 PM : INFO  : self_train : ] : Training error of trained model : 5.40\n",
      "[04/02/2024 09:07:44 PM : INFO  : self_train : ] : Test error of the model         : 48.70\n",
      "[04/02/2024 09:07:44 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:44 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:44 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:44 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:44 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:44 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:44 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:44 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7846\n",
      "[04/02/2024 09:07:44 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:44 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:44 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.35297299805283544\n",
      "[04/02/2024 09:07:44 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:44 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:44 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:44 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9361239075660706 for class 0   \n",
      "[04/02/2024 09:07:44 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:44 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:07:44 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.9361239, inf]\n",
      "[04/02/2024 09:07:45 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1204 \n",
      "[04/02/2024 09:07:45 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:07:45 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : =============================== END Epoch 13 =======================\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950166112956811, 'coverage_1': 0.1505, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7846\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : cur_query_count= 154 and max_query_count=1000\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 14 ============================\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : Number of unalabeled points  :7846\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : Current Available Query Budget: 846\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:45 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:45 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7838\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : Training data size : 1366\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1353}\n",
      "[04/02/2024 09:07:45 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:45 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:45 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1366}\n",
      "[04/02/2024 09:07:45 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:45 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:45 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1684 , Training Loss : 0.0067\n",
      "[04/02/2024 09:07:45 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0608 , Training Loss : 0.0034\n",
      "[04/02/2024 09:07:45 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0600 , Training Loss : 0.0026\n",
      "[04/02/2024 09:07:45 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0593 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:46 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0593 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:46 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0600 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:46 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0556 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:46 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0556 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:46 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0542 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:46 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0586 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:46 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0586 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:47 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0578 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:47 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0586 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:47 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0571 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:47 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0571 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:47 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0549 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:47 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0571 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:48 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0556 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:48 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0556 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:48 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0549 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:48 PM : DEBUG : model_trai : ] : Average training loss : 0.0023595356144582944\n",
      "[04/02/2024 09:07:48 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:48 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:48 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.49\n",
      "[04/02/2024 09:07:48 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.49\n",
      "[04/02/2024 09:07:48 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:48 PM : INFO  : self_train : ] : Training error of trained model : 5.56\n",
      "[04/02/2024 09:07:48 PM : INFO  : self_train : ] : Test error of the model         : 48.70\n",
      "[04/02/2024 09:07:48 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:48 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:48 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:48 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:48 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:48 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:48 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:48 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7838\n",
      "[04/02/2024 09:07:48 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:48 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:48 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.3591809426546097\n",
      "[04/02/2024 09:07:48 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:48 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:48 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9427701830863953 for class 0   \n",
      "[04/02/2024 09:07:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:48 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:07:48 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.9427702, inf]\n",
      "[04/02/2024 09:07:49 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1204 \n",
      "[04/02/2024 09:07:49 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:07:49 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : =============================== END Epoch 14 =======================\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950166112956811, 'coverage_1': 0.1505, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7838\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : cur_query_count= 162 and max_query_count=1000\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 15 ============================\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : Number of unalabeled points  :7838\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : Current Available Query Budget: 838\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:49 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:49 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7830\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : Training data size : 1374\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1366}\n",
      "[04/02/2024 09:07:49 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:49 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:49 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1374}\n",
      "[04/02/2024 09:07:49 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:49 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:49 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.0611 , Training Loss : 0.0039\n",
      "[04/02/2024 09:07:49 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0597 , Training Loss : 0.0030\n",
      "[04/02/2024 09:07:49 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0619 , Training Loss : 0.0026\n",
      "[04/02/2024 09:07:49 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0604 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:49 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0604 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:50 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0597 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:50 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0597 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:50 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0590 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:50 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0590 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:50 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0590 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:50 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0590 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:51 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0626 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:51 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0626 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:51 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0633 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:51 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0640 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:51 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0626 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:51 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0626 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:51 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0619 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:52 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0626 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:52 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0619 , Training Loss : 0.0021\n",
      "[04/02/2024 09:07:52 PM : DEBUG : model_trai : ] : Average training loss : 0.0022434559941535565\n",
      "[04/02/2024 09:07:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:52 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4895\n",
      "[04/02/2024 09:07:52 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4895\n",
      "[04/02/2024 09:07:52 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:52 PM : INFO  : self_train : ] : Training error of trained model : 5.97\n",
      "[04/02/2024 09:07:52 PM : INFO  : self_train : ] : Test error of the model         : 48.75\n",
      "[04/02/2024 09:07:52 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:52 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:52 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:52 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:52 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:52 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:52 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:52 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7830\n",
      "[04/02/2024 09:07:52 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:52 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:52 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.30754010382294655\n",
      "[04/02/2024 09:07:52 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:52 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:52 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8815402388572693 for class 0   \n",
      "[04/02/2024 09:07:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:52 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.155\n",
      "[04/02/2024 09:07:52 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.88154024, inf]\n",
      "[04/02/2024 09:07:53 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1203 \n",
      "[04/02/2024 09:07:53 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 310\n",
      "[04/02/2024 09:07:53 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : =============================== END Epoch 15 =======================\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9950124688279302, 'coverage_1': 0.150375, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7830\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : cur_query_count= 170 and max_query_count=1000\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 16 ============================\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : Number of unalabeled points  :7830\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : Current Available Query Budget: 830\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:53 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:53 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7822\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : Training data size : 1381\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1374}\n",
      "[04/02/2024 09:07:53 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:53 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1381}\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.6640 , Training Loss : 0.0155\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0594 , Training Loss : 0.0039\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0637 , Training Loss : 0.0027\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0623 , Training Loss : 0.0025\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0630 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:53 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0630 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:54 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0637 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:54 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0637 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:54 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0630 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:54 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0623 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:54 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0608 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:54 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0615 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:55 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0623 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:55 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0637 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:55 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0630 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:55 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0630 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:55 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0630 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:55 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0630 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:56 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0637 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:56 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0630 , Training Loss : 0.0022\n",
      "[04/02/2024 09:07:56 PM : DEBUG : model_trai : ] : Average training loss : 0.0028623578969328434\n",
      "[04/02/2024 09:07:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:07:56 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4885\n",
      "[04/02/2024 09:07:56 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4885\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : Training error of trained model : 6.30\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : Test error of the model         : 48.80\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:07:56 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7822\n",
      "[04/02/2024 09:07:56 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:07:56 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.3221103922426701\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:07:56 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:07:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8986930847167969 for class 0   \n",
      "[04/02/2024 09:07:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:07:56 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.154\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8986931, inf]\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1198 \n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 308\n",
      "[04/02/2024 09:07:56 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:07:56 PM : DEBUG : self_train : ] : =============================== END Epoch 16 =======================\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9941569282136895, 'coverage_1': 0.14975, 'coverage_2': 0}\n",
      "[04/02/2024 09:07:56 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7822\n",
      "[04/02/2024 09:07:56 PM : DEBUG : self_train : ] : cur_query_count= 178 and max_query_count=1000\n",
      "[04/02/2024 09:07:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:56 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 17 ============================\n",
      "[04/02/2024 09:07:56 PM : DEBUG : self_train : ] : Number of unalabeled points  :7822\n",
      "[04/02/2024 09:07:56 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:07:56 PM : DEBUG : self_train : ] : Current Available Query Budget: 822\n",
      "[04/02/2024 09:07:56 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:07:56 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:07:57 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:07:57 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:07:57 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7814\n",
      "[04/02/2024 09:07:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:07:57 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:07:57 PM : INFO  : self_train : ] : Training data size : 1384\n",
      "[04/02/2024 09:07:57 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:07:57 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1381}\n",
      "[04/02/2024 09:07:57 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:57 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1384}\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1207 , Training Loss : 0.0062\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0708 , Training Loss : 0.0035\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0708 , Training Loss : 0.0028\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0679 , Training Loss : 0.0025\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0665 , Training Loss : 0.0025\n",
      "[04/02/2024 09:07:57 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0665 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:58 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0643 , Training Loss : 0.0024\n",
      "[04/02/2024 09:07:58 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0643 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:58 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0636 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:58 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0636 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:58 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0621 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:58 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0614 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:58 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0629 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:59 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0636 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:59 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0650 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:59 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0650 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:59 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0650 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:59 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0643 , Training Loss : 0.0023\n",
      "[04/02/2024 09:07:59 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0658 , Training Loss : 0.0023\n",
      "[04/02/2024 09:08:00 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0636 , Training Loss : 0.0023\n",
      "[04/02/2024 09:08:00 PM : DEBUG : model_trai : ] : Average training loss : 0.0024822182578316428\n",
      "[04/02/2024 09:08:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:00 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.489\n",
      "[04/02/2024 09:08:00 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.489\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : Training error of trained model : 7.01\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : Test error of the model         : 49.40\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:00 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7814\n",
      "[04/02/2024 09:08:00 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:00 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.22098441720008846\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:00 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:00 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7621036171913147 for class 0   \n",
      "[04/02/2024 09:08:00 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:00 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1535\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7621036, inf]\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1235 \n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 307\n",
      "[04/02/2024 09:08:00 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : =============================== END Epoch 17 =======================\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.979757085020243, 'coverage_1': 0.154375, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7814\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : cur_query_count= 186 and max_query_count=1000\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 18 ============================\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : Number of unalabeled points  :7814\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : Current Available Query Budget: 814\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:00 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:00 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7806\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : Training data size : 1429\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1384}\n",
      "[04/02/2024 09:08:00 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:00 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:00 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1429}\n",
      "[04/02/2024 09:08:00 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:00 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:00 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5738 , Training Loss : 0.0129\n",
      "[04/02/2024 09:08:01 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0847 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:01 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0833 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:01 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0826 , Training Loss : 0.0032\n",
      "[04/02/2024 09:08:01 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0826 , Training Loss : 0.0032\n",
      "[04/02/2024 09:08:01 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0833 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:01 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0833 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:02 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0826 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:02 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0826 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:02 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0819 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:02 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0819 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:02 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0819 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:02 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0819 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:03 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0819 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:03 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0826 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:03 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0826 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:03 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0826 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:03 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0826 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:03 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0826 , Training Loss : 0.0029\n",
      "[04/02/2024 09:08:03 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0826 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:04 PM : DEBUG : model_trai : ] : Average training loss : 0.0034332151609044047\n",
      "[04/02/2024 09:08:04 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:04 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:04 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4895\n",
      "[04/02/2024 09:08:04 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4895\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : Training error of trained model : 8.47\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : Test error of the model         : 49.30\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:04 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7806\n",
      "[04/02/2024 09:08:04 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:04 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27065917998552325\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:04 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:04 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8302724361419678 for class 0   \n",
      "[04/02/2024 09:08:04 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:04 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.154\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.83027244, inf]\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1230 \n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 308\n",
      "[04/02/2024 09:08:04 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : =============================== END Epoch 18 =======================\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9821138211382113, 'coverage_1': 0.15375, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7806\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : cur_query_count= 194 and max_query_count=1000\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 19 ============================\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : Number of unalabeled points  :7806\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : Current Available Query Budget: 806\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:04 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:04 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7798\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : Training data size : 1432\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1429}\n",
      "[04/02/2024 09:08:04 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:04 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:04 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1432}\n",
      "[04/02/2024 09:08:04 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:04 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:04 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5628 , Training Loss : 0.0127\n",
      "[04/02/2024 09:08:05 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0838 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:05 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0845 , Training Loss : 0.0033\n",
      "[04/02/2024 09:08:05 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0845 , Training Loss : 0.0032\n",
      "[04/02/2024 09:08:05 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0845 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:05 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0845 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:05 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0852 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:06 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0852 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:06 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0852 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:06 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0845 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:06 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0845 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:06 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0838 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:06 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0838 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:06 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0838 , Training Loss : 0.0029\n",
      "[04/02/2024 09:08:07 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0838 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:07 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0838 , Training Loss : 0.0029\n",
      "[04/02/2024 09:08:07 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0838 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:07 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0838 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:07 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0838 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:07 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0838 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:07 PM : DEBUG : model_trai : ] : Average training loss : 0.003404162086082618\n",
      "[04/02/2024 09:08:07 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:07 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:08 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4885\n",
      "[04/02/2024 09:08:08 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4885\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : Training error of trained model : 8.45\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : Test error of the model         : 49.35\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:08 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7798\n",
      "[04/02/2024 09:08:08 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:08 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2721980049312115\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:08 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:08 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8308448195457458 for class 0   \n",
      "[04/02/2024 09:08:08 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:08 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1535\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8308448, inf]\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1236 \n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 307\n",
      "[04/02/2024 09:08:08 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : =============================== END Epoch 19 =======================\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9830097087378641, 'coverage_1': 0.1545, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7798\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : cur_query_count= 202 and max_query_count=1000\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 20 ============================\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : Number of unalabeled points  :7798\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : Current Available Query Budget: 798\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:08 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:08 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7790\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : Training data size : 1446\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1432}\n",
      "[04/02/2024 09:08:08 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:08 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:08 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1446}\n",
      "[04/02/2024 09:08:08 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:08 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:08 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2870 , Training Loss : 0.0087\n",
      "[04/02/2024 09:08:09 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0851 , Training Loss : 0.0040\n",
      "[04/02/2024 09:08:09 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0851 , Training Loss : 0.0033\n",
      "[04/02/2024 09:08:09 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0851 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:09 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0851 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:09 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0851 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:09 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0844 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:10 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0844 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:10 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0844 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:10 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0844 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:10 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0844 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:10 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0844 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:10 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0844 , Training Loss : 0.0029\n",
      "[04/02/2024 09:08:11 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0851 , Training Loss : 0.0029\n",
      "[04/02/2024 09:08:11 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0851 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:11 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0851 , Training Loss : 0.0029\n",
      "[04/02/2024 09:08:11 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0851 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:11 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0851 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:11 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0851 , Training Loss : 0.0029\n",
      "[04/02/2024 09:08:12 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0851 , Training Loss : 0.0029\n",
      "[04/02/2024 09:08:12 PM : DEBUG : model_trai : ] : Average training loss : 0.003168046676142134\n",
      "[04/02/2024 09:08:12 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:12 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:12 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4875\n",
      "[04/02/2024 09:08:12 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4875\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : Training error of trained model : 8.51\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : Test error of the model         : 48.70\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:12 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7790\n",
      "[04/02/2024 09:08:12 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:12 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.3478710158467293\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:12 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:12 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9253560304641724 for class 0   \n",
      "[04/02/2024 09:08:12 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:12 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.92535603, inf]\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1238 \n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:08:12 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : =============================== END Epoch 20 =======================\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9781906300484653, 'coverage_1': 0.15475, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7790\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : cur_query_count= 210 and max_query_count=1000\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 21 ============================\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : Number of unalabeled points  :7790\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : Current Available Query Budget: 790\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:12 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:12 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7782\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : Training data size : 1456\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1446}\n",
      "[04/02/2024 09:08:12 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:12 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:12 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1456}\n",
      "[04/02/2024 09:08:12 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:12 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:12 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.0941 , Training Loss : 0.0059\n",
      "[04/02/2024 09:08:13 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0913 , Training Loss : 0.0039\n",
      "[04/02/2024 09:08:13 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0913 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:13 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0920 , Training Loss : 0.0032\n",
      "[04/02/2024 09:08:13 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0913 , Training Loss : 0.0032\n",
      "[04/02/2024 09:08:13 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0907 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:13 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0907 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:13 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0913 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:14 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0913 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:14 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0927 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:14 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0934 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:14 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0934 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:14 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0934 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:15 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0941 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:15 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0934 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:15 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0934 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:15 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0934 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:15 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0934 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:15 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0941 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:15 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0934 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:16 PM : DEBUG : model_trai : ] : Average training loss : 0.0031262258506827897\n",
      "[04/02/2024 09:08:16 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:16 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:16 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4895\n",
      "[04/02/2024 09:08:16 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4895\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : Training error of trained model : 9.07\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : Test error of the model         : 48.85\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:16 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7782\n",
      "[04/02/2024 09:08:16 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:16 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.3266871794462204\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:16 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:16 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.9020969867706299 for class 0   \n",
      "[04/02/2024 09:08:16 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:16 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.902097, inf]\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1233 \n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:08:16 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : =============================== END Epoch 21 =======================\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9805352798053528, 'coverage_1': 0.154125, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7782\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : cur_query_count= 218 and max_query_count=1000\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 22 ============================\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : Number of unalabeled points  :7782\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : Current Available Query Budget: 782\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:16 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:16 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7774\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : Training data size : 1459\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1456}\n",
      "[04/02/2024 09:08:16 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:16 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:16 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1459}\n",
      "[04/02/2024 09:08:16 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:16 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:17 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3365 , Training Loss : 0.0094\n",
      "[04/02/2024 09:08:17 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0918 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:17 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0912 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:17 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0912 , Training Loss : 0.0032\n",
      "[04/02/2024 09:08:17 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0918 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:17 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0939 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:18 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0925 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:18 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0953 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:18 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0960 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:18 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0953 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:18 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0939 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:18 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0946 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:18 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0932 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:19 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0932 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:19 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0932 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:19 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0932 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:19 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0932 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:19 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0932 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:19 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0925 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:20 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0932 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:20 PM : DEBUG : model_trai : ] : Average training loss : 0.0032756274368536996\n",
      "[04/02/2024 09:08:20 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:20 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:20 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.4885\n",
      "[04/02/2024 09:08:20 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.4885\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : Training error of trained model : 9.25\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : Test error of the model         : 48.65\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:20 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7774\n",
      "[04/02/2024 09:08:20 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:20 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.31958312818408013\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:20 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:20 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8919716477394104 for class 0   \n",
      "[04/02/2024 09:08:20 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:20 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1585\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.89197165, inf]\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1232 \n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 317\n",
      "[04/02/2024 09:08:20 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : =============================== END Epoch 22 =======================\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9805194805194806, 'coverage_1': 0.154, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7774\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : cur_query_count= 226 and max_query_count=1000\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 23 ============================\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : Number of unalabeled points  :7774\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : Current Available Query Budget: 774\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:20 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:20 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7766\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : Training data size : 1466\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1459}\n",
      "[04/02/2024 09:08:20 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:20 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:20 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1466}\n",
      "[04/02/2024 09:08:20 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:20 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:20 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3643 , Training Loss : 0.0100\n",
      "[04/02/2024 09:08:21 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0962 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:21 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0935 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:21 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0928 , Training Loss : 0.0032\n",
      "[04/02/2024 09:08:21 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0928 , Training Loss : 0.0032\n",
      "[04/02/2024 09:08:21 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0935 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:21 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0948 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:22 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0948 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:22 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0962 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:22 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0989 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:22 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0989 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:22 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0975 , Training Loss : 0.0031\n",
      "[04/02/2024 09:08:22 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0975 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:23 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0975 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:23 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0975 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:23 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0975 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:23 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0982 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:23 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0975 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:23 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0962 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:23 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0969 , Training Loss : 0.0030\n",
      "[04/02/2024 09:08:24 PM : DEBUG : model_trai : ] : Average training loss : 0.0033319239414304367\n",
      "[04/02/2024 09:08:24 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:24 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:24 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.49\n",
      "[04/02/2024 09:08:24 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.49\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : Training error of trained model : 9.48\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : Test error of the model         : 49.80\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:24 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7766\n",
      "[04/02/2024 09:08:24 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:24 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1964363785982132\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:24 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:24 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7322777509689331 for class 0   \n",
      "[04/02/2024 09:08:24 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:24 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.148\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.73227775, inf]\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1229 \n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 296\n",
      "[04/02/2024 09:08:24 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : =============================== END Epoch 23 =======================\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9820992676973149, 'coverage_1': 0.153625, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7766\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : cur_query_count= 234 and max_query_count=1000\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 24 ============================\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : Number of unalabeled points  :7766\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : Current Available Query Budget: 766\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:24 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:24 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7758\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : Training data size : 1471\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1466}\n",
      "[04/02/2024 09:08:24 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:24 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:24 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1471}\n",
      "[04/02/2024 09:08:24 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:24 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:24 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2148 , Training Loss : 0.0077\n",
      "[04/02/2024 09:08:25 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0959 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:25 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0965 , Training Loss : 0.0038\n",
      "[04/02/2024 09:08:25 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0965 , Training Loss : 0.0036\n",
      "[04/02/2024 09:08:25 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0952 , Training Loss : 0.0036\n",
      "[04/02/2024 09:08:25 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0945 , Training Loss : 0.0035\n",
      "[04/02/2024 09:08:25 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0952 , Training Loss : 0.0035\n",
      "[04/02/2024 09:08:26 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:26 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:26 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:26 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:26 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:26 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:26 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:27 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:27 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:27 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:27 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:27 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:27 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0952 , Training Loss : 0.0034\n",
      "[04/02/2024 09:08:27 PM : DEBUG : model_trai : ] : Average training loss : 0.0035418108931009485\n",
      "[04/02/2024 09:08:27 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:27 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:28 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.493\n",
      "[04/02/2024 09:08:28 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.493\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : Training error of trained model : 9.59\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : Test error of the model         : 50.60\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:28 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7758\n",
      "[04/02/2024 09:08:28 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:28 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.20499542072415353\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:28 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:28 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7510594129562378 for class 0   \n",
      "[04/02/2024 09:08:28 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:28 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.152\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7510594, inf]\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1178 \n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 304\n",
      "[04/02/2024 09:08:28 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : =============================== END Epoch 24 =======================\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9881154499151104, 'coverage_1': 0.14725, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7758\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : cur_query_count= 242 and max_query_count=1000\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 25 ============================\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : Number of unalabeled points  :7758\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : Current Available Query Budget: 758\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:28 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:28 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7750\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : Training data size : 1428\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1471}\n",
      "[04/02/2024 09:08:28 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:28 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:28 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1428}\n",
      "[04/02/2024 09:08:28 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:28 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:28 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2080 , Training Loss : 0.0077\n",
      "[04/02/2024 09:08:28 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0931 , Training Loss : 0.0049\n",
      "[04/02/2024 09:08:28 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0945 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:29 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0945 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:29 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0973 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:29 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0966 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:29 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0966 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:29 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0959 , Training Loss : 0.0040\n",
      "[04/02/2024 09:08:29 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0959 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:30 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0959 , Training Loss : 0.0040\n",
      "[04/02/2024 09:08:30 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0959 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:30 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0959 , Training Loss : 0.0040\n",
      "[04/02/2024 09:08:30 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0966 , Training Loss : 0.0039\n",
      "[04/02/2024 09:08:30 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0966 , Training Loss : 0.0040\n",
      "[04/02/2024 09:08:30 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0966 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:30 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0973 , Training Loss : 0.0040\n",
      "[04/02/2024 09:08:31 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0973 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:31 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0973 , Training Loss : 0.0040\n",
      "[04/02/2024 09:08:31 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0973 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:31 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0973 , Training Loss : 0.0039\n",
      "[04/02/2024 09:08:31 PM : DEBUG : model_trai : ] : Average training loss : 0.004076136372028406\n",
      "[04/02/2024 09:08:31 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:31 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:31 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.503\n",
      "[04/02/2024 09:08:31 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.503\n",
      "[04/02/2024 09:08:31 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:31 PM : INFO  : self_train : ] : Training error of trained model : 9.31\n",
      "[04/02/2024 09:08:31 PM : INFO  : self_train : ] : Test error of the model         : 51.95\n",
      "[04/02/2024 09:08:31 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:31 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:31 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:31 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:31 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:31 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:31 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:31 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7750\n",
      "[04/02/2024 09:08:32 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:32 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:32 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.19740146356821056\n",
      "[04/02/2024 09:08:32 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:32 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:32 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:32 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7518541216850281 for class 0   \n",
      "[04/02/2024 09:08:32 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:32 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1555\n",
      "[04/02/2024 09:08:32 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7518541, inf]\n",
      "[04/02/2024 09:08:32 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1147 \n",
      "[04/02/2024 09:08:32 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 311\n",
      "[04/02/2024 09:08:32 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : =============================== END Epoch 25 =======================\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.988666085440279, 'coverage_1': 0.143375, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7750\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : cur_query_count= 250 and max_query_count=1000\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 26 ============================\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : Number of unalabeled points  :7750\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : Current Available Query Budget: 750\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:32 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:32 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7742\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : Training data size : 1405\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1428}\n",
      "[04/02/2024 09:08:32 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:32 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:32 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1405}\n",
      "[04/02/2024 09:08:32 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:32 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:32 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3096 , Training Loss : 0.0086\n",
      "[04/02/2024 09:08:32 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0968 , Training Loss : 0.0051\n",
      "[04/02/2024 09:08:32 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0961 , Training Loss : 0.0046\n",
      "[04/02/2024 09:08:33 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0968 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:33 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0961 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:33 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0961 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:33 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0961 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:33 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0961 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:33 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0982 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:34 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0975 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:34 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0982 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:34 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0982 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:34 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0982 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:34 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0982 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:34 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0982 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:35 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0989 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:35 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0989 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:35 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0989 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:35 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0989 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:35 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0989 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:35 PM : DEBUG : model_trai : ] : Average training loss : 0.004436962377962431\n",
      "[04/02/2024 09:08:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:35 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5165\n",
      "[04/02/2024 09:08:35 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5165\n",
      "[04/02/2024 09:08:35 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:35 PM : INFO  : self_train : ] : Training error of trained model : 9.89\n",
      "[04/02/2024 09:08:35 PM : INFO  : self_train : ] : Test error of the model         : 51.75\n",
      "[04/02/2024 09:08:35 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:35 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:35 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:35 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:35 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:35 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:35 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:35 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:35 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7742\n",
      "[04/02/2024 09:08:35 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:35 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:36 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.19088611027598382\n",
      "[04/02/2024 09:08:36 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:36 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:36 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:36 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7567004561424255 for class 0   \n",
      "[04/02/2024 09:08:36 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:36 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1535\n",
      "[04/02/2024 09:08:36 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.75670046, inf]\n",
      "[04/02/2024 09:08:36 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1154 \n",
      "[04/02/2024 09:08:36 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 307\n",
      "[04/02/2024 09:08:36 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : =============================== END Epoch 26 =======================\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9939341421143848, 'coverage_1': 0.14425, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7742\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : cur_query_count= 258 and max_query_count=1000\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 27 ============================\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : Number of unalabeled points  :7742\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : Current Available Query Budget: 742\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:36 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:36 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7734\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : Training data size : 1420\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1405}\n",
      "[04/02/2024 09:08:36 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:36 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:36 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1420}\n",
      "[04/02/2024 09:08:36 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:36 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:36 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4958 , Training Loss : 0.0116\n",
      "[04/02/2024 09:08:36 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0944 , Training Loss : 0.0048\n",
      "[04/02/2024 09:08:36 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0937 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:37 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0937 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:37 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0937 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:37 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0937 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:37 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0937 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:37 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0937 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:37 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0937 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:38 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0937 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:38 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0937 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:38 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0937 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:38 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0937 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:38 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0937 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:38 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0937 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:38 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0937 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:39 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0937 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:39 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0937 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:39 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0937 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:39 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0937 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:39 PM : DEBUG : model_trai : ] : Average training loss : 0.0043717818374674955\n",
      "[04/02/2024 09:08:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:39 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.52\n",
      "[04/02/2024 09:08:39 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.52\n",
      "[04/02/2024 09:08:39 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:39 PM : INFO  : self_train : ] : Training error of trained model : 9.37\n",
      "[04/02/2024 09:08:39 PM : INFO  : self_train : ] : Test error of the model         : 51.45\n",
      "[04/02/2024 09:08:39 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:39 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:39 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:39 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:39 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:39 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:39 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:39 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:39 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7734\n",
      "[04/02/2024 09:08:39 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:39 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:39 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2621182931959629\n",
      "[04/02/2024 09:08:39 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:39 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:39 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8513593673706055 for class 0   \n",
      "[04/02/2024 09:08:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:40 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:08:40 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.85135937, inf]\n",
      "[04/02/2024 09:08:40 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1183 \n",
      "[04/02/2024 09:08:40 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:08:40 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : =============================== END Epoch 27 =======================\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9864750633981403, 'coverage_1': 0.147875, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7734\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : cur_query_count= 266 and max_query_count=1000\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 28 ============================\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : Number of unalabeled points  :7734\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : Current Available Query Budget: 734\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:40 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:40 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7726\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : Training data size : 1457\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1420}\n",
      "[04/02/2024 09:08:40 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:40 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:40 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1457}\n",
      "[04/02/2024 09:08:40 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:40 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:40 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3288 , Training Loss : 0.0090\n",
      "[04/02/2024 09:08:40 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.0988 , Training Loss : 0.0048\n",
      "[04/02/2024 09:08:40 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0995 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:40 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0995 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:41 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0995 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:41 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0995 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:41 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1002 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:41 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1002 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:41 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1002 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:41 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1002 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:42 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1009 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:42 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:42 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:42 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:42 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:42 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:43 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:43 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:43 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:43 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1009 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:43 PM : DEBUG : model_trai : ] : Average training loss : 0.004222107413497146\n",
      "[04/02/2024 09:08:43 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:43 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:43 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.521\n",
      "[04/02/2024 09:08:43 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.521\n",
      "[04/02/2024 09:08:43 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:43 PM : INFO  : self_train : ] : Training error of trained model : 9.95\n",
      "[04/02/2024 09:08:43 PM : INFO  : self_train : ] : Test error of the model         : 50.80\n",
      "[04/02/2024 09:08:43 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:43 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:43 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:43 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:43 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:43 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:43 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:43 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:43 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7726\n",
      "[04/02/2024 09:08:43 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:43 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:43 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23407191586494447\n",
      "[04/02/2024 09:08:43 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:43 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:43 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:43 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8143585324287415 for class 0   \n",
      "[04/02/2024 09:08:43 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:43 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:08:43 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.81435853, inf]\n",
      "[04/02/2024 09:08:44 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1195 \n",
      "[04/02/2024 09:08:44 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:08:44 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : =============================== END Epoch 28 =======================\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9849372384937238, 'coverage_1': 0.149375, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7726\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : cur_query_count= 274 and max_query_count=1000\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 29 ============================\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : Number of unalabeled points  :7726\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : Current Available Query Budget: 726\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:44 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:44 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7718\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : Training data size : 1477\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1457}\n",
      "[04/02/2024 09:08:44 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:44 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:44 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1477}\n",
      "[04/02/2024 09:08:44 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:44 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:44 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4083 , Training Loss : 0.0103\n",
      "[04/02/2024 09:08:44 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1043 , Training Loss : 0.0049\n",
      "[04/02/2024 09:08:44 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1022 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:44 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1029 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:45 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1036 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:45 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1036 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:45 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1036 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:45 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1043 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:45 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1043 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:45 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1043 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:46 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1043 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:46 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1043 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:46 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1049 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:46 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1049 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:46 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1049 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:46 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1049 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:46 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1049 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:47 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1049 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:47 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1049 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:47 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1049 , Training Loss : 0.0041\n",
      "[04/02/2024 09:08:47 PM : DEBUG : model_trai : ] : Average training loss : 0.004372228717664249\n",
      "[04/02/2024 09:08:47 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:47 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:47 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5205\n",
      "[04/02/2024 09:08:47 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5205\n",
      "[04/02/2024 09:08:47 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:47 PM : INFO  : self_train : ] : Training error of trained model : 10.29\n",
      "[04/02/2024 09:08:47 PM : INFO  : self_train : ] : Test error of the model         : 50.70\n",
      "[04/02/2024 09:08:47 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:47 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:47 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:47 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:47 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:47 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:47 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:47 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:47 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7718\n",
      "[04/02/2024 09:08:47 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:47 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:47 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23727594006061553\n",
      "[04/02/2024 09:08:47 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:47 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:47 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.817970871925354 for class 0   \n",
      "[04/02/2024 09:08:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:48 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:08:48 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8179709, inf]\n",
      "[04/02/2024 09:08:48 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1196 \n",
      "[04/02/2024 09:08:48 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:08:48 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : =============================== END Epoch 29 =======================\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9849498327759197, 'coverage_1': 0.1495, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7718\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : cur_query_count= 282 and max_query_count=1000\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 30 ============================\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : Number of unalabeled points  :7718\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : Current Available Query Budget: 718\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:48 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:48 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7710\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : Training data size : 1486\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1477}\n",
      "[04/02/2024 09:08:48 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:48 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:48 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1486}\n",
      "[04/02/2024 09:08:48 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:48 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:48 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1413 , Training Loss : 0.0059\n",
      "[04/02/2024 09:08:48 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1063 , Training Loss : 0.0047\n",
      "[04/02/2024 09:08:48 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1070 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:48 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1070 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:49 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1070 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:49 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1063 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:49 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1070 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:49 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1070 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:49 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1070 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:49 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1070 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:49 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1070 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:50 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1070 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:50 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1070 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:50 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1070 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:50 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1070 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:50 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1070 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:51 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1070 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:51 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1070 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:51 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1070 , Training Loss : 0.0042\n",
      "[04/02/2024 09:08:51 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1063 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:51 PM : DEBUG : model_trai : ] : Average training loss : 0.004187669064714719\n",
      "[04/02/2024 09:08:51 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:51 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:51 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5165\n",
      "[04/02/2024 09:08:51 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5165\n",
      "[04/02/2024 09:08:51 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:51 PM : INFO  : self_train : ] : Training error of trained model : 10.70\n",
      "[04/02/2024 09:08:51 PM : INFO  : self_train : ] : Test error of the model         : 51.15\n",
      "[04/02/2024 09:08:51 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:51 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:51 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:51 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:51 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:51 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:51 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:51 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:51 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7710\n",
      "[04/02/2024 09:08:51 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:51 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:51 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2568416242599487\n",
      "[04/02/2024 09:08:51 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:51 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:51 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:51 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8359988331794739 for class 0   \n",
      "[04/02/2024 09:08:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:52 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1625\n",
      "[04/02/2024 09:08:52 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.83599883, inf]\n",
      "[04/02/2024 09:08:52 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1243 \n",
      "[04/02/2024 09:08:52 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 325\n",
      "[04/02/2024 09:08:52 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : =============================== END Epoch 30 =======================\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9694288012872083, 'coverage_1': 0.155375, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7710\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : cur_query_count= 290 and max_query_count=1000\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 31 ============================\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : Number of unalabeled points  :7710\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : Current Available Query Budget: 710\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:52 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:52 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7702\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : Training data size : 1541\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1486}\n",
      "[04/02/2024 09:08:52 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:52 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:52 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1541}\n",
      "[04/02/2024 09:08:52 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:52 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:52 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3718 , Training Loss : 0.0096\n",
      "[04/02/2024 09:08:52 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1175 , Training Loss : 0.0049\n",
      "[04/02/2024 09:08:52 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1194 , Training Loss : 0.0046\n",
      "[04/02/2024 09:08:52 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1194 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:53 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1188 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:53 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1188 , Training Loss : 0.0047\n",
      "[04/02/2024 09:08:53 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1194 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:53 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1194 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:53 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1194 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:53 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1194 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:54 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1194 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:54 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1194 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:54 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1194 , Training Loss : 0.0046\n",
      "[04/02/2024 09:08:54 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1194 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:54 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1194 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:54 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:55 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1194 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:55 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1194 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:55 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1194 , Training Loss : 0.0047\n",
      "[04/02/2024 09:08:55 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1194 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:55 PM : DEBUG : model_trai : ] : Average training loss : 0.004473762601159978\n",
      "[04/02/2024 09:08:55 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:55 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:55 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:08:55 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:08:55 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:55 PM : INFO  : self_train : ] : Training error of trained model : 11.94\n",
      "[04/02/2024 09:08:55 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:08:55 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:55 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:55 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:55 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:55 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:55 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:55 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:55 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:55 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7702\n",
      "[04/02/2024 09:08:55 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:55 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:55 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.26270168998837473\n",
      "[04/02/2024 09:08:55 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:55 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:55 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8447372913360596 for class 0   \n",
      "[04/02/2024 09:08:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:56 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:08:56 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8447373, inf]\n",
      "[04/02/2024 09:08:56 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1247 \n",
      "[04/02/2024 09:08:56 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:08:56 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : =============================== END Epoch 31 =======================\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.967121090617482, 'coverage_1': 0.155875, 'coverage_2': 0}\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7702\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : cur_query_count= 298 and max_query_count=1000\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 32 ============================\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : Number of unalabeled points  :7702\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : Current Available Query Budget: 702\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:08:56 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:08:56 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7694\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : Training data size : 1553\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1541}\n",
      "[04/02/2024 09:08:56 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:56 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:08:56 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1553}\n",
      "[04/02/2024 09:08:56 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:08:56 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:08:56 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1217 , Training Loss : 0.0061\n",
      "[04/02/2024 09:08:56 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1243 , Training Loss : 0.0048\n",
      "[04/02/2024 09:08:56 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1243 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:56 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1243 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:57 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:57 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1249 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:57 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1249 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:57 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1249 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:57 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:57 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1249 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:58 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1249 , Training Loss : 0.0043\n",
      "[04/02/2024 09:08:58 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:58 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:58 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:58 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1249 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:58 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:59 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:59 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:59 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1249 , Training Loss : 0.0045\n",
      "[04/02/2024 09:08:59 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1249 , Training Loss : 0.0044\n",
      "[04/02/2024 09:08:59 PM : DEBUG : model_trai : ] : Average training loss : 0.00431811614051437\n",
      "[04/02/2024 09:08:59 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:59 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:08:59 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:08:59 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:08:59 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:08:59 PM : INFO  : self_train : ] : Training error of trained model : 12.36\n",
      "[04/02/2024 09:08:59 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:08:59 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:08:59 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:08:59 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:08:59 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:08:59 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:08:59 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:08:59 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:08:59 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:08:59 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7694\n",
      "[04/02/2024 09:08:59 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:08:59 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:08:59 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.19590984746813778\n",
      "[04/02/2024 09:08:59 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:08:59 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:08:59 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:08:59 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7570205330848694 for class 0   \n",
      "[04/02/2024 09:08:59 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:08:59 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:08:59 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.75702053, inf]\n",
      "[04/02/2024 09:09:00 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1247 \n",
      "[04/02/2024 09:09:00 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:09:00 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : =============================== END Epoch 32 =======================\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9655172413793104, 'coverage_1': 0.155875, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7694\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : cur_query_count= 306 and max_query_count=1000\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 33 ============================\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : Number of unalabeled points  :7694\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : Current Available Query Budget: 694\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:00 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:00 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7686\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : Training data size : 1561\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1553}\n",
      "[04/02/2024 09:09:00 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:00 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:00 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1561}\n",
      "[04/02/2024 09:09:00 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:00 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:00 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4388 , Training Loss : 0.0112\n",
      "[04/02/2024 09:09:00 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1236 , Training Loss : 0.0053\n",
      "[04/02/2024 09:09:00 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1243 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:01 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1268 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:01 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1268 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:01 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:01 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:01 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:01 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:01 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:02 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:02 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:02 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1275 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:02 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:02 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1275 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:02 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1275 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:03 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1275 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:03 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1275 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:03 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1275 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:03 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1275 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:03 PM : DEBUG : model_trai : ] : Average training loss : 0.0046493557484727915\n",
      "[04/02/2024 09:09:03 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:03 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:03 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.522\n",
      "[04/02/2024 09:09:03 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.522\n",
      "[04/02/2024 09:09:03 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:03 PM : INFO  : self_train : ] : Training error of trained model : 12.30\n",
      "[04/02/2024 09:09:03 PM : INFO  : self_train : ] : Test error of the model         : 51.50\n",
      "[04/02/2024 09:09:03 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:03 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:03 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:03 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:03 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:03 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:04 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7686\n",
      "[04/02/2024 09:09:04 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:04 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.15360777604579925\n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:04 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:04 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7126280069351196 for class 0   \n",
      "[04/02/2024 09:09:04 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:04 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1575\n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.712628, inf]\n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1175 \n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 315\n",
      "[04/02/2024 09:09:04 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : =============================== END Epoch 33 =======================\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.985531914893617, 'coverage_1': 0.146875, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7686\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : cur_query_count= 314 and max_query_count=1000\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 34 ============================\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : Number of unalabeled points  :7686\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : Current Available Query Budget: 686\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:04 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:04 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7678\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : Training data size : 1497\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1561}\n",
      "[04/02/2024 09:09:04 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:04 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:04 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1497}\n",
      "[04/02/2024 09:09:04 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:04 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:04 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4636 , Training Loss : 0.0115\n",
      "[04/02/2024 09:09:04 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1122 , Training Loss : 0.0053\n",
      "[04/02/2024 09:09:04 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1102 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:05 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1136 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:05 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1156 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:05 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1156 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:05 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1156 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:05 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1156 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:05 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1156 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:05 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1162 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:06 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1162 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:06 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1162 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:06 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1162 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:06 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1162 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:06 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1162 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:06 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1162 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:07 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1162 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:07 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1162 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:07 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1162 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:07 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1162 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:07 PM : DEBUG : model_trai : ] : Average training loss : 0.004660663070736577\n",
      "[04/02/2024 09:09:07 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:07 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:07 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5215\n",
      "[04/02/2024 09:09:07 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5215\n",
      "[04/02/2024 09:09:07 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:07 PM : INFO  : self_train : ] : Training error of trained model : 11.36\n",
      "[04/02/2024 09:09:07 PM : INFO  : self_train : ] : Test error of the model         : 51.40\n",
      "[04/02/2024 09:09:07 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:07 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:07 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:07 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:07 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:07 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:07 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:07 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:07 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7678\n",
      "[04/02/2024 09:09:07 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:07 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:07 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2568663283884525\n",
      "[04/02/2024 09:09:07 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:07 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:07 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:07 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8430764079093933 for class 0   \n",
      "[04/02/2024 09:09:08 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:08 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1575\n",
      "[04/02/2024 09:09:08 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8430764, inf]\n",
      "[04/02/2024 09:09:08 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1177 \n",
      "[04/02/2024 09:09:08 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 315\n",
      "[04/02/2024 09:09:08 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : =============================== END Epoch 34 =======================\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9855564995751912, 'coverage_1': 0.147125, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7678\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : cur_query_count= 322 and max_query_count=1000\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 35 ============================\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : Number of unalabeled points  :7678\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : Current Available Query Budget: 678\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:08 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:08 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7670\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : Training data size : 1507\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1497}\n",
      "[04/02/2024 09:09:08 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:08 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:08 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1507}\n",
      "[04/02/2024 09:09:08 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:08 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:08 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2940 , Training Loss : 0.0092\n",
      "[04/02/2024 09:09:08 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1121 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:08 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1135 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:08 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1168 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:09 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1175 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:09 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1188 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:09 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1188 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:09 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1188 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:09 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1188 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:09 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:10 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:10 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:10 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:10 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:10 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:10 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:11 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:11 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:11 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:11 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1194 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:11 PM : DEBUG : model_trai : ] : Average training loss : 0.004562811148919272\n",
      "[04/02/2024 09:09:11 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:11 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:11 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5205\n",
      "[04/02/2024 09:09:11 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5205\n",
      "[04/02/2024 09:09:11 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:11 PM : INFO  : self_train : ] : Training error of trained model : 11.88\n",
      "[04/02/2024 09:09:11 PM : INFO  : self_train : ] : Test error of the model         : 51.60\n",
      "[04/02/2024 09:09:11 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:11 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:11 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:11 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:11 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:11 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:11 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:11 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:11 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7670\n",
      "[04/02/2024 09:09:12 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:12 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:12 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27090920513868333\n",
      "[04/02/2024 09:09:12 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:12 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:12 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:12 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8616237640380859 for class 0   \n",
      "[04/02/2024 09:09:12 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:12 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:09:12 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.86162376, inf]\n",
      "[04/02/2024 09:09:12 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1201 \n",
      "[04/02/2024 09:09:12 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:09:12 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : =============================== END Epoch 35 =======================\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9833472106577852, 'coverage_1': 0.150125, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7670\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : cur_query_count= 330 and max_query_count=1000\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 36 ============================\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : Number of unalabeled points  :7670\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : Current Available Query Budget: 670\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:12 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:12 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7662\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : Training data size : 1539\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1507}\n",
      "[04/02/2024 09:09:12 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:12 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:12 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1539}\n",
      "[04/02/2024 09:09:12 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:12 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:12 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1222 , Training Loss : 0.0064\n",
      "[04/02/2024 09:09:12 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1222 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:12 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1222 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:13 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1222 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:13 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1222 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:13 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1222 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:13 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1222 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:13 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:13 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:14 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1228 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:14 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:14 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:14 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:14 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1228 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:14 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:15 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:15 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:15 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:15 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1228 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:15 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1222 , Training Loss : 0.0044\n",
      "[04/02/2024 09:09:15 PM : DEBUG : model_trai : ] : Average training loss : 0.00439255902663368\n",
      "[04/02/2024 09:09:15 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:15 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:15 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:09:15 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:09:15 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : Training error of trained model : 12.22\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : Test error of the model         : 50.90\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:16 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7662\n",
      "[04/02/2024 09:09:16 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:16 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.24621245217323304\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:16 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:16 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8206364512443542 for class 0   \n",
      "[04/02/2024 09:09:16 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:16 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.158\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.82063645, inf]\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1233 \n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 316\n",
      "[04/02/2024 09:09:16 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : =============================== END Epoch 36 =======================\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9724249797242498, 'coverage_1': 0.154125, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7662\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : cur_query_count= 338 and max_query_count=1000\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 37 ============================\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : Number of unalabeled points  :7662\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : Current Available Query Budget: 662\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:16 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:16 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7654\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : Training data size : 1579\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1539}\n",
      "[04/02/2024 09:09:16 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:16 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:16 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1579}\n",
      "[04/02/2024 09:09:16 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:16 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:16 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1374 , Training Loss : 0.0066\n",
      "[04/02/2024 09:09:16 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1273 , Training Loss : 0.0052\n",
      "[04/02/2024 09:09:17 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1286 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:17 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1298 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:17 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1311 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:17 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1317 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:17 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1311 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:17 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1317 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:17 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1324 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:18 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1324 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:18 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1317 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:18 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1317 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:18 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1317 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:18 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1317 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:18 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1324 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:18 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1324 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:19 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1330 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:19 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1330 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:19 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1330 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:19 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1330 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:19 PM : DEBUG : model_trai : ] : Average training loss : 0.004539032866802805\n",
      "[04/02/2024 09:09:19 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:19 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:19 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5195\n",
      "[04/02/2024 09:09:19 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5195\n",
      "[04/02/2024 09:09:19 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:19 PM : INFO  : self_train : ] : Training error of trained model : 12.92\n",
      "[04/02/2024 09:09:19 PM : INFO  : self_train : ] : Test error of the model         : 51.60\n",
      "[04/02/2024 09:09:19 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:19 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:19 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:19 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:19 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:19 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:19 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:19 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:19 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7654\n",
      "[04/02/2024 09:09:19 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:19 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:20 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.24077098429203034\n",
      "[04/02/2024 09:09:20 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:20 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:20 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:20 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8212259411811829 for class 0   \n",
      "[04/02/2024 09:09:20 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:20 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:09:20 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.82122594, inf]\n",
      "[04/02/2024 09:09:20 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1196 \n",
      "[04/02/2024 09:09:20 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:09:20 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : =============================== END Epoch 37 =======================\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9841137123745819, 'coverage_1': 0.1495, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7654\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : cur_query_count= 346 and max_query_count=1000\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 38 ============================\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : Number of unalabeled points  :7654\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : Current Available Query Budget: 654\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:20 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:20 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7646\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : Training data size : 1550\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1579}\n",
      "[04/02/2024 09:09:20 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:20 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:20 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1550}\n",
      "[04/02/2024 09:09:20 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:20 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:20 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5535 , Training Loss : 0.0133\n",
      "[04/02/2024 09:09:20 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1277 , Training Loss : 0.0053\n",
      "[04/02/2024 09:09:20 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1271 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:20 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1271 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:21 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1271 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:21 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1271 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:21 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1271 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:21 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1271 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:21 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1277 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:21 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1271 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:22 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1277 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:22 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1277 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:22 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1277 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:22 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1277 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:22 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1277 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:22 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1277 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:22 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1277 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:23 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1277 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:23 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1277 , Training Loss : 0.0046\n",
      "[04/02/2024 09:09:23 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1277 , Training Loss : 0.0045\n",
      "[04/02/2024 09:09:23 PM : DEBUG : model_trai : ] : Average training loss : 0.004809881187345943\n",
      "[04/02/2024 09:09:23 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:23 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:23 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:09:23 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:09:23 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:23 PM : INFO  : self_train : ] : Training error of trained model : 12.71\n",
      "[04/02/2024 09:09:23 PM : INFO  : self_train : ] : Test error of the model         : 50.55\n",
      "[04/02/2024 09:09:23 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:23 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:23 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:23 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:23 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:23 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:23 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:23 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:23 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7646\n",
      "[04/02/2024 09:09:23 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:23 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:23 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2770931126475334\n",
      "[04/02/2024 09:09:23 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:23 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:23 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:23 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8592332005500793 for class 0   \n",
      "[04/02/2024 09:09:24 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:24 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:09:24 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8592332, inf]\n",
      "[04/02/2024 09:09:24 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1242 \n",
      "[04/02/2024 09:09:24 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:09:24 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : =============================== END Epoch 38 =======================\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9694041867954911, 'coverage_1': 0.15525, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7646\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : cur_query_count= 354 and max_query_count=1000\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 39 ============================\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : Number of unalabeled points  :7646\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : Current Available Query Budget: 646\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:24 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:24 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7638\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : Training data size : 1604\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1550}\n",
      "[04/02/2024 09:09:24 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:24 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:24 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1604}\n",
      "[04/02/2024 09:09:24 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:24 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:24 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1421 , Training Loss : 0.0058\n",
      "[04/02/2024 09:09:24 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1409 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:24 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1415 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:24 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1421 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:25 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1428 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:25 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1421 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:25 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1415 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:25 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1390 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:25 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1397 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:26 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1415 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:26 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1421 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:26 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1397 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:26 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1384 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:26 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1428 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:26 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1415 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:26 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1428 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:27 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1421 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:27 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1415 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:27 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1421 , Training Loss : 0.0047\n",
      "[04/02/2024 09:09:27 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1415 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:27 PM : DEBUG : model_trai : ] : Average training loss : 0.004642698640199994\n",
      "[04/02/2024 09:09:27 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:27 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:27 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.518\n",
      "[04/02/2024 09:09:27 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.518\n",
      "[04/02/2024 09:09:27 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:27 PM : INFO  : self_train : ] : Training error of trained model : 14.28\n",
      "[04/02/2024 09:09:27 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:09:27 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:27 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:27 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:27 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:27 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:27 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:27 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:27 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:27 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7638\n",
      "[04/02/2024 09:09:27 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:27 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:27 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2756190993785858\n",
      "[04/02/2024 09:09:27 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:27 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:27 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:28 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8617925047874451 for class 0   \n",
      "[04/02/2024 09:09:28 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:28 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:09:28 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8617925, inf]\n",
      "[04/02/2024 09:09:28 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1247 \n",
      "[04/02/2024 09:09:28 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:09:28 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : =============================== END Epoch 39 =======================\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9655172413793104, 'coverage_1': 0.155875, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7638\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : cur_query_count= 362 and max_query_count=1000\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 40 ============================\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : Number of unalabeled points  :7638\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : Current Available Query Budget: 638\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:28 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:28 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7630\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : Training data size : 1617\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1604}\n",
      "[04/02/2024 09:09:28 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:28 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:28 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1617}\n",
      "[04/02/2024 09:09:28 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:28 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:28 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1515 , Training Loss : 0.0062\n",
      "[04/02/2024 09:09:28 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1459 , Training Loss : 0.0052\n",
      "[04/02/2024 09:09:28 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:28 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1453 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:29 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:29 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:29 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1447 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:29 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1453 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:29 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:29 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1453 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:30 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:30 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:30 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1453 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:30 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1453 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:30 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:30 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:31 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1453 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:31 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1453 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:31 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1453 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:31 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1453 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:31 PM : DEBUG : model_trai : ] : Average training loss : 0.0047086567609478025\n",
      "[04/02/2024 09:09:31 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:31 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:31 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.513\n",
      "[04/02/2024 09:09:31 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.513\n",
      "[04/02/2024 09:09:31 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:31 PM : INFO  : self_train : ] : Training error of trained model : 14.53\n",
      "[04/02/2024 09:09:31 PM : INFO  : self_train : ] : Test error of the model         : 50.85\n",
      "[04/02/2024 09:09:31 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:31 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:31 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:31 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:31 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:31 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:31 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:31 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7630\n",
      "[04/02/2024 09:09:31 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:31 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:32 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.21634672173857689\n",
      "[04/02/2024 09:09:32 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:32 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:32 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:32 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7783837914466858 for class 0   \n",
      "[04/02/2024 09:09:32 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:32 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:09:32 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7783838, inf]\n",
      "[04/02/2024 09:09:32 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1264 \n",
      "[04/02/2024 09:09:32 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:09:32 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : =============================== END Epoch 40 =======================\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9588607594936709, 'coverage_1': 0.158, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7630\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : cur_query_count= 370 and max_query_count=1000\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 41 ============================\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : Number of unalabeled points  :7630\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : Current Available Query Budget: 630\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:32 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:32 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7622\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : Training data size : 1642\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1617}\n",
      "[04/02/2024 09:09:32 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:32 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:32 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1642}\n",
      "[04/02/2024 09:09:32 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:32 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:32 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2576 , Training Loss : 0.0083\n",
      "[04/02/2024 09:09:32 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1553 , Training Loss : 0.0054\n",
      "[04/02/2024 09:09:32 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1523 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:33 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1510 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:33 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1510 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:33 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:33 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:33 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:33 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1498 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:34 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:34 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:34 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:34 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1498 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:34 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1498 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:34 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1498 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:34 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1498 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:35 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1510 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:35 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:35 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:35 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1498 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:35 PM : DEBUG : model_trai : ] : Average training loss : 0.004854307712363806\n",
      "[04/02/2024 09:09:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:35 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:09:35 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:09:35 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:35 PM : INFO  : self_train : ] : Training error of trained model : 15.10\n",
      "[04/02/2024 09:09:35 PM : INFO  : self_train : ] : Test error of the model         : 50.85\n",
      "[04/02/2024 09:09:35 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:35 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:35 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:35 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:35 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:35 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:35 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:35 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:35 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7622\n",
      "[04/02/2024 09:09:36 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:36 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:36 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2655965981781483\n",
      "[04/02/2024 09:09:36 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:36 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:36 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:36 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8470738530158997 for class 0   \n",
      "[04/02/2024 09:09:36 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:36 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:09:36 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.84707385, inf]\n",
      "[04/02/2024 09:09:36 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1263 \n",
      "[04/02/2024 09:09:36 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:09:36 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : =============================== END Epoch 41 =======================\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9612034837688044, 'coverage_1': 0.157875, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7622\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : cur_query_count= 378 and max_query_count=1000\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 42 ============================\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : Number of unalabeled points  :7622\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : Current Available Query Budget: 622\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:36 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:36 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7614\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : Training data size : 1649\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1642}\n",
      "[04/02/2024 09:09:36 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:36 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:36 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1649}\n",
      "[04/02/2024 09:09:36 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:36 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:36 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1504 , Training Loss : 0.0071\n",
      "[04/02/2024 09:09:36 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1504 , Training Loss : 0.0053\n",
      "[04/02/2024 09:09:36 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:37 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:37 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:37 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:37 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1510 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:37 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1504 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:37 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1510 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:38 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:38 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:38 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1504 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:38 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:38 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1510 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:38 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1504 , Training Loss : 0.0048\n",
      "[04/02/2024 09:09:39 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:39 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:39 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:39 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:39 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1504 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:39 PM : DEBUG : model_trai : ] : Average training loss : 0.004760817753156382\n",
      "[04/02/2024 09:09:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:39 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5135\n",
      "[04/02/2024 09:09:39 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5135\n",
      "[04/02/2024 09:09:39 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : Training error of trained model : 14.98\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : Test error of the model         : 50.80\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:40 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7614\n",
      "[04/02/2024 09:09:40 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:40 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2392302960753441\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:40 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8090444207191467 for class 0   \n",
      "[04/02/2024 09:09:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:40 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8090444, inf]\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1266 \n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:09:40 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : =============================== END Epoch 42 =======================\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9581358609794629, 'coverage_1': 0.15825, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7614\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : cur_query_count= 386 and max_query_count=1000\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 43 ============================\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : Number of unalabeled points  :7614\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : Current Available Query Budget: 614\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:40 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:40 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7606\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : Training data size : 1660\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1649}\n",
      "[04/02/2024 09:09:40 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:40 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:40 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1660}\n",
      "[04/02/2024 09:09:40 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:40 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:40 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2500 , Training Loss : 0.0085\n",
      "[04/02/2024 09:09:40 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1536 , Training Loss : 0.0054\n",
      "[04/02/2024 09:09:41 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1524 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:41 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1530 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:41 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1518 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:41 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:41 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:41 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:42 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1518 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:42 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:42 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1530 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:42 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:42 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:42 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1518 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:43 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:43 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:43 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1530 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:43 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1530 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:43 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1524 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:43 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1518 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:44 PM : DEBUG : model_trai : ] : Average training loss : 0.004885364546132237\n",
      "[04/02/2024 09:09:44 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:44 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:44 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:09:44 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : Training error of trained model : 15.36\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : Test error of the model         : 50.80\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:44 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7606\n",
      "[04/02/2024 09:09:44 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:44 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2362185934782028\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:44 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:44 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8076488971710205 for class 0   \n",
      "[04/02/2024 09:09:44 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:44 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8076489, inf]\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1266 \n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:09:44 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : =============================== END Epoch 43 =======================\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9597156398104265, 'coverage_1': 0.15825, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7606\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : cur_query_count= 394 and max_query_count=1000\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 44 ============================\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : Number of unalabeled points  :7606\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : Current Available Query Budget: 606\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:44 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:44 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7598\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : Training data size : 1668\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1660}\n",
      "[04/02/2024 09:09:44 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:44 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:44 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1668}\n",
      "[04/02/2024 09:09:44 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:44 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:44 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1601 , Training Loss : 0.0078\n",
      "[04/02/2024 09:09:45 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1559 , Training Loss : 0.0057\n",
      "[04/02/2024 09:09:45 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1547 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:45 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1541 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:45 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1535 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:45 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:45 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1523 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:46 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1535 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:46 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1535 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:46 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1541 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:46 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1541 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:46 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:46 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1541 , Training Loss : 0.0052\n",
      "[04/02/2024 09:09:47 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1547 , Training Loss : 0.0056\n",
      "[04/02/2024 09:09:47 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:47 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1529 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:47 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1535 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:47 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1523 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:47 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1523 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:48 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1529 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:48 PM : DEBUG : model_trai : ] : Average training loss : 0.0049882804094533535\n",
      "[04/02/2024 09:09:48 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:48 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:48 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5155\n",
      "[04/02/2024 09:09:48 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5155\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : Training error of trained model : 15.41\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : Test error of the model         : 50.90\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:48 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7598\n",
      "[04/02/2024 09:09:48 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:48 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27761009061336517\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:48 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8634731769561768 for class 0   \n",
      "[04/02/2024 09:09:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:48 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8634732, inf]\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1264 \n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:09:48 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : =============================== END Epoch 44 =======================\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9604430379746836, 'coverage_1': 0.158, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7598\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : cur_query_count= 402 and max_query_count=1000\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 45 ============================\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : Number of unalabeled points  :7598\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : Current Available Query Budget: 598\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:48 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:48 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7590\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : Training data size : 1674\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1668}\n",
      "[04/02/2024 09:09:48 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:48 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:48 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1674}\n",
      "[04/02/2024 09:09:48 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:48 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:49 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4797 , Training Loss : 0.0116\n",
      "[04/02/2024 09:09:49 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1577 , Training Loss : 0.0056\n",
      "[04/02/2024 09:09:49 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1577 , Training Loss : 0.0052\n",
      "[04/02/2024 09:09:49 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1535 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:49 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1553 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:49 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1535 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:50 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1553 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:50 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1541 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:50 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1547 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:50 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1547 , Training Loss : 0.0052\n",
      "[04/02/2024 09:09:50 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1559 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:50 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1547 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:51 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1547 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:51 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1547 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:51 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1559 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:51 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1547 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:51 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1535 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:51 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1535 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:52 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1541 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:52 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:52 PM : DEBUG : model_trai : ] : Average training loss : 0.005154358357345379\n",
      "[04/02/2024 09:09:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:52 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5155\n",
      "[04/02/2024 09:09:52 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5155\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : Training error of trained model : 15.47\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : Test error of the model         : 50.85\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:52 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7590\n",
      "[04/02/2024 09:09:52 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:52 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27677429339289666\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:52 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.862521767616272 for class 0   \n",
      "[04/02/2024 09:09:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:52 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.86252177, inf]\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1263 \n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:09:52 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:52 PM : DEBUG : self_train : ] : =============================== END Epoch 45 =======================\n",
      "[04/02/2024 09:09:52 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9619952494061758, 'coverage_1': 0.157875, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7590\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : cur_query_count= 410 and max_query_count=1000\n",
      "[04/02/2024 09:09:53 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 46 ============================\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : Number of unalabeled points  :7590\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : Current Available Query Budget: 590\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:53 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:53 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:53 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7582\n",
      "[04/02/2024 09:09:53 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:53 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:53 PM : INFO  : self_train : ] : Training data size : 1681\n",
      "[04/02/2024 09:09:53 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:53 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1674}\n",
      "[04/02/2024 09:09:53 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:53 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:53 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1681}\n",
      "[04/02/2024 09:09:53 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:53 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:53 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1588 , Training Loss : 0.0057\n",
      "[04/02/2024 09:09:53 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1582 , Training Loss : 0.0053\n",
      "[04/02/2024 09:09:53 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1559 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:53 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:53 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1547 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:54 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:54 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1523 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:54 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:54 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1523 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:54 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1529 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:54 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:55 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1523 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:55 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1529 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:55 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1529 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:55 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1535 , Training Loss : 0.0049\n",
      "[04/02/2024 09:09:55 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:55 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1535 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:55 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1547 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:56 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1535 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:56 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1523 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:56 PM : DEBUG : model_trai : ] : Average training loss : 0.004855919001752577\n",
      "[04/02/2024 09:09:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:09:56 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5155\n",
      "[04/02/2024 09:09:56 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5155\n",
      "[04/02/2024 09:09:56 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:09:56 PM : INFO  : self_train : ] : Training error of trained model : 15.47\n",
      "[04/02/2024 09:09:56 PM : INFO  : self_train : ] : Test error of the model         : 50.90\n",
      "[04/02/2024 09:09:56 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:09:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:56 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:09:56 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:09:56 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:09:56 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:09:56 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:09:56 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:09:56 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7582\n",
      "[04/02/2024 09:09:56 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:09:56 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:09:56 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27832935854792595\n",
      "[04/02/2024 09:09:56 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:09:56 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:09:56 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:09:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8644164204597473 for class 0   \n",
      "[04/02/2024 09:09:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:09:56 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:09:56 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8644164, inf]\n",
      "[04/02/2024 09:09:57 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1264 \n",
      "[04/02/2024 09:09:57 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:09:57 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : =============================== END Epoch 46 =======================\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9604430379746836, 'coverage_1': 0.158, 'coverage_2': 0}\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7582\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : cur_query_count= 418 and max_query_count=1000\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 47 ============================\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : Number of unalabeled points  :7582\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : Current Available Query Budget: 582\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:09:57 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:09:57 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7574\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : Training data size : 1690\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1681}\n",
      "[04/02/2024 09:09:57 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:57 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:09:57 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1690}\n",
      "[04/02/2024 09:09:57 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:09:57 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:09:57 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4432 , Training Loss : 0.0107\n",
      "[04/02/2024 09:09:57 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1663 , Training Loss : 0.0057\n",
      "[04/02/2024 09:09:57 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1621 , Training Loss : 0.0052\n",
      "[04/02/2024 09:09:57 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1580 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:57 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1556 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:58 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1550 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:58 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1556 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:58 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1550 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:58 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1568 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:58 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1538 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:58 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1550 , Training Loss : 0.0050\n",
      "[04/02/2024 09:09:59 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1556 , Training Loss : 0.0052\n",
      "[04/02/2024 09:09:59 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1568 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:59 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1574 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:59 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1562 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:59 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1574 , Training Loss : 0.0051\n",
      "[04/02/2024 09:09:59 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1574 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:00 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1562 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:00 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1562 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:00 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1574 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:00 PM : DEBUG : model_trai : ] : Average training loss : 0.00514085481589396\n",
      "[04/02/2024 09:10:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:00 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5165\n",
      "[04/02/2024 09:10:00 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5165\n",
      "[04/02/2024 09:10:00 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:00 PM : INFO  : self_train : ] : Training error of trained model : 16.39\n",
      "[04/02/2024 09:10:00 PM : INFO  : self_train : ] : Test error of the model         : 51.30\n",
      "[04/02/2024 09:10:00 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:00 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:00 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:00 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:00 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:00 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:00 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:00 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:00 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7574\n",
      "[04/02/2024 09:10:00 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:00 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:00 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.14886851194500925\n",
      "[04/02/2024 09:10:00 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:00 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:00 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:00 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.700564444065094 for class 0   \n",
      "[04/02/2024 09:10:00 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:00 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1565\n",
      "[04/02/2024 09:10:00 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.70056444, inf]\n",
      "[04/02/2024 09:10:01 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1260 \n",
      "[04/02/2024 09:10:01 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 313\n",
      "[04/02/2024 09:10:01 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : =============================== END Epoch 47 =======================\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9722222222222222, 'coverage_1': 0.1575, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7574\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : cur_query_count= 426 and max_query_count=1000\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 48 ============================\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : Number of unalabeled points  :7574\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : Current Available Query Budget: 574\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:01 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:01 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7566\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : Training data size : 1694\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1690}\n",
      "[04/02/2024 09:10:01 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:01 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:01 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1694}\n",
      "[04/02/2024 09:10:01 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:01 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:01 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1558 , Training Loss : 0.0062\n",
      "[04/02/2024 09:10:01 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1541 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:01 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1570 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:01 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1576 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:01 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1623 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:02 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1600 , Training Loss : 0.0048\n",
      "[04/02/2024 09:10:02 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1594 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:02 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1612 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:02 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1600 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:02 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1594 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:02 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1600 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:03 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1594 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:03 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1588 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:03 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1582 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:03 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1594 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:03 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1594 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:03 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1582 , Training Loss : 0.0048\n",
      "[04/02/2024 09:10:04 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1588 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:04 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1576 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:04 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1588 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:04 PM : DEBUG : model_trai : ] : Average training loss : 0.004735544886474177\n",
      "[04/02/2024 09:10:04 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:04 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:04 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.517\n",
      "[04/02/2024 09:10:04 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.517\n",
      "[04/02/2024 09:10:04 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:04 PM : INFO  : self_train : ] : Training error of trained model : 15.58\n",
      "[04/02/2024 09:10:04 PM : INFO  : self_train : ] : Test error of the model         : 51.35\n",
      "[04/02/2024 09:10:04 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:04 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:04 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:04 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:04 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:04 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:04 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:04 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:04 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7566\n",
      "[04/02/2024 09:10:04 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:04 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:04 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2397607724070549\n",
      "[04/02/2024 09:10:04 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:04 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:04 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:04 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.819332480430603 for class 0   \n",
      "[04/02/2024 09:10:04 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:04 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1575\n",
      "[04/02/2024 09:10:04 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8193325, inf]\n",
      "[04/02/2024 09:10:05 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1267 \n",
      "[04/02/2024 09:10:05 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 315\n",
      "[04/02/2024 09:10:05 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : =============================== END Epoch 48 =======================\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9684293606945541, 'coverage_1': 0.158375, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7566\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : cur_query_count= 434 and max_query_count=1000\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 49 ============================\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : Number of unalabeled points  :7566\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : Current Available Query Budget: 566\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:05 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:05 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7558\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : Training data size : 1709\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1694}\n",
      "[04/02/2024 09:10:05 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:05 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:05 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1709}\n",
      "[04/02/2024 09:10:05 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:05 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:05 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3218 , Training Loss : 0.0092\n",
      "[04/02/2024 09:10:05 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1556 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:05 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1615 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:05 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1627 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:05 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1627 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:06 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1638 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:06 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1615 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:06 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1609 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:06 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1615 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:06 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1615 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:07 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1592 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:07 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1586 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:07 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1609 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:07 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1597 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:07 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1592 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:07 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1615 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:08 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1609 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:08 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1597 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:08 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1592 , Training Loss : 0.0049\n",
      "[04/02/2024 09:10:08 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1586 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:08 PM : DEBUG : model_trai : ] : Average training loss : 0.004937563578443875\n",
      "[04/02/2024 09:10:08 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:08 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:08 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:10:08 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:10:08 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:08 PM : INFO  : self_train : ] : Training error of trained model : 15.74\n",
      "[04/02/2024 09:10:08 PM : INFO  : self_train : ] : Test error of the model         : 51.05\n",
      "[04/02/2024 09:10:08 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:08 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:08 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:08 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:08 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:08 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:08 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:08 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:08 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7558\n",
      "[04/02/2024 09:10:08 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:08 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:08 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.24083046165108682\n",
      "[04/02/2024 09:10:08 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:08 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:09 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:09 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8147614002227783 for class 0   \n",
      "[04/02/2024 09:10:09 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:09 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.158\n",
      "[04/02/2024 09:10:09 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8147614, inf]\n",
      "[04/02/2024 09:10:09 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1265 \n",
      "[04/02/2024 09:10:09 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 316\n",
      "[04/02/2024 09:10:09 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : =============================== END Epoch 49 =======================\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9604743083003953, 'coverage_1': 0.158125, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7558\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : cur_query_count= 442 and max_query_count=1000\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 50 ============================\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : Number of unalabeled points  :7558\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : Current Available Query Budget: 558\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:09 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:09 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7550\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : Training data size : 1715\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1709}\n",
      "[04/02/2024 09:10:09 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:09 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:09 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1715}\n",
      "[04/02/2024 09:10:09 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:09 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:09 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1650 , Training Loss : 0.0068\n",
      "[04/02/2024 09:10:09 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1609 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:09 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1569 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:09 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1598 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:10 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1609 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:10 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1627 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:10 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1627 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:10 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1638 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:10 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1621 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:10 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1627 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:11 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1638 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:11 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1633 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:11 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1638 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:11 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1633 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:11 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1621 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:11 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1627 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:12 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1627 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:12 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1644 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:12 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1633 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:12 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1627 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:12 PM : DEBUG : model_trai : ] : Average training loss : 0.004949733722082495\n",
      "[04/02/2024 09:10:12 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:12 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:12 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5155\n",
      "[04/02/2024 09:10:12 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5155\n",
      "[04/02/2024 09:10:12 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:12 PM : INFO  : self_train : ] : Training error of trained model : 16.03\n",
      "[04/02/2024 09:10:12 PM : INFO  : self_train : ] : Test error of the model         : 50.85\n",
      "[04/02/2024 09:10:12 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:12 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:12 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:12 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:12 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:12 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:12 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:12 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:12 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7550\n",
      "[04/02/2024 09:10:12 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:12 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:13 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2663829976916313\n",
      "[04/02/2024 09:10:13 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:13 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:13 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:13 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8484303951263428 for class 0   \n",
      "[04/02/2024 09:10:13 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:13 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:10:13 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8484304, inf]\n",
      "[04/02/2024 09:10:13 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1266 \n",
      "[04/02/2024 09:10:13 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:10:13 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : =============================== END Epoch 50 =======================\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9597156398104265, 'coverage_1': 0.15825, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7550\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : cur_query_count= 450 and max_query_count=1000\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 51 ============================\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : Number of unalabeled points  :7550\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : Current Available Query Budget: 550\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:13 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:13 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7542\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : Training data size : 1724\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1715}\n",
      "[04/02/2024 09:10:13 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:13 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:13 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1724}\n",
      "[04/02/2024 09:10:13 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:13 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:13 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1937 , Training Loss : 0.0074\n",
      "[04/02/2024 09:10:13 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1700 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:13 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1676 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:14 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1630 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:14 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1607 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:14 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1601 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:14 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1595 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:14 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1607 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:14 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1595 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:15 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1595 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:15 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1589 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:15 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1578 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:15 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1601 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:15 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1589 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:15 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1601 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:16 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1601 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:16 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1595 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:16 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1607 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:16 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1584 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:16 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1589 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:16 PM : DEBUG : model_trai : ] : Average training loss : 0.004988931391913776\n",
      "[04/02/2024 09:10:16 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:16 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:16 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:10:16 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:10:16 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : Training error of trained model : 16.94\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : Test error of the model         : 51.10\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:17 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7542\n",
      "[04/02/2024 09:10:17 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:17 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.18078787571191784\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:17 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:17 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7384006381034851 for class 0   \n",
      "[04/02/2024 09:10:17 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:17 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1585\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.73840064, inf]\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1263 \n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 317\n",
      "[04/02/2024 09:10:17 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : =============================== END Epoch 51 =======================\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9683293745051464, 'coverage_1': 0.157875, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7542\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : cur_query_count= 458 and max_query_count=1000\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 52 ============================\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : Number of unalabeled points  :7542\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : Current Available Query Budget: 542\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:17 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:17 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7534\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : Training data size : 1729\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1724}\n",
      "[04/02/2024 09:10:17 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:17 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:17 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1729}\n",
      "[04/02/2024 09:10:17 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:17 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:17 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1579 , Training Loss : 0.0069\n",
      "[04/02/2024 09:10:17 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1695 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:18 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1677 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:18 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1683 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:18 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1689 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:18 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1683 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:18 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1683 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:18 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1689 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:19 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1654 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:19 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1637 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:19 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1631 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:19 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1637 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:19 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1637 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:19 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1637 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:20 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1631 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:20 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1637 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:20 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1631 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:20 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1637 , Training Loss : 0.0050\n",
      "[04/02/2024 09:10:20 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1631 , Training Loss : 0.0062\n",
      "[04/02/2024 09:10:20 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1637 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:20 PM : DEBUG : model_trai : ] : Average training loss : 0.005005930087184721\n",
      "[04/02/2024 09:10:20 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:20 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:21 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:10:21 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : Training error of trained model : 16.43\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : Test error of the model         : 51.25\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:21 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7534\n",
      "[04/02/2024 09:10:21 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:21 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.28486616450548174\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:21 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:21 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8725433945655823 for class 0   \n",
      "[04/02/2024 09:10:21 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:21 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8725434, inf]\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1268 \n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:10:21 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : =============================== END Epoch 52 =======================\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9629337539432177, 'coverage_1': 0.1585, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7534\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : cur_query_count= 466 and max_query_count=1000\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 53 ============================\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : Number of unalabeled points  :7534\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : Current Available Query Budget: 534\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:21 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:21 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7526\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : Training data size : 1742\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1729}\n",
      "[04/02/2024 09:10:21 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:21 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:21 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1742}\n",
      "[04/02/2024 09:10:21 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:21 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:21 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3278 , Training Loss : 0.0094\n",
      "[04/02/2024 09:10:22 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1630 , Training Loss : 0.0058\n",
      "[04/02/2024 09:10:22 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1607 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:22 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1670 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:22 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1676 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:22 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1682 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:22 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1676 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:23 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1676 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:23 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1676 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:23 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1682 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:23 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1682 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:23 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1682 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:23 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1682 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:24 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1676 , Training Loss : 0.0051\n",
      "[04/02/2024 09:10:24 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1682 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:24 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1682 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:24 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1682 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:24 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1682 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:24 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1682 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:25 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1676 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:25 PM : DEBUG : model_trai : ] : Average training loss : 0.005214401095784596\n",
      "[04/02/2024 09:10:25 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:25 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:25 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:10:25 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : Training error of trained model : 16.76\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : Test error of the model         : 50.95\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:25 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7526\n",
      "[04/02/2024 09:10:25 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:25 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2704610733985901\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:25 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:25 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8508710265159607 for class 0   \n",
      "[04/02/2024 09:10:25 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:25 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.850871, inf]\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1269 \n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:10:25 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : =============================== END Epoch 53 =======================\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9574468085106383, 'coverage_1': 0.158625, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7526\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : cur_query_count= 474 and max_query_count=1000\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 54 ============================\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : Number of unalabeled points  :7526\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : Current Available Query Budget: 526\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:25 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:25 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7518\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : Training data size : 1751\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1742}\n",
      "[04/02/2024 09:10:25 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:25 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:25 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1751}\n",
      "[04/02/2024 09:10:25 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:25 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:25 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3392 , Training Loss : 0.0096\n",
      "[04/02/2024 09:10:26 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1690 , Training Loss : 0.0059\n",
      "[04/02/2024 09:10:26 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1690 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:26 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1668 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:26 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1679 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:26 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1668 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:27 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1702 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:27 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1668 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:27 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:27 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1679 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:27 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:27 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1668 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:28 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1685 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:28 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1690 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:28 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1685 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:28 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1696 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:28 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1679 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:28 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1673 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:28 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1679 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:29 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1668 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:29 PM : DEBUG : model_trai : ] : Average training loss : 0.005314598608106444\n",
      "[04/02/2024 09:10:29 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:29 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:29 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.516\n",
      "[04/02/2024 09:10:29 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.516\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : Training error of trained model : 16.90\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : Test error of the model         : 50.55\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:29 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7518\n",
      "[04/02/2024 09:10:29 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:29 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1678161241710186\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:29 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:29 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7190226316452026 for class 0   \n",
      "[04/02/2024 09:10:29 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:29 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.71902263, inf]\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1247 \n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:10:29 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:29 PM : DEBUG : self_train : ] : =============================== END Epoch 54 =======================\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9655172413793104, 'coverage_1': 0.155875, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:29 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7518\n",
      "[04/02/2024 09:10:29 PM : DEBUG : self_train : ] : cur_query_count= 482 and max_query_count=1000\n",
      "[04/02/2024 09:10:29 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:29 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 55 ============================\n",
      "[04/02/2024 09:10:29 PM : DEBUG : self_train : ] : Number of unalabeled points  :7518\n",
      "[04/02/2024 09:10:29 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:29 PM : DEBUG : self_train : ] : Current Available Query Budget: 518\n",
      "[04/02/2024 09:10:29 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:29 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:30 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:30 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:30 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7510\n",
      "[04/02/2024 09:10:30 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:30 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:30 PM : INFO  : self_train : ] : Training data size : 1737\n",
      "[04/02/2024 09:10:30 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:30 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1751}\n",
      "[04/02/2024 09:10:30 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:30 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:30 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1737}\n",
      "[04/02/2024 09:10:30 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:30 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:30 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1652 , Training Loss : 0.0081\n",
      "[04/02/2024 09:10:30 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1647 , Training Loss : 0.0057\n",
      "[04/02/2024 09:10:30 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1652 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:30 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1652 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:30 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:31 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1658 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:31 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:31 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:31 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:31 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:31 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:32 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:32 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1658 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:32 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:32 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:32 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:32 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:33 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1658 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:33 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1658 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:33 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1658 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:33 PM : DEBUG : model_trai : ] : Average training loss : 0.005220596545764247\n",
      "[04/02/2024 09:10:33 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:33 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:33 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:10:33 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:10:33 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:33 PM : INFO  : self_train : ] : Training error of trained model : 16.52\n",
      "[04/02/2024 09:10:33 PM : INFO  : self_train : ] : Test error of the model         : 50.45\n",
      "[04/02/2024 09:10:33 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:33 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:33 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:33 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:33 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:33 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:33 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:33 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:33 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7510\n",
      "[04/02/2024 09:10:33 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:33 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:33 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.17539936921000482\n",
      "[04/02/2024 09:10:33 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:33 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:33 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:34 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7260490655899048 for class 0   \n",
      "[04/02/2024 09:10:34 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:34 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.162\n",
      "[04/02/2024 09:10:34 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.72604907, inf]\n",
      "[04/02/2024 09:10:34 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1253 \n",
      "[04/02/2024 09:10:34 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 324\n",
      "[04/02/2024 09:10:34 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : =============================== END Epoch 55 =======================\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9648842777334398, 'coverage_1': 0.156625, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7510\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : cur_query_count= 490 and max_query_count=1000\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 56 ============================\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : Number of unalabeled points  :7510\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : Current Available Query Budget: 510\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:34 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:34 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7502\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : Training data size : 1751\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1737}\n",
      "[04/02/2024 09:10:34 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:34 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:34 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1751}\n",
      "[04/02/2024 09:10:34 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:34 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:34 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5060 , Training Loss : 0.0120\n",
      "[04/02/2024 09:10:34 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1633 , Training Loss : 0.0058\n",
      "[04/02/2024 09:10:34 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:35 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1673 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:35 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1673 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:35 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:35 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:35 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1673 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:35 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1673 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:35 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:36 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:36 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:36 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:36 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:36 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:37 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1673 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:37 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1673 , Training Loss : 0.0052\n",
      "[04/02/2024 09:10:37 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:37 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:37 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1673 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:37 PM : DEBUG : model_trai : ] : Average training loss : 0.005388006833793906\n",
      "[04/02/2024 09:10:37 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:37 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:37 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5125\n",
      "[04/02/2024 09:10:37 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5125\n",
      "[04/02/2024 09:10:37 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : Training error of trained model : 17.08\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : Test error of the model         : 50.90\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:38 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7502\n",
      "[04/02/2024 09:10:38 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:38 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1517485494017601\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:38 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:38 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.6944597363471985 for class 0   \n",
      "[04/02/2024 09:10:38 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:38 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.158\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.69445974, inf]\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1271 \n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 316\n",
      "[04/02/2024 09:10:38 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : =============================== END Epoch 56 =======================\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.957513768686074, 'coverage_1': 0.158875, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7502\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : cur_query_count= 498 and max_query_count=1000\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 57 ============================\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : Number of unalabeled points  :7502\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : Current Available Query Budget: 502\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:38 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:38 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7494\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : Training data size : 1777\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1751}\n",
      "[04/02/2024 09:10:38 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:38 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:38 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1777}\n",
      "[04/02/2024 09:10:38 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:38 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:38 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3793 , Training Loss : 0.0096\n",
      "[04/02/2024 09:10:38 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1761 , Training Loss : 0.0058\n",
      "[04/02/2024 09:10:39 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1756 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:39 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1733 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:39 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1722 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:39 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1728 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:39 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1716 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:39 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1733 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:40 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1722 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:40 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1716 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:40 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1733 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:40 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1739 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:40 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1716 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:40 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1722 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1722 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1722 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1733 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1728 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1722 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1739 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Average training loss : 0.005309601068963102\n",
      "[04/02/2024 09:10:41 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:41 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5155\n",
      "[04/02/2024 09:10:41 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5155\n",
      "[04/02/2024 09:10:41 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : Training error of trained model : 17.28\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : Test error of the model         : 50.90\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:42 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7494\n",
      "[04/02/2024 09:10:42 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:42 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2688167763948441\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:42 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:42 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8517356514930725 for class 0   \n",
      "[04/02/2024 09:10:42 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:42 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.85173565, inf]\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1266 \n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:10:42 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : =============================== END Epoch 57 =======================\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9605055292259084, 'coverage_1': 0.15825, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7494\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : cur_query_count= 506 and max_query_count=1000\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 58 ============================\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : Number of unalabeled points  :7494\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : Current Available Query Budget: 494\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:42 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:42 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7486\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : Training data size : 1780\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1777}\n",
      "[04/02/2024 09:10:42 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:42 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:42 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1780}\n",
      "[04/02/2024 09:10:42 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:42 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:42 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4427 , Training Loss : 0.0105\n",
      "[04/02/2024 09:10:42 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1742 , Training Loss : 0.0058\n",
      "[04/02/2024 09:10:43 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1747 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:43 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1713 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:43 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1713 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:43 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1713 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:43 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1719 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:43 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1713 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:44 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1708 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:44 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1708 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:44 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1725 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:44 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1719 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:44 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1713 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:44 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1697 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:44 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1719 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:45 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1725 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:45 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1719 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:45 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1725 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:45 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1719 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:45 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1691 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:45 PM : DEBUG : model_trai : ] : Average training loss : 0.005314145350819796\n",
      "[04/02/2024 09:10:45 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:45 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:46 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5155\n",
      "[04/02/2024 09:10:46 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5155\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : Training error of trained model : 17.13\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : Test error of the model         : 50.85\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:46 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7486\n",
      "[04/02/2024 09:10:46 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:46 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.25660123220086095\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:46 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:46 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8358947038650513 for class 0   \n",
      "[04/02/2024 09:10:46 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:46 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8358947, inf]\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1263 \n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:10:46 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : =============================== END Epoch 58 =======================\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9619952494061758, 'coverage_1': 0.157875, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7486\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : cur_query_count= 514 and max_query_count=1000\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 59 ============================\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : Number of unalabeled points  :7486\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : Current Available Query Budget: 486\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:46 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:46 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7478\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : Training data size : 1785\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1780}\n",
      "[04/02/2024 09:10:46 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:46 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:46 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1785}\n",
      "[04/02/2024 09:10:46 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:46 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:46 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2078 , Training Loss : 0.0077\n",
      "[04/02/2024 09:10:47 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1748 , Training Loss : 0.0057\n",
      "[04/02/2024 09:10:47 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1748 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:47 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1720 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:47 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1697 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:47 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1703 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:47 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1697 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:48 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1692 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:48 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1692 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:48 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1703 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:48 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1709 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:48 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1703 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:48 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1709 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:49 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1720 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:49 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1714 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:49 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1692 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:49 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1697 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:49 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1686 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:49 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1703 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:50 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1725 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:50 PM : DEBUG : model_trai : ] : Average training loss : 0.005161376975847432\n",
      "[04/02/2024 09:10:50 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:50 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:50 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:10:50 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : Training error of trained model : 17.09\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : Test error of the model         : 50.90\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:50 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7478\n",
      "[04/02/2024 09:10:50 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:50 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.280247028529644\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:50 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:50 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.866206169128418 for class 0   \n",
      "[04/02/2024 09:10:50 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:50 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.86620617, inf]\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1266 \n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:10:50 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : =============================== END Epoch 59 =======================\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9605055292259084, 'coverage_1': 0.15825, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7478\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : cur_query_count= 522 and max_query_count=1000\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 60 ============================\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : Number of unalabeled points  :7478\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : Current Available Query Budget: 478\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:50 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:50 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7470\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : Training data size : 1796\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1785}\n",
      "[04/02/2024 09:10:50 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:50 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:50 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1796}\n",
      "[04/02/2024 09:10:50 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:50 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:50 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2405 , Training Loss : 0.0082\n",
      "[04/02/2024 09:10:51 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1771 , Training Loss : 0.0058\n",
      "[04/02/2024 09:10:51 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1759 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:51 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1759 , Training Loss : 0.0056\n",
      "[04/02/2024 09:10:51 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1715 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:51 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1709 , Training Loss : 0.0057\n",
      "[04/02/2024 09:10:51 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1704 , Training Loss : 0.0060\n",
      "[04/02/2024 09:10:52 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1715 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:52 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1698 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:52 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1715 , Training Loss : 0.0058\n",
      "[04/02/2024 09:10:52 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1720 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:52 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1732 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:52 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1720 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:53 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1715 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:53 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1732 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:53 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1715 , Training Loss : 0.0057\n",
      "[04/02/2024 09:10:53 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1698 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:53 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1709 , Training Loss : 0.0056\n",
      "[04/02/2024 09:10:53 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1715 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:54 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1709 , Training Loss : 0.0058\n",
      "[04/02/2024 09:10:54 PM : DEBUG : model_trai : ] : Average training loss : 0.005437410173540417\n",
      "[04/02/2024 09:10:54 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:54 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:54 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:10:54 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : Training error of trained model : 17.54\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:54 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7470\n",
      "[04/02/2024 09:10:54 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:54 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.18636415767669678\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:54 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:54 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7416232824325562 for class 0   \n",
      "[04/02/2024 09:10:54 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:54 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7416233, inf]\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1248 \n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:10:54 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:54 PM : DEBUG : self_train : ] : =============================== END Epoch 60 =======================\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9647435897435898, 'coverage_1': 0.156, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:54 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7470\n",
      "[04/02/2024 09:10:54 PM : DEBUG : self_train : ] : cur_query_count= 530 and max_query_count=1000\n",
      "[04/02/2024 09:10:54 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:54 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 61 ============================\n",
      "[04/02/2024 09:10:54 PM : DEBUG : self_train : ] : Number of unalabeled points  :7470\n",
      "[04/02/2024 09:10:54 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:54 PM : DEBUG : self_train : ] : Current Available Query Budget: 470\n",
      "[04/02/2024 09:10:54 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:54 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:55 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:55 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:55 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7462\n",
      "[04/02/2024 09:10:55 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:55 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:55 PM : INFO  : self_train : ] : Training data size : 1786\n",
      "[04/02/2024 09:10:55 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:55 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1796}\n",
      "[04/02/2024 09:10:55 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:55 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1786}\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2391 , Training Loss : 0.0081\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1719 , Training Loss : 0.0059\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1753 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1753 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1769 , Training Loss : 0.0054\n",
      "[04/02/2024 09:10:55 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:56 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:56 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:56 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:56 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:56 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:56 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:57 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:57 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:57 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:57 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:57 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:57 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:58 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:58 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1769 , Training Loss : 0.0053\n",
      "[04/02/2024 09:10:58 PM : DEBUG : model_trai : ] : Average training loss : 0.005256389790739383\n",
      "[04/02/2024 09:10:58 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:58 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:10:58 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.521\n",
      "[04/02/2024 09:10:58 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.521\n",
      "[04/02/2024 09:10:58 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:10:58 PM : INFO  : self_train : ] : Training error of trained model : 16.85\n",
      "[04/02/2024 09:10:58 PM : INFO  : self_train : ] : Test error of the model         : 51.25\n",
      "[04/02/2024 09:10:58 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:10:58 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:58 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:10:58 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:10:58 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:10:58 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:10:58 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:10:58 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:10:58 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7462\n",
      "[04/02/2024 09:10:58 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:10:58 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:10:58 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.18929235377907752\n",
      "[04/02/2024 09:10:58 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:10:58 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:10:58 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:10:58 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7562596201896667 for class 0   \n",
      "[04/02/2024 09:10:58 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:10:58 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:10:58 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7562596, inf]\n",
      "[04/02/2024 09:10:59 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1159 \n",
      "[04/02/2024 09:10:59 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:10:59 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : =============================== END Epoch 61 =======================\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9853321829163072, 'coverage_1': 0.144875, 'coverage_2': 0}\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7462\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : cur_query_count= 538 and max_query_count=1000\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 62 ============================\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : Number of unalabeled points  :7462\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : Current Available Query Budget: 462\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:10:59 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:10:59 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7454\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : Training data size : 1705\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1786}\n",
      "[04/02/2024 09:10:59 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:59 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:10:59 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1705}\n",
      "[04/02/2024 09:10:59 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:10:59 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:10:59 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5490 , Training Loss : 0.0126\n",
      "[04/02/2024 09:10:59 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1666 , Training Loss : 0.0060\n",
      "[04/02/2024 09:10:59 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1666 , Training Loss : 0.0055\n",
      "[04/02/2024 09:10:59 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1666 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:00 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1689 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:00 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1689 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:00 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1701 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:00 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1701 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:00 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1701 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:00 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1695 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:01 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1695 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:01 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1695 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:01 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1695 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:01 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1695 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:01 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1695 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:01 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1695 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:02 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1695 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:02 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1701 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:02 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1707 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:02 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1707 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:02 PM : DEBUG : model_trai : ] : Average training loss : 0.005563545830921327\n",
      "[04/02/2024 09:11:02 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:02 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:02 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.518\n",
      "[04/02/2024 09:11:02 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.518\n",
      "[04/02/2024 09:11:02 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:02 PM : INFO  : self_train : ] : Training error of trained model : 16.66\n",
      "[04/02/2024 09:11:02 PM : INFO  : self_train : ] : Test error of the model         : 51.45\n",
      "[04/02/2024 09:11:02 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:02 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:02 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:02 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:02 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:02 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:02 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:02 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:02 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7454\n",
      "[04/02/2024 09:11:03 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:03 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:03 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23478039929270744\n",
      "[04/02/2024 09:11:03 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:03 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:03 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:03 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8102189302444458 for class 0   \n",
      "[04/02/2024 09:11:03 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:03 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.158\n",
      "[04/02/2024 09:11:03 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.81021893, inf]\n",
      "[04/02/2024 09:11:03 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1206 \n",
      "[04/02/2024 09:11:03 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 316\n",
      "[04/02/2024 09:11:03 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : =============================== END Epoch 62 =======================\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.978441127694859, 'coverage_1': 0.15075, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7454\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : cur_query_count= 546 and max_query_count=1000\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 63 ============================\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : Number of unalabeled points  :7454\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : Current Available Query Budget: 454\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:03 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:03 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7446\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : Training data size : 1760\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1705}\n",
      "[04/02/2024 09:11:03 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:03 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:03 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1760}\n",
      "[04/02/2024 09:11:03 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:03 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:03 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1795 , Training Loss : 0.0077\n",
      "[04/02/2024 09:11:03 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1676 , Training Loss : 0.0059\n",
      "[04/02/2024 09:11:03 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1687 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:04 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1710 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:04 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1727 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:04 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1733 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:04 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1733 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:04 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1727 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:04 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1733 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:05 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1739 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:05 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1739 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:05 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1739 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:05 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1733 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:05 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1744 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:05 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1727 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:06 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1739 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:06 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1739 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:06 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1739 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:06 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1727 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:06 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1739 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:06 PM : DEBUG : model_trai : ] : Average training loss : 0.0053263095981598675\n",
      "[04/02/2024 09:11:06 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:06 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:06 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.522\n",
      "[04/02/2024 09:11:06 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.522\n",
      "[04/02/2024 09:11:06 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:06 PM : INFO  : self_train : ] : Training error of trained model : 16.42\n",
      "[04/02/2024 09:11:06 PM : INFO  : self_train : ] : Test error of the model         : 51.40\n",
      "[04/02/2024 09:11:06 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:06 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:06 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:06 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:06 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:06 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:06 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:06 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:06 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7446\n",
      "[04/02/2024 09:11:07 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:07 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:07 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.17595536145567894\n",
      "[04/02/2024 09:11:07 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:07 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:07 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:07 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7416642904281616 for class 0   \n",
      "[04/02/2024 09:11:07 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:07 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1575\n",
      "[04/02/2024 09:11:07 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7416643, inf]\n",
      "[04/02/2024 09:11:07 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1142 \n",
      "[04/02/2024 09:11:07 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 315\n",
      "[04/02/2024 09:11:07 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : =============================== END Epoch 63 =======================\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.989492119089317, 'coverage_1': 0.14275, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7446\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : cur_query_count= 554 and max_query_count=1000\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 64 ============================\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : Number of unalabeled points  :7446\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : Current Available Query Budget: 446\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:07 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:07 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7438\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : Training data size : 1704\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1760}\n",
      "[04/02/2024 09:11:07 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:07 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:07 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1704}\n",
      "[04/02/2024 09:11:07 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:07 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:07 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1673 , Training Loss : 0.0074\n",
      "[04/02/2024 09:11:07 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1684 , Training Loss : 0.0059\n",
      "[04/02/2024 09:11:07 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1690 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:08 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1696 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:08 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1690 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:08 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1708 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:08 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1719 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:08 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1719 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:08 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:09 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:09 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:09 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:09 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:09 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:09 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:10 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:10 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1719 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:10 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:10 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:10 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1725 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:10 PM : DEBUG : model_trai : ] : Average training loss : 0.005358193692243821\n",
      "[04/02/2024 09:11:10 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:10 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:10 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5185\n",
      "[04/02/2024 09:11:10 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5185\n",
      "[04/02/2024 09:11:10 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : Training error of trained model : 16.67\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : Test error of the model         : 51.20\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:11 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7438\n",
      "[04/02/2024 09:11:11 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:11 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1755102451145649\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:11 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:11 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.734231173992157 for class 0   \n",
      "[04/02/2024 09:11:11 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:11 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1585\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7342312, inf]\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1185 \n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 317\n",
      "[04/02/2024 09:11:11 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : =============================== END Epoch 64 =======================\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9839662447257383, 'coverage_1': 0.148125, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7438\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : cur_query_count= 562 and max_query_count=1000\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 65 ============================\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : Number of unalabeled points  :7438\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : Current Available Query Budget: 438\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:11 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:11 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7430\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : Training data size : 1755\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1704}\n",
      "[04/02/2024 09:11:11 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:11 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:11 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1755}\n",
      "[04/02/2024 09:11:11 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:11 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:11 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3687 , Training Loss : 0.0103\n",
      "[04/02/2024 09:11:11 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1647 , Training Loss : 0.0063\n",
      "[04/02/2024 09:11:12 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1698 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:12 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1715 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:12 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1732 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:12 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1738 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:12 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1738 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:12 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1738 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:13 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1744 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:13 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1755 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:13 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1749 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:13 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1749 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:13 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1744 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:13 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1749 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1749 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1744 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1738 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1744 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1749 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1749 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Average training loss : 0.005518663961760242\n",
      "[04/02/2024 09:11:14 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:14 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5205\n",
      "[04/02/2024 09:11:14 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5205\n",
      "[04/02/2024 09:11:14 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : Training error of trained model : 16.75\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : Test error of the model         : 50.90\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:15 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7430\n",
      "[04/02/2024 09:11:15 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:15 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.22704054334759713\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:15 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:15 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8047409653663635 for class 0   \n",
      "[04/02/2024 09:11:15 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:15 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.80474097, inf]\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1162 \n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:11:15 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : =============================== END Epoch 65 =======================\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9845094664371773, 'coverage_1': 0.14525, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7430\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : cur_query_count= 570 and max_query_count=1000\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 66 ============================\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : Number of unalabeled points  :7430\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : Current Available Query Budget: 430\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:15 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:15 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7422\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : Training data size : 1740\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1755}\n",
      "[04/02/2024 09:11:15 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:15 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:15 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1740}\n",
      "[04/02/2024 09:11:15 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:15 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:15 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1764 , Training Loss : 0.0073\n",
      "[04/02/2024 09:11:15 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1741 , Training Loss : 0.0059\n",
      "[04/02/2024 09:11:16 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1736 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:16 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1759 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:16 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1747 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:16 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1770 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:16 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1770 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:16 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1770 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:17 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1770 , Training Loss : 0.0058\n",
      "[04/02/2024 09:11:17 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1764 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:17 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1764 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:17 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1764 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:17 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1764 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:17 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1764 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:18 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1770 , Training Loss : 0.0058\n",
      "[04/02/2024 09:11:18 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1764 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:18 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1764 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:18 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1782 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:18 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1776 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:18 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1764 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:19 PM : DEBUG : model_trai : ] : Average training loss : 0.005471052167010424\n",
      "[04/02/2024 09:11:19 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:19 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:19 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.517\n",
      "[04/02/2024 09:11:19 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.517\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : Training error of trained model : 17.36\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : Test error of the model         : 51.25\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:19 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7422\n",
      "[04/02/2024 09:11:19 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:19 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.18288681656122208\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:19 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:19 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7422104477882385 for class 0   \n",
      "[04/02/2024 09:11:19 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:19 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.156\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.74221045, inf]\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1198 \n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 312\n",
      "[04/02/2024 09:11:19 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : =============================== END Epoch 66 =======================\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9799666110183639, 'coverage_1': 0.14975, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7422\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : cur_query_count= 578 and max_query_count=1000\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 67 ============================\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : Number of unalabeled points  :7422\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : Current Available Query Budget: 422\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:19 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:19 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7414\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : Training data size : 1784\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1740}\n",
      "[04/02/2024 09:11:19 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:19 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:19 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1784}\n",
      "[04/02/2024 09:11:19 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:19 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:19 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3117 , Training Loss : 0.0090\n",
      "[04/02/2024 09:11:20 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1777 , Training Loss : 0.0058\n",
      "[04/02/2024 09:11:20 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1777 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:20 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1783 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:20 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1783 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:20 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1783 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:20 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1783 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:21 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1788 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:21 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1799 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:21 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1805 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:21 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1794 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:21 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1788 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:22 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1799 , Training Loss : 0.0055\n",
      "[04/02/2024 09:11:22 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1799 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:22 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1794 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:22 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1811 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:22 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1799 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:22 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1788 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:22 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1794 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:23 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1794 , Training Loss : 0.0054\n",
      "[04/02/2024 09:11:23 PM : DEBUG : model_trai : ] : Average training loss : 0.005378510869010095\n",
      "[04/02/2024 09:11:23 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:23 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:23 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.518\n",
      "[04/02/2024 09:11:23 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.518\n",
      "[04/02/2024 09:11:23 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:23 PM : INFO  : self_train : ] : Training error of trained model : 17.88\n",
      "[04/02/2024 09:11:23 PM : INFO  : self_train : ] : Test error of the model         : 50.60\n",
      "[04/02/2024 09:11:23 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:23 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:23 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:23 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:23 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:23 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:23 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:23 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:23 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7414\n",
      "[04/02/2024 09:11:23 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:23 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:23 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2787990076541901\n",
      "[04/02/2024 09:11:23 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:23 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:23 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:23 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8639211654663086 for class 0   \n",
      "[04/02/2024 09:11:23 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:23 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:11:23 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.86392117, inf]\n",
      "[04/02/2024 09:11:24 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1246 \n",
      "[04/02/2024 09:11:24 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:11:24 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : =============================== END Epoch 67 =======================\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9646869983948636, 'coverage_1': 0.15575, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7414\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : cur_query_count= 586 and max_query_count=1000\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 68 ============================\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : Number of unalabeled points  :7414\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : Current Available Query Budget: 414\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:24 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:24 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7406\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : Training data size : 1840\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1784}\n",
      "[04/02/2024 09:11:24 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:24 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:24 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1840}\n",
      "[04/02/2024 09:11:24 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:24 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:24 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2152 , Training Loss : 0.0082\n",
      "[04/02/2024 09:11:24 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1848 , Training Loss : 0.0060\n",
      "[04/02/2024 09:11:24 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1891 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:24 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1870 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:24 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1875 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:25 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:25 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:25 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:25 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:25 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:25 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:26 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:26 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:26 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:26 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:26 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:27 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:27 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:27 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:27 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1880 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:27 PM : DEBUG : model_trai : ] : Average training loss : 0.005482158488661482\n",
      "[04/02/2024 09:11:27 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:27 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:27 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.517\n",
      "[04/02/2024 09:11:27 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.517\n",
      "[04/02/2024 09:11:27 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:27 PM : INFO  : self_train : ] : Training error of trained model : 18.64\n",
      "[04/02/2024 09:11:27 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:11:27 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:27 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:27 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:27 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:27 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:27 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:27 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:27 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:27 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7406\n",
      "[04/02/2024 09:11:27 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:27 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:28 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2332426477968693\n",
      "[04/02/2024 09:11:28 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:28 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:28 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:28 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8052319288253784 for class 0   \n",
      "[04/02/2024 09:11:28 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:28 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:11:28 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8052319, inf]\n",
      "[04/02/2024 09:11:28 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1245 \n",
      "[04/02/2024 09:11:28 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:11:28 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : =============================== END Epoch 68 =======================\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9670682730923694, 'coverage_1': 0.155625, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7406\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : cur_query_count= 594 and max_query_count=1000\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 69 ============================\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : Number of unalabeled points  :7406\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : Current Available Query Budget: 406\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:28 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:28 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7398\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : Training data size : 1847\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1840}\n",
      "[04/02/2024 09:11:28 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:28 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:28 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1847}\n",
      "[04/02/2024 09:11:28 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:28 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:28 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1830 , Training Loss : 0.0065\n",
      "[04/02/2024 09:11:28 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1830 , Training Loss : 0.0058\n",
      "[04/02/2024 09:11:28 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1879 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:29 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1879 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:29 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1879 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:29 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1879 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:29 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:29 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:29 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:30 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:30 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:30 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:30 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:30 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:30 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:31 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:31 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:31 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:31 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:31 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1884 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:31 PM : DEBUG : model_trai : ] : Average training loss : 0.005359993252003186\n",
      "[04/02/2024 09:11:31 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:31 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:32 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:11:32 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : Training error of trained model : 18.68\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:32 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7398\n",
      "[04/02/2024 09:11:32 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:32 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2389286498129368\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:32 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:32 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8132714033126831 for class 0   \n",
      "[04/02/2024 09:11:32 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:32 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8132714, inf]\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1245 \n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:11:32 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : =============================== END Epoch 69 =======================\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9646586345381526, 'coverage_1': 0.155625, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7398\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : cur_query_count= 602 and max_query_count=1000\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 70 ============================\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : Number of unalabeled points  :7398\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : Current Available Query Budget: 398\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:32 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:32 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7390\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : Training data size : 1855\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1847}\n",
      "[04/02/2024 09:11:32 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:32 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:32 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1855}\n",
      "[04/02/2024 09:11:32 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:32 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:32 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4922 , Training Loss : 0.0111\n",
      "[04/02/2024 09:11:32 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1930 , Training Loss : 0.0061\n",
      "[04/02/2024 09:11:33 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1930 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:33 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1930 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:33 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1930 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:33 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:33 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:33 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:34 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:34 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:34 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:34 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:34 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:34 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:35 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:35 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:35 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:35 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:35 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:35 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1935 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:35 PM : DEBUG : model_trai : ] : Average training loss : 0.005628131602560505\n",
      "[04/02/2024 09:11:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:36 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:11:36 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : Training error of trained model : 19.30\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : Test error of the model         : 50.55\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:36 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7390\n",
      "[04/02/2024 09:11:36 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:36 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23583066695928573\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:36 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:36 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8041320443153381 for class 0   \n",
      "[04/02/2024 09:11:36 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:36 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1635\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.80413204, inf]\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1264 \n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 327\n",
      "[04/02/2024 09:11:36 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : =============================== END Epoch 70 =======================\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9651898734177216, 'coverage_1': 0.158, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7390\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : cur_query_count= 610 and max_query_count=1000\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 71 ============================\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : Number of unalabeled points  :7390\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : Current Available Query Budget: 390\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:36 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:36 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7382\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : Training data size : 1882\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1855}\n",
      "[04/02/2024 09:11:36 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:36 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:36 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1882}\n",
      "[04/02/2024 09:11:36 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:36 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:37 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4989 , Training Loss : 0.0113\n",
      "[04/02/2024 09:11:37 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1929 , Training Loss : 0.0061\n",
      "[04/02/2024 09:11:37 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1939 , Training Loss : 0.0058\n",
      "[04/02/2024 09:11:37 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:37 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:37 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:38 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:38 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:38 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:38 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:38 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:38 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:39 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:39 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:39 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:39 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1939 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:39 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:39 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:40 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:40 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1939 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:40 PM : DEBUG : model_trai : ] : Average training loss : 0.005718601405783453\n",
      "[04/02/2024 09:11:40 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:40 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:40 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:11:40 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:11:40 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:40 PM : INFO  : self_train : ] : Training error of trained model : 19.34\n",
      "[04/02/2024 09:11:40 PM : INFO  : self_train : ] : Test error of the model         : 50.60\n",
      "[04/02/2024 09:11:40 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:40 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:40 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:40 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:40 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:40 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:40 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:40 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7382\n",
      "[04/02/2024 09:11:40 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:40 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:40 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23620858705043793\n",
      "[04/02/2024 09:11:40 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:40 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:40 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8048397898674011 for class 0   \n",
      "[04/02/2024 09:11:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:40 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.162\n",
      "[04/02/2024 09:11:40 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8048398, inf]\n",
      "[04/02/2024 09:11:41 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1267 \n",
      "[04/02/2024 09:11:41 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 324\n",
      "[04/02/2024 09:11:41 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : =============================== END Epoch 71 =======================\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9644830307813733, 'coverage_1': 0.158375, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7382\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : cur_query_count= 618 and max_query_count=1000\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 72 ============================\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : Number of unalabeled points  :7382\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : Current Available Query Budget: 382\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:41 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:41 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7374\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : Training data size : 1893\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1882}\n",
      "[04/02/2024 09:11:41 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:41 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:41 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1893}\n",
      "[04/02/2024 09:11:41 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:41 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:41 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3967 , Training Loss : 0.0104\n",
      "[04/02/2024 09:11:41 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1933 , Training Loss : 0.0062\n",
      "[04/02/2024 09:11:41 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:41 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:41 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:42 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:42 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:42 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:42 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:42 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:42 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:43 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:43 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:43 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:43 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:43 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:43 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:44 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:44 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:44 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:44 PM : DEBUG : model_trai : ] : Average training loss : 0.005676574785583493\n",
      "[04/02/2024 09:11:44 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:44 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:44 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5125\n",
      "[04/02/2024 09:11:44 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5125\n",
      "[04/02/2024 09:11:44 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:44 PM : INFO  : self_train : ] : Training error of trained model : 19.65\n",
      "[04/02/2024 09:11:44 PM : INFO  : self_train : ] : Test error of the model         : 50.40\n",
      "[04/02/2024 09:11:44 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:44 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:44 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:44 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:44 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:44 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:44 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:44 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7374\n",
      "[04/02/2024 09:11:44 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:44 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:44 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2602744791209698\n",
      "[04/02/2024 09:11:44 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:44 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:44 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:44 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.83536297082901 for class 0   \n",
      "[04/02/2024 09:11:45 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:45 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1615\n",
      "[04/02/2024 09:11:45 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.835363, inf]\n",
      "[04/02/2024 09:11:45 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1264 \n",
      "[04/02/2024 09:11:45 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 323\n",
      "[04/02/2024 09:11:45 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : =============================== END Epoch 72 =======================\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9667721518987342, 'coverage_1': 0.158, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7374\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : cur_query_count= 626 and max_query_count=1000\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 73 ============================\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : Number of unalabeled points  :7374\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : Current Available Query Budget: 374\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:45 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:45 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7366\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : Training data size : 1898\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1893}\n",
      "[04/02/2024 09:11:45 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:45 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:45 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1898}\n",
      "[04/02/2024 09:11:45 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:45 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:45 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1960 , Training Loss : 0.0069\n",
      "[04/02/2024 09:11:45 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1960 , Training Loss : 0.0060\n",
      "[04/02/2024 09:11:45 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:45 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:46 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1965 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:46 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:46 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:46 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1960 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:46 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:46 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:47 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:47 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:47 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1965 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:47 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1960 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:47 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:47 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:48 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:48 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:48 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:48 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1960 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:48 PM : DEBUG : model_trai : ] : Average training loss : 0.005468522871205784\n",
      "[04/02/2024 09:11:48 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:48 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:48 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5125\n",
      "[04/02/2024 09:11:48 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5125\n",
      "[04/02/2024 09:11:48 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:48 PM : INFO  : self_train : ] : Training error of trained model : 19.60\n",
      "[04/02/2024 09:11:48 PM : INFO  : self_train : ] : Test error of the model         : 50.55\n",
      "[04/02/2024 09:11:48 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:48 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:48 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:48 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:48 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:48 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:48 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:48 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7366\n",
      "[04/02/2024 09:11:48 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:48 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:49 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27631102177500727\n",
      "[04/02/2024 09:11:49 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:49 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:49 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:49 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8551913499832153 for class 0   \n",
      "[04/02/2024 09:11:49 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:49 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.163\n",
      "[04/02/2024 09:11:49 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.85519135, inf]\n",
      "[04/02/2024 09:11:49 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1275 \n",
      "[04/02/2024 09:11:49 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 326\n",
      "[04/02/2024 09:11:49 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : =============================== END Epoch 73 =======================\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9647058823529412, 'coverage_1': 0.159375, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7366\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : cur_query_count= 634 and max_query_count=1000\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 74 ============================\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : Number of unalabeled points  :7366\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : Current Available Query Budget: 366\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:49 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:49 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7358\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : Training data size : 1917\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1898}\n",
      "[04/02/2024 09:11:49 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:49 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:49 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1917}\n",
      "[04/02/2024 09:11:49 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:49 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:49 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1946 , Training Loss : 0.0066\n",
      "[04/02/2024 09:11:49 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1993 , Training Loss : 0.0059\n",
      "[04/02/2024 09:11:49 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1987 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:50 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1977 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:50 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1972 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:50 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1967 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:50 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1972 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:50 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:50 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:51 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:51 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1972 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:51 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1972 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:51 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:51 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:51 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1972 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:52 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:52 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:52 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:52 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:52 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1972 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:52 PM : DEBUG : model_trai : ] : Average training loss : 0.0054410032704603935\n",
      "[04/02/2024 09:11:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:52 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5125\n",
      "[04/02/2024 09:11:52 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5125\n",
      "[04/02/2024 09:11:52 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : Training error of trained model : 19.87\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : Test error of the model         : 50.40\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:53 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7358\n",
      "[04/02/2024 09:11:53 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:53 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.26144195514917373\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:53 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:53 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8368257880210876 for class 0   \n",
      "[04/02/2024 09:11:53 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:53 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1615\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8368258, inf]\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1264 \n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 323\n",
      "[04/02/2024 09:11:53 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : =============================== END Epoch 74 =======================\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9667721518987342, 'coverage_1': 0.158, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7358\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : cur_query_count= 642 and max_query_count=1000\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 75 ============================\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : Number of unalabeled points  :7358\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : Current Available Query Budget: 358\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:53 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:53 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7350\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : Training data size : 1914\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1917}\n",
      "[04/02/2024 09:11:53 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:53 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:53 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1914}\n",
      "[04/02/2024 09:11:53 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:53 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:53 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.1881 , Training Loss : 0.0068\n",
      "[04/02/2024 09:11:53 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2001 , Training Loss : 0.0059\n",
      "[04/02/2024 09:11:54 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2001 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:54 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1985 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:54 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1991 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:54 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1991 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:54 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1991 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:54 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1991 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:55 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1980 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:55 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1985 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:55 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1980 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:55 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1985 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:55 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1980 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:55 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1980 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:56 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1980 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:56 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1980 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:56 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1985 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:56 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1991 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:56 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1975 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:56 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1970 , Training Loss : 0.0056\n",
      "[04/02/2024 09:11:57 PM : DEBUG : model_trai : ] : Average training loss : 0.005457065177968043\n",
      "[04/02/2024 09:11:57 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:57 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:11:57 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5135\n",
      "[04/02/2024 09:11:57 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5135\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : Training error of trained model : 19.59\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : Test error of the model         : 50.50\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:11:57 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7350\n",
      "[04/02/2024 09:11:57 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:11:57 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.20269552859663964\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:11:57 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:11:57 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7602859735488892 for class 0   \n",
      "[04/02/2024 09:11:57 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:11:57 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.163\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.760286, inf]\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1259 \n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 326\n",
      "[04/02/2024 09:11:57 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : =============================== END Epoch 75 =======================\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9642573471008737, 'coverage_1': 0.157375, 'coverage_2': 0}\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7350\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : cur_query_count= 650 and max_query_count=1000\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 76 ============================\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : Number of unalabeled points  :7350\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : Current Available Query Budget: 350\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:11:57 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:11:57 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7342\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : Training data size : 1917\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1914}\n",
      "[04/02/2024 09:11:57 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:57 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:11:57 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1917}\n",
      "[04/02/2024 09:11:57 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:11:57 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:11:57 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2087 , Training Loss : 0.0082\n",
      "[04/02/2024 09:11:58 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1941 , Training Loss : 0.0061\n",
      "[04/02/2024 09:11:58 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1998 , Training Loss : 0.0058\n",
      "[04/02/2024 09:11:58 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2029 , Training Loss : 0.0058\n",
      "[04/02/2024 09:11:58 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:58 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:58 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:59 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:59 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:59 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:59 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2034 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:59 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:59 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:11:59 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:12:00 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:12:00 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:12:00 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2034 , Training Loss : 0.0057\n",
      "[04/02/2024 09:12:00 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:12:00 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:12:01 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2029 , Training Loss : 0.0057\n",
      "[04/02/2024 09:12:01 PM : DEBUG : model_trai : ] : Average training loss : 0.005599009360917548\n",
      "[04/02/2024 09:12:01 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:01 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:01 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5165\n",
      "[04/02/2024 09:12:01 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5165\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : Training error of trained model : 19.35\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : Test error of the model         : 51.15\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:01 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7342\n",
      "[04/02/2024 09:12:01 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:01 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.17275449961423875\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:01 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:01 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7264707684516907 for class 0   \n",
      "[04/02/2024 09:12:01 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:01 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.162\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.72647077, inf]\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1241 \n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 324\n",
      "[04/02/2024 09:12:01 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : =============================== END Epoch 76 =======================\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9685737308622079, 'coverage_1': 0.155125, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7342\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : cur_query_count= 658 and max_query_count=1000\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 77 ============================\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : Number of unalabeled points  :7342\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : Current Available Query Budget: 342\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:01 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:01 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7334\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : Training data size : 1907\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1917}\n",
      "[04/02/2024 09:12:01 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:01 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:01 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1907}\n",
      "[04/02/2024 09:12:01 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:01 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:02 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2669 , Training Loss : 0.0087\n",
      "[04/02/2024 09:12:02 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1904 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:02 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1951 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:02 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1961 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:02 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1972 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:02 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1987 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:03 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1987 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:03 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1987 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:03 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1987 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:03 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1993 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:03 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1982 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:03 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1993 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:04 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2003 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:04 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2003 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:04 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2008 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:04 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1993 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:04 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1998 , Training Loss : 0.0057\n",
      "[04/02/2024 09:12:04 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1998 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:05 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1987 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:05 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1998 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:05 PM : DEBUG : model_trai : ] : Average training loss : 0.005653715567228382\n",
      "[04/02/2024 09:12:05 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:05 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:05 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:12:05 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : Training error of trained model : 19.09\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:05 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7334\n",
      "[04/02/2024 09:12:05 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:05 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.16479940530657775\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:05 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7172768115997314 for class 0   \n",
      "[04/02/2024 09:12:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:05 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.161\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7172768, inf]\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1248 \n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 322\n",
      "[04/02/2024 09:12:05 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:05 PM : DEBUG : self_train : ] : =============================== END Epoch 77 =======================\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.967948717948718, 'coverage_1': 0.156, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:05 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7334\n",
      "[04/02/2024 09:12:05 PM : DEBUG : self_train : ] : cur_query_count= 666 and max_query_count=1000\n",
      "[04/02/2024 09:12:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:05 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 78 ============================\n",
      "[04/02/2024 09:12:05 PM : DEBUG : self_train : ] : Number of unalabeled points  :7334\n",
      "[04/02/2024 09:12:05 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:05 PM : DEBUG : self_train : ] : Current Available Query Budget: 334\n",
      "[04/02/2024 09:12:05 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:06 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:06 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:06 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:06 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7326\n",
      "[04/02/2024 09:12:06 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:06 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:06 PM : INFO  : self_train : ] : Training data size : 1922\n",
      "[04/02/2024 09:12:06 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:06 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1907}\n",
      "[04/02/2024 09:12:06 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:06 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:06 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1922}\n",
      "[04/02/2024 09:12:06 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:06 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:06 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4506 , Training Loss : 0.0106\n",
      "[04/02/2024 09:12:06 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1946 , Training Loss : 0.0064\n",
      "[04/02/2024 09:12:06 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1956 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:06 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2024 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:06 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2034 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:07 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2034 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:07 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2024 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:07 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2014 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:07 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2034 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:07 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2034 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:07 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2029 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:08 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2029 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:08 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2040 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:08 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2014 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:08 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2024 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:08 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2034 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:08 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2029 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:09 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2034 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:09 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2019 , Training Loss : 0.0064\n",
      "[04/02/2024 09:12:09 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2034 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:09 PM : DEBUG : model_trai : ] : Average training loss : 0.0059049929727579\n",
      "[04/02/2024 09:12:09 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:09 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:09 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.517\n",
      "[04/02/2024 09:12:09 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.517\n",
      "[04/02/2024 09:12:09 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:09 PM : INFO  : self_train : ] : Training error of trained model : 19.67\n",
      "[04/02/2024 09:12:09 PM : INFO  : self_train : ] : Test error of the model         : 50.60\n",
      "[04/02/2024 09:12:09 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:09 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:09 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:09 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:09 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:09 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:09 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:09 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7326\n",
      "[04/02/2024 09:12:09 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:09 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:09 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2354399789273739\n",
      "[04/02/2024 09:12:09 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:09 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:09 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:09 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8080976009368896 for class 0   \n",
      "[04/02/2024 09:12:09 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:09 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:12:09 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8080976, inf]\n",
      "[04/02/2024 09:12:10 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1247 \n",
      "[04/02/2024 09:12:10 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:12:10 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : =============================== END Epoch 78 =======================\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9647153167602245, 'coverage_1': 0.155875, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7326\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : cur_query_count= 674 and max_query_count=1000\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 79 ============================\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : Number of unalabeled points  :7326\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : Current Available Query Budget: 326\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:10 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:10 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7318\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : Training data size : 1929\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1922}\n",
      "[04/02/2024 09:12:10 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:10 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:10 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1929}\n",
      "[04/02/2024 09:12:10 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:10 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:10 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2063 , Training Loss : 0.0075\n",
      "[04/02/2024 09:12:10 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2058 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:10 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:10 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:11 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:11 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:11 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:11 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:11 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2058 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:11 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2058 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:12 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:12 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2058 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:12 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2058 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:12 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:12 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:12 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:13 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2058 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:13 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2058 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:13 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2058 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:13 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2058 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:13 PM : DEBUG : model_trai : ] : Average training loss : 0.005763677201718007\n",
      "[04/02/2024 09:12:13 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:13 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:13 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.512\n",
      "[04/02/2024 09:12:13 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.512\n",
      "[04/02/2024 09:12:13 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:13 PM : INFO  : self_train : ] : Training error of trained model : 20.53\n",
      "[04/02/2024 09:12:13 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:12:13 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:13 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:13 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:13 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:13 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:13 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:13 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:13 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:13 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7318\n",
      "[04/02/2024 09:12:13 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:13 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:14 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.24316076755523686\n",
      "[04/02/2024 09:12:14 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:14 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:14 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:14 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8110759258270264 for class 0   \n",
      "[04/02/2024 09:12:14 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:14 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1615\n",
      "[04/02/2024 09:12:14 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8110759, inf]\n",
      "[04/02/2024 09:12:14 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1271 \n",
      "[04/02/2024 09:12:14 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 323\n",
      "[04/02/2024 09:12:14 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : =============================== END Epoch 79 =======================\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.963808025177026, 'coverage_1': 0.158875, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7318\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : cur_query_count= 682 and max_query_count=1000\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 80 ============================\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : Number of unalabeled points  :7318\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : Current Available Query Budget: 318\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:14 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:14 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7310\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : Training data size : 1961\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1929}\n",
      "[04/02/2024 09:12:14 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:14 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:14 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1961}\n",
      "[04/02/2024 09:12:14 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:14 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:14 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4467 , Training Loss : 0.0114\n",
      "[04/02/2024 09:12:14 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1968 , Training Loss : 0.0064\n",
      "[04/02/2024 09:12:15 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2035 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:15 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2050 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:15 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2050 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:15 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2055 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:15 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2040 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:15 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2045 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:16 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2035 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:16 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2040 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:16 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2035 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:16 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2040 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:16 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2040 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:16 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2055 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:17 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2035 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:17 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2035 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:17 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2040 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:17 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2040 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:17 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2035 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:17 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2040 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:18 PM : DEBUG : model_trai : ] : Average training loss : 0.00586244819723313\n",
      "[04/02/2024 09:12:18 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:18 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:18 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.517\n",
      "[04/02/2024 09:12:18 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.517\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : Training error of trained model : 19.48\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : Test error of the model         : 51.25\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:18 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7310\n",
      "[04/02/2024 09:12:18 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:18 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1570903955698013\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:18 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:18 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7091113924980164 for class 0   \n",
      "[04/02/2024 09:12:18 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:18 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.156\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7091114, inf]\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1198 \n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 312\n",
      "[04/02/2024 09:12:18 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : =============================== END Epoch 80 =======================\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9799666110183639, 'coverage_1': 0.14975, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7310\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : cur_query_count= 690 and max_query_count=1000\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 81 ============================\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : Number of unalabeled points  :7310\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : Current Available Query Budget: 310\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:18 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:18 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7302\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : Training data size : 1896\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1961}\n",
      "[04/02/2024 09:12:18 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:18 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:18 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1896}\n",
      "[04/02/2024 09:12:18 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:18 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:18 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2073 , Training Loss : 0.0077\n",
      "[04/02/2024 09:12:19 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1862 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:19 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.1941 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:19 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.1951 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:19 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.1957 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:19 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.1957 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:19 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.1941 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:20 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.1962 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:20 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.1978 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:20 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.1978 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:20 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.1978 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:20 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.1973 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:20 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.1962 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:21 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.1957 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:21 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.1962 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:21 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.1983 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:21 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.1973 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:21 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.1962 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:21 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.1973 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:22 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.1962 , Training Loss : 0.0058\n",
      "[04/02/2024 09:12:22 PM : DEBUG : model_trai : ] : Average training loss : 0.005670909329527279\n",
      "[04/02/2024 09:12:22 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:22 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:22 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:12:22 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : Training error of trained model : 19.73\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:22 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7302\n",
      "[04/02/2024 09:12:22 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:22 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2707532685697079\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:22 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:22 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8553075194358826 for class 0   \n",
      "[04/02/2024 09:12:22 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:22 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8553075, inf]\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1245 \n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:12:22 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : =============================== END Epoch 81 =======================\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9670682730923694, 'coverage_1': 0.155625, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7302\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : cur_query_count= 698 and max_query_count=1000\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 82 ============================\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : Number of unalabeled points  :7302\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : Current Available Query Budget: 302\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:22 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:22 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7294\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : Training data size : 1951\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1896}\n",
      "[04/02/2024 09:12:22 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:22 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:22 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1951}\n",
      "[04/02/2024 09:12:22 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:22 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:23 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4485 , Training Loss : 0.0108\n",
      "[04/02/2024 09:12:23 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1978 , Training Loss : 0.0064\n",
      "[04/02/2024 09:12:23 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2004 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:23 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2035 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:23 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2060 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:23 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2071 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:24 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2081 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:24 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2071 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:24 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2076 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:24 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2086 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:24 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2081 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:24 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2076 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:25 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2076 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:25 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2081 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:25 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2076 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:25 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2076 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:25 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2076 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:26 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2081 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:26 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2081 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:26 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2076 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:26 PM : DEBUG : model_trai : ] : Average training loss : 0.0059063377238033395\n",
      "[04/02/2024 09:12:26 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:26 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:26 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.517\n",
      "[04/02/2024 09:12:26 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.517\n",
      "[04/02/2024 09:12:26 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:26 PM : INFO  : self_train : ] : Training error of trained model : 19.99\n",
      "[04/02/2024 09:12:26 PM : INFO  : self_train : ] : Test error of the model         : 50.70\n",
      "[04/02/2024 09:12:26 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:26 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:26 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:26 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:26 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:26 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:26 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:26 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:26 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7294\n",
      "[04/02/2024 09:12:26 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:26 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:26 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23249717855453492\n",
      "[04/02/2024 09:12:26 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:26 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:26 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:26 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8036613464355469 for class 0   \n",
      "[04/02/2024 09:12:26 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:26 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:12:26 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.80366135, inf]\n",
      "[04/02/2024 09:12:27 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1246 \n",
      "[04/02/2024 09:12:27 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:12:27 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : =============================== END Epoch 82 =======================\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9670947030497592, 'coverage_1': 0.15575, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7294\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : cur_query_count= 706 and max_query_count=1000\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 83 ============================\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : Number of unalabeled points  :7294\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : Current Available Query Budget: 294\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:27 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:27 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7286\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : Training data size : 1960\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1951}\n",
      "[04/02/2024 09:12:27 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:27 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:27 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1960}\n",
      "[04/02/2024 09:12:27 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:27 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:27 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2500 , Training Loss : 0.0078\n",
      "[04/02/2024 09:12:27 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2097 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:27 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2097 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:27 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2092 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:28 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2087 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:28 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2092 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:28 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2102 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:28 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2102 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:28 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2097 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:29 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2092 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:29 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2102 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:29 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2107 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:29 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2097 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:29 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2102 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:29 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2097 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:30 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2107 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:30 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2102 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:30 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2102 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:30 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2107 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:30 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2102 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:30 PM : DEBUG : model_trai : ] : Average training loss : 0.00575171364335555\n",
      "[04/02/2024 09:12:30 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:30 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:30 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:12:30 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:12:30 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : Training error of trained model : 20.71\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : Test error of the model         : 50.70\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:31 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7286\n",
      "[04/02/2024 09:12:31 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:31 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.19642641803622246\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:31 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:31 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7506417632102966 for class 0   \n",
      "[04/02/2024 09:12:31 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:31 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.161\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.75064176, inf]\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1280 \n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 322\n",
      "[04/02/2024 09:12:31 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : =============================== END Epoch 83 =======================\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.953125, 'coverage_1': 0.16, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7286\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : cur_query_count= 714 and max_query_count=1000\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 84 ============================\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : Number of unalabeled points  :7286\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : Current Available Query Budget: 286\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:31 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:31 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7278\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : Training data size : 2002\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1960}\n",
      "[04/02/2024 09:12:31 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:31 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:31 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2002}\n",
      "[04/02/2024 09:12:31 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:31 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:31 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2163 , Training Loss : 0.0068\n",
      "[04/02/2024 09:12:31 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2118 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:32 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:32 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:32 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:32 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2143 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:32 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:32 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:33 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:33 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2143 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:33 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:33 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2143 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:33 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2143 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:33 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:34 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:34 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2143 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:34 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:34 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:34 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2143 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:35 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2143 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:35 PM : DEBUG : model_trai : ] : Average training loss : 0.005938225005198247\n",
      "[04/02/2024 09:12:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:35 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:12:35 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : Training error of trained model : 21.18\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:35 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7278\n",
      "[04/02/2024 09:12:35 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:35 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2112229199409485\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:35 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:35 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7753363847732544 for class 0   \n",
      "[04/02/2024 09:12:35 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:35 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1575\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7753364, inf]\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1253 \n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 315\n",
      "[04/02/2024 09:12:35 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : =============================== END Epoch 84 =======================\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9624900239425379, 'coverage_1': 0.156625, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7278\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : cur_query_count= 722 and max_query_count=1000\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 85 ============================\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : Number of unalabeled points  :7278\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : Current Available Query Budget: 278\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:35 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:35 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7270\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : Training data size : 1983\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2002}\n",
      "[04/02/2024 09:12:35 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:35 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:35 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1983}\n",
      "[04/02/2024 09:12:35 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:35 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:36 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3162 , Training Loss : 0.0091\n",
      "[04/02/2024 09:12:36 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2078 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:36 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:36 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:36 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:36 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:36 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:37 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:37 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:37 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:37 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:37 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:38 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:38 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:38 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:38 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:38 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:38 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:39 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:39 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:39 PM : DEBUG : model_trai : ] : Average training loss : 0.005844492793836067\n",
      "[04/02/2024 09:12:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:39 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.516\n",
      "[04/02/2024 09:12:39 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.516\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : Training error of trained model : 20.52\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : Test error of the model         : 51.10\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:39 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7270\n",
      "[04/02/2024 09:12:39 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:39 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.17788821655511855\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:39 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:39 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7322288155555725 for class 0   \n",
      "[04/02/2024 09:12:39 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:39 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1615\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7322288, inf]\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1244 \n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 323\n",
      "[04/02/2024 09:12:39 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:39 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : =============================== END Epoch 85 =======================\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9694533762057878, 'coverage_1': 0.1555, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7270\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : cur_query_count= 730 and max_query_count=1000\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 86 ============================\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : Number of unalabeled points  :7270\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : Current Available Query Budget: 270\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:40 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:40 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7262\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : Training data size : 1982\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1983}\n",
      "[04/02/2024 09:12:40 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:40 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:40 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1982}\n",
      "[04/02/2024 09:12:40 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:40 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:40 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5116 , Training Loss : 0.0115\n",
      "[04/02/2024 09:12:40 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2059 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:40 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2048 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:40 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2074 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:40 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2084 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:41 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2104 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:41 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2089 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:41 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2089 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:41 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2094 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:41 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2104 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:41 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2084 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:41 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2099 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:42 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2099 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:42 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2094 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:42 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2079 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:42 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2084 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:42 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2084 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:42 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2089 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:43 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2089 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:43 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2099 , Training Loss : 0.0059\n",
      "[04/02/2024 09:12:43 PM : DEBUG : model_trai : ] : Average training loss : 0.005910900713622865\n",
      "[04/02/2024 09:12:43 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:43 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:43 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.517\n",
      "[04/02/2024 09:12:43 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.517\n",
      "[04/02/2024 09:12:43 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:43 PM : INFO  : self_train : ] : Training error of trained model : 20.53\n",
      "[04/02/2024 09:12:43 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:12:43 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:43 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:43 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:43 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:43 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:43 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:43 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:43 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:43 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7262\n",
      "[04/02/2024 09:12:43 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:43 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:43 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23304173719882965\n",
      "[04/02/2024 09:12:43 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:43 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:43 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:43 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8048954010009766 for class 0   \n",
      "[04/02/2024 09:12:43 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:43 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:12:43 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8048954, inf]\n",
      "[04/02/2024 09:12:44 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1246 \n",
      "[04/02/2024 09:12:44 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:12:44 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : =============================== END Epoch 86 =======================\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9646869983948636, 'coverage_1': 0.15575, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7262\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : cur_query_count= 738 and max_query_count=1000\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 87 ============================\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : Number of unalabeled points  :7262\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : Current Available Query Budget: 262\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:44 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:44 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7254\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : Training data size : 1992\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1982}\n",
      "[04/02/2024 09:12:44 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:44 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:44 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1992}\n",
      "[04/02/2024 09:12:44 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:44 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:44 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2118 , Training Loss : 0.0075\n",
      "[04/02/2024 09:12:44 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2068 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:44 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2093 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:44 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2144 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:45 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2149 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:45 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2149 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:45 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2149 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:45 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2144 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:45 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2149 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:45 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2144 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:46 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2139 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:46 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2144 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:46 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2144 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:46 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2144 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:46 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2139 , Training Loss : 0.0063\n",
      "[04/02/2024 09:12:46 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2139 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:47 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2139 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:47 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2144 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:47 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2139 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:47 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2144 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:47 PM : DEBUG : model_trai : ] : Average training loss : 0.005924942472379325\n",
      "[04/02/2024 09:12:47 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:47 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:47 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.515\n",
      "[04/02/2024 09:12:47 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.515\n",
      "[04/02/2024 09:12:47 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:47 PM : INFO  : self_train : ] : Training error of trained model : 21.03\n",
      "[04/02/2024 09:12:47 PM : INFO  : self_train : ] : Test error of the model         : 50.50\n",
      "[04/02/2024 09:12:47 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:47 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:47 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:47 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:47 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:47 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:47 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:47 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:47 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7254\n",
      "[04/02/2024 09:12:48 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:48 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:48 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23741872176527978\n",
      "[04/02/2024 09:12:48 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:48 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:48 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8078284859657288 for class 0   \n",
      "[04/02/2024 09:12:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:48 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:12:48 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8078285, inf]\n",
      "[04/02/2024 09:12:48 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1251 \n",
      "[04/02/2024 09:12:48 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:12:48 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : =============================== END Epoch 87 =======================\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.964828137490008, 'coverage_1': 0.156375, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7254\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : cur_query_count= 746 and max_query_count=1000\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 88 ============================\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : Number of unalabeled points  :7254\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : Current Available Query Budget: 254\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:48 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:48 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7246\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : Training data size : 2005\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1992}\n",
      "[04/02/2024 09:12:48 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:48 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:48 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2005}\n",
      "[04/02/2024 09:12:48 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:48 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:48 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4234 , Training Loss : 0.0111\n",
      "[04/02/2024 09:12:48 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2100 , Training Loss : 0.0065\n",
      "[04/02/2024 09:12:48 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2140 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:49 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:49 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:49 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:49 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2140 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:49 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:49 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:50 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2130 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:50 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2140 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:50 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:50 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:50 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2140 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:51 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2125 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:51 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:51 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2140 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:51 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:51 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:51 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2135 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:51 PM : DEBUG : model_trai : ] : Average training loss : 0.006058684967501601\n",
      "[04/02/2024 09:12:51 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:51 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:52 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.512\n",
      "[04/02/2024 09:12:52 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.512\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : Training error of trained model : 21.60\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : Test error of the model         : 51.10\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:52 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7246\n",
      "[04/02/2024 09:12:52 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:52 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.17638402858376506\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:52 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7291734218597412 for class 0   \n",
      "[04/02/2024 09:12:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:52 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.158\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7291734, inf]\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1244 \n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 316\n",
      "[04/02/2024 09:12:52 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : =============================== END Epoch 88 =======================\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9718649517684887, 'coverage_1': 0.1555, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7246\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : cur_query_count= 754 and max_query_count=1000\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 89 ============================\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : Number of unalabeled points  :7246\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : Current Available Query Budget: 246\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:52 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:52 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7238\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : Training data size : 2006\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2005}\n",
      "[04/02/2024 09:12:52 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:52 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:52 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2006}\n",
      "[04/02/2024 09:12:52 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:52 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:52 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2149 , Training Loss : 0.0077\n",
      "[04/02/2024 09:12:53 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2129 , Training Loss : 0.0065\n",
      "[04/02/2024 09:12:53 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2168 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:53 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2099 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:53 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2124 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:53 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2109 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:53 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2119 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:53 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2089 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:54 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2079 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:54 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2069 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:54 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2074 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:54 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2039 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:54 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2059 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:55 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2054 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:55 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2074 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:55 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2059 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:55 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2054 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:55 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2059 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:55 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2069 , Training Loss : 0.0060\n",
      "[04/02/2024 09:12:56 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2074 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:56 PM : DEBUG : model_trai : ] : Average training loss : 0.005879459845605458\n",
      "[04/02/2024 09:12:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:12:56 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5155\n",
      "[04/02/2024 09:12:56 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5155\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : Training error of trained model : 20.74\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : Test error of the model         : 50.90\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:12:56 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7238\n",
      "[04/02/2024 09:12:56 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:12:56 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27497572392225267\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:12:56 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:12:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8598337769508362 for class 0   \n",
      "[04/02/2024 09:12:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:12:56 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.157\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8598338, inf]\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1259 \n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 314\n",
      "[04/02/2024 09:12:56 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : =============================== END Epoch 89 =======================\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.960285941223193, 'coverage_1': 0.157375, 'coverage_2': 0}\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7238\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : cur_query_count= 762 and max_query_count=1000\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 90 ============================\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : Number of unalabeled points  :7238\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : Current Available Query Budget: 238\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:12:56 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:12:56 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7230\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : Training data size : 2029\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2006}\n",
      "[04/02/2024 09:12:56 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:56 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:12:56 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2029}\n",
      "[04/02/2024 09:12:56 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:12:56 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:12:57 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5515 , Training Loss : 0.0131\n",
      "[04/02/2024 09:12:57 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2159 , Training Loss : 0.0066\n",
      "[04/02/2024 09:12:57 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2159 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:57 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2149 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:57 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:57 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:58 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2154 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:58 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:58 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:58 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:58 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:58 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2154 , Training Loss : 0.0062\n",
      "[04/02/2024 09:12:59 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:59 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:59 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:59 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:12:59 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:00 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:00 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:00 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2154 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:00 PM : DEBUG : model_trai : ] : Average training loss : 0.0061970389388850845\n",
      "[04/02/2024 09:13:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:00 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:13:00 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:13:00 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:00 PM : INFO  : self_train : ] : Training error of trained model : 21.59\n",
      "[04/02/2024 09:13:00 PM : INFO  : self_train : ] : Test error of the model         : 50.70\n",
      "[04/02/2024 09:13:00 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:00 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:00 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:00 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:00 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:00 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:00 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:00 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:00 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7230\n",
      "[04/02/2024 09:13:00 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:00 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:00 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.13128704473376274\n",
      "[04/02/2024 09:13:00 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:00 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:00 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:00 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.6697627305984497 for class 0   \n",
      "[04/02/2024 09:13:00 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:00 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:13:00 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.66976273, inf]\n",
      "[04/02/2024 09:13:01 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1273 \n",
      "[04/02/2024 09:13:01 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:13:01 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : =============================== END Epoch 90 =======================\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9552238805970149, 'coverage_1': 0.159125, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7230\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : cur_query_count= 770 and max_query_count=1000\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 91 ============================\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : Number of unalabeled points  :7230\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : Current Available Query Budget: 230\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:01 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:01 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7222\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : Training data size : 2051\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2029}\n",
      "[04/02/2024 09:13:01 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:01 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:01 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2051}\n",
      "[04/02/2024 09:13:01 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:01 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:01 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4144 , Training Loss : 0.0109\n",
      "[04/02/2024 09:13:01 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2140 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:01 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2175 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:01 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2175 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:02 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2175 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:02 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2175 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:02 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2175 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:02 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2175 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:02 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2175 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:02 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2175 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:03 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2175 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:03 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2175 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:03 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2175 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:03 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2175 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:03 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2175 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:04 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2175 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:04 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2175 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:04 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2175 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:04 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2179 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:04 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2175 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:04 PM : DEBUG : model_trai : ] : Average training loss : 0.0062428914463396054\n",
      "[04/02/2024 09:13:04 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:04 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:04 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5165\n",
      "[04/02/2024 09:13:04 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5165\n",
      "[04/02/2024 09:13:04 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : Training error of trained model : 21.50\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : Test error of the model         : 51.00\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:05 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7222\n",
      "[04/02/2024 09:13:05 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:05 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.16480070620775222\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:05 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7161340117454529 for class 0   \n",
      "[04/02/2024 09:13:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:05 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.716134, inf]\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1244 \n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:13:05 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : =============================== END Epoch 91 =======================\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9694533762057878, 'coverage_1': 0.1555, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7222\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : cur_query_count= 778 and max_query_count=1000\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 92 ============================\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : Number of unalabeled points  :7222\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : Current Available Query Budget: 222\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:05 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:05 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7214\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : Training data size : 2030\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2051}\n",
      "[04/02/2024 09:13:05 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:05 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:05 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2030}\n",
      "[04/02/2024 09:13:05 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:05 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:05 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2074 , Training Loss : 0.0078\n",
      "[04/02/2024 09:13:05 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2089 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:06 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2118 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:06 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2099 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:06 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2123 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:06 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2148 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:06 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2118 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:06 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2118 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:07 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2133 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:07 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2138 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:07 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2123 , Training Loss : 0.0060\n",
      "[04/02/2024 09:13:07 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2133 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:07 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2138 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:08 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2133 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:08 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2143 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:08 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2143 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:08 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2133 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:08 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2138 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:08 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2118 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:09 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2133 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:09 PM : DEBUG : model_trai : ] : Average training loss : 0.00588651115894877\n",
      "[04/02/2024 09:13:09 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:09 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:09 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:13:09 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : Training error of trained model : 21.08\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:09 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7214\n",
      "[04/02/2024 09:13:09 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:09 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2491795675456524\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:09 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:09 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8268204927444458 for class 0   \n",
      "[04/02/2024 09:13:09 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:09 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8268205, inf]\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1246 \n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:13:09 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : =============================== END Epoch 92 =======================\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9646869983948636, 'coverage_1': 0.15575, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7214\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : cur_query_count= 786 and max_query_count=1000\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 93 ============================\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : Number of unalabeled points  :7214\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : Current Available Query Budget: 214\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:09 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:09 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7206\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : Training data size : 2040\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2030}\n",
      "[04/02/2024 09:13:09 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:09 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:09 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2040}\n",
      "[04/02/2024 09:13:09 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:09 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:10 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2902 , Training Loss : 0.0088\n",
      "[04/02/2024 09:13:10 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2137 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:10 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2172 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:10 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2186 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:10 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:10 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2196 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:11 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:11 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:11 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2186 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:11 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2186 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:11 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2186 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:11 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:12 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:12 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:12 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:12 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:12 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2186 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:13 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2191 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:13 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2186 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:13 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2186 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:13 PM : DEBUG : model_trai : ] : Average training loss : 0.005966702606929005\n",
      "[04/02/2024 09:13:13 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:13 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:13 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:13:13 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:13:13 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:13 PM : INFO  : self_train : ] : Training error of trained model : 21.23\n",
      "[04/02/2024 09:13:13 PM : INFO  : self_train : ] : Test error of the model         : 51.10\n",
      "[04/02/2024 09:13:13 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:13 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:13 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:13 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:13 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:13 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:13 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:13 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:13 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7206\n",
      "[04/02/2024 09:13:13 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:13 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:13 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.17442431873083114\n",
      "[04/02/2024 09:13:13 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:13 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:13 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:13 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7317090630531311 for class 0   \n",
      "[04/02/2024 09:13:14 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:14 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1575\n",
      "[04/02/2024 09:13:14 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.73170906, inf]\n",
      "[04/02/2024 09:13:14 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1197 \n",
      "[04/02/2024 09:13:14 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 315\n",
      "[04/02/2024 09:13:14 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : =============================== END Epoch 93 =======================\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9799498746867168, 'coverage_1': 0.149625, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7206\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : cur_query_count= 794 and max_query_count=1000\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 94 ============================\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : Number of unalabeled points  :7206\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : Current Available Query Budget: 206\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:14 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:14 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7198\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : Training data size : 1999\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2040}\n",
      "[04/02/2024 09:13:14 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:14 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:14 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1999}\n",
      "[04/02/2024 09:13:14 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:14 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:14 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2426 , Training Loss : 0.0081\n",
      "[04/02/2024 09:13:14 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2086 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:14 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2076 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:14 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2081 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:15 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2076 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:15 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2081 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:15 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2081 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:15 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2071 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:15 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2091 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:15 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2111 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:16 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2116 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:16 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2106 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:16 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2106 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:16 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2101 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:16 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2101 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:16 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2091 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:17 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2111 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:17 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2106 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:17 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2106 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:17 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2116 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:17 PM : DEBUG : model_trai : ] : Average training loss : 0.005986985774301364\n",
      "[04/02/2024 09:13:17 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:17 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:17 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.518\n",
      "[04/02/2024 09:13:17 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.518\n",
      "[04/02/2024 09:13:17 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:17 PM : INFO  : self_train : ] : Training error of trained model : 20.71\n",
      "[04/02/2024 09:13:17 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:13:17 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:17 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:17 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:17 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:17 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:18 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7198\n",
      "[04/02/2024 09:13:18 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:18 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27303035497665407\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:18 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:18 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8589272499084473 for class 0   \n",
      "[04/02/2024 09:13:18 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:18 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.85892725, inf]\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1248 \n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:13:18 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : =============================== END Epoch 94 =======================\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9671474358974359, 'coverage_1': 0.156, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7198\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : cur_query_count= 802 and max_query_count=1000\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 95 ============================\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : Number of unalabeled points  :7198\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : Current Available Query Budget: 198\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:18 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:18 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7190\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : Training data size : 2058\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 1999}\n",
      "[04/02/2024 09:13:18 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:18 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:18 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2058}\n",
      "[04/02/2024 09:13:18 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:18 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:18 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3499 , Training Loss : 0.0093\n",
      "[04/02/2024 09:13:18 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2172 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:18 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2153 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:19 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2191 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:19 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2182 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:19 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2196 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:19 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2201 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:19 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2211 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:19 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2206 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:20 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2221 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:20 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2206 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:20 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2216 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:20 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2221 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:20 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2216 , Training Loss : 0.0061\n",
      "[04/02/2024 09:13:20 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2211 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:21 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2206 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:21 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2206 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:21 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2211 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:21 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2216 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:21 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2211 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:21 PM : DEBUG : model_trai : ] : Average training loss : 0.006113390355896787\n",
      "[04/02/2024 09:13:21 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:21 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:21 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:13:21 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:13:21 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : Training error of trained model : 21.53\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:22 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7190\n",
      "[04/02/2024 09:13:22 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:22 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.16569890144467353\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:22 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:22 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7184097766876221 for class 0   \n",
      "[04/02/2024 09:13:22 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:22 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7184098, inf]\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1245 \n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:13:22 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : =============================== END Epoch 95 =======================\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9670682730923694, 'coverage_1': 0.155625, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7190\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : cur_query_count= 810 and max_query_count=1000\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 96 ============================\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : Number of unalabeled points  :7190\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : Current Available Query Budget: 190\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:22 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:22 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7182\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : Training data size : 2063\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2058}\n",
      "[04/02/2024 09:13:22 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:22 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:22 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2063}\n",
      "[04/02/2024 09:13:22 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:22 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:22 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4552 , Training Loss : 0.0115\n",
      "[04/02/2024 09:13:23 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2215 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:23 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2225 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:23 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2230 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:23 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2215 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:23 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2235 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:23 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2230 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:24 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2230 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:24 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2244 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:24 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2239 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:24 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2239 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:24 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2230 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:24 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2225 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:25 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2235 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:25 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2230 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:25 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2235 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:25 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2244 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:25 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2244 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:25 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2239 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:26 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2235 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:26 PM : DEBUG : model_trai : ] : Average training loss : 0.006251975044061572\n",
      "[04/02/2024 09:13:26 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:26 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:26 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:13:26 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : Training error of trained model : 22.25\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : Test error of the model         : 50.55\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:26 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7182\n",
      "[04/02/2024 09:13:26 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:26 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.25661981528997424\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:26 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:26 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8318300843238831 for class 0   \n",
      "[04/02/2024 09:13:26 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:26 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.162\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8318301, inf]\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1268 \n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 324\n",
      "[04/02/2024 09:13:26 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : =============================== END Epoch 96 =======================\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9645110410094637, 'coverage_1': 0.1585, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7182\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : cur_query_count= 818 and max_query_count=1000\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 97 ============================\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : Number of unalabeled points  :7182\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : Current Available Query Budget: 182\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:26 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:26 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7174\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : Training data size : 2094\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2063}\n",
      "[04/02/2024 09:13:26 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:26 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:26 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2094}\n",
      "[04/02/2024 09:13:26 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:26 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:26 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4465 , Training Loss : 0.0108\n",
      "[04/02/2024 09:13:27 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2254 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:27 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2249 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:27 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2249 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:27 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2249 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:27 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2249 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:27 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2249 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:28 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:28 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:28 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:28 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:28 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:29 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2249 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:29 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2249 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:29 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2249 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:29 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:29 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:29 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:30 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:30 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2245 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:30 PM : DEBUG : model_trai : ] : Average training loss : 0.006135113786714714\n",
      "[04/02/2024 09:13:30 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:30 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:30 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.513\n",
      "[04/02/2024 09:13:30 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.513\n",
      "[04/02/2024 09:13:30 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:30 PM : INFO  : self_train : ] : Training error of trained model : 22.11\n",
      "[04/02/2024 09:13:30 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:13:30 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:30 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:30 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:30 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:30 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:30 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:30 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:30 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:30 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7174\n",
      "[04/02/2024 09:13:30 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:30 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:30 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1608207121491432\n",
      "[04/02/2024 09:13:30 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:30 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:30 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:30 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7071868777275085 for class 0   \n",
      "[04/02/2024 09:13:30 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:30 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:13:30 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7071869, inf]\n",
      "[04/02/2024 09:13:31 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1254 \n",
      "[04/02/2024 09:13:31 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:13:31 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : =============================== END Epoch 97 =======================\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9609250398724083, 'coverage_1': 0.15675, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7174\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : cur_query_count= 826 and max_query_count=1000\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 98 ============================\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : Number of unalabeled points  :7174\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : Current Available Query Budget: 174\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:31 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:31 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7166\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : Training data size : 2088\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2094}\n",
      "[04/02/2024 09:13:31 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:31 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:31 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2088}\n",
      "[04/02/2024 09:13:31 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:31 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:31 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5053 , Training Loss : 0.0117\n",
      "[04/02/2024 09:13:31 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2280 , Training Loss : 0.0067\n",
      "[04/02/2024 09:13:31 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2280 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:31 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:31 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:32 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:32 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:32 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:32 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:32 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:32 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:33 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:33 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:33 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:33 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:33 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:34 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:34 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:34 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:34 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2280 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:34 PM : DEBUG : model_trai : ] : Average training loss : 0.00630033679192322\n",
      "[04/02/2024 09:13:34 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:34 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:34 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.511\n",
      "[04/02/2024 09:13:34 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.511\n",
      "[04/02/2024 09:13:34 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:34 PM : INFO  : self_train : ] : Training error of trained model : 22.80\n",
      "[04/02/2024 09:13:34 PM : INFO  : self_train : ] : Test error of the model         : 50.55\n",
      "[04/02/2024 09:13:34 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:34 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:34 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:34 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:34 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:34 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:34 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:34 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:34 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7166\n",
      "[04/02/2024 09:13:35 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:35 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:35 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2634817587137222\n",
      "[04/02/2024 09:13:35 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:35 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:35 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:35 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8350194692611694 for class 0   \n",
      "[04/02/2024 09:13:35 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:35 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1635\n",
      "[04/02/2024 09:13:35 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.83501947, inf]\n",
      "[04/02/2024 09:13:35 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1278 \n",
      "[04/02/2024 09:13:35 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 327\n",
      "[04/02/2024 09:13:35 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : =============================== END Epoch 98 =======================\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9585289514866979, 'coverage_1': 0.15975, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7166\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : cur_query_count= 834 and max_query_count=1000\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 99 ============================\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : Number of unalabeled points  :7166\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : Current Available Query Budget: 166\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:35 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:35 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7158\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : Training data size : 2120\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2088}\n",
      "[04/02/2024 09:13:35 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:35 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:35 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2120}\n",
      "[04/02/2024 09:13:35 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:35 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:35 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2915 , Training Loss : 0.0090\n",
      "[04/02/2024 09:13:35 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2297 , Training Loss : 0.0067\n",
      "[04/02/2024 09:13:36 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2283 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:36 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2292 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:36 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2292 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:36 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2288 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:36 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2288 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:36 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2292 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:37 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2288 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:37 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2292 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:37 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2292 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:37 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2288 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:37 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2288 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:37 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2288 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:38 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2283 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:38 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2288 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:38 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2283 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:38 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2288 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:38 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2288 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:38 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2288 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:39 PM : DEBUG : model_trai : ] : Average training loss : 0.00626944951338213\n",
      "[04/02/2024 09:13:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:39 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.513\n",
      "[04/02/2024 09:13:39 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.513\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : Training error of trained model : 22.83\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : Test error of the model         : 50.45\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:39 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7158\n",
      "[04/02/2024 09:13:39 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:39 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1756338673830032\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:39 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:39 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7250942587852478 for class 0   \n",
      "[04/02/2024 09:13:39 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:39 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.163\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.72509426, inf]\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1257 \n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 326\n",
      "[04/02/2024 09:13:39 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : =============================== END Epoch 99 =======================\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9657915672235481, 'coverage_1': 0.157125, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7158\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : cur_query_count= 842 and max_query_count=1000\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 100 ============================\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : Number of unalabeled points  :7158\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : Current Available Query Budget: 158\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:39 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:39 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7150\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : Training data size : 2107\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2120}\n",
      "[04/02/2024 09:13:39 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:39 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:39 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2107}\n",
      "[04/02/2024 09:13:39 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:39 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:39 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2245 , Training Loss : 0.0078\n",
      "[04/02/2024 09:13:40 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2273 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:40 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2292 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:40 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2302 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:40 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2297 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:40 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2292 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:41 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:41 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2292 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:41 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:41 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:41 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2292 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:41 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:42 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2292 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:42 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2292 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:42 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:42 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:42 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:42 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2292 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:43 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:43 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2288 , Training Loss : 0.0062\n",
      "[04/02/2024 09:13:43 PM : DEBUG : model_trai : ] : Average training loss : 0.00601246413602466\n",
      "[04/02/2024 09:13:43 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:43 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:43 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5135\n",
      "[04/02/2024 09:13:43 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5135\n",
      "[04/02/2024 09:13:43 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:43 PM : INFO  : self_train : ] : Training error of trained model : 22.73\n",
      "[04/02/2024 09:13:43 PM : INFO  : self_train : ] : Test error of the model         : 50.50\n",
      "[04/02/2024 09:13:43 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:43 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:43 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:43 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:43 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:43 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:43 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:43 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:43 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7150\n",
      "[04/02/2024 09:13:43 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:43 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:43 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.18603313159942628\n",
      "[04/02/2024 09:13:43 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:43 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:43 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:43 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.738820493221283 for class 0   \n",
      "[04/02/2024 09:13:43 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:43 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.163\n",
      "[04/02/2024 09:13:43 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7388205, inf]\n",
      "[04/02/2024 09:13:44 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1259 \n",
      "[04/02/2024 09:13:44 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 326\n",
      "[04/02/2024 09:13:44 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : =============================== END Epoch 100 =======================\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9642573471008737, 'coverage_1': 0.157375, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7150\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : cur_query_count= 850 and max_query_count=1000\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 101 ============================\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : Number of unalabeled points  :7150\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : Current Available Query Budget: 150\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:44 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:44 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7142\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : Training data size : 2117\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2107}\n",
      "[04/02/2024 09:13:44 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:44 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:44 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2117}\n",
      "[04/02/2024 09:13:44 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:44 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:44 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4388 , Training Loss : 0.0104\n",
      "[04/02/2024 09:13:44 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2263 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:44 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2286 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:44 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2324 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:45 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2315 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:45 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2315 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:45 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2324 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:45 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2315 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:45 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2324 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:45 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2319 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:46 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2319 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:46 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2310 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:46 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2310 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:46 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2319 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:46 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2310 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:47 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2310 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:47 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2310 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:47 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2310 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:47 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2310 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:47 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2310 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:47 PM : DEBUG : model_trai : ] : Average training loss : 0.006316112532839992\n",
      "[04/02/2024 09:13:47 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:47 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:47 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.518\n",
      "[04/02/2024 09:13:47 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.518\n",
      "[04/02/2024 09:13:47 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : Training error of trained model : 22.58\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:48 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7142\n",
      "[04/02/2024 09:13:48 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:48 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1581352471709252\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:48 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7094891667366028 for class 0   \n",
      "[04/02/2024 09:13:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:48 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.70948917, inf]\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1246 \n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:13:48 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : =============================== END Epoch 101 =======================\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9654895666131621, 'coverage_1': 0.15575, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7142\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : cur_query_count= 858 and max_query_count=1000\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 102 ============================\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : Number of unalabeled points  :7142\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : Current Available Query Budget: 142\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:48 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:48 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7134\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : Training data size : 2112\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2117}\n",
      "[04/02/2024 09:13:48 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:48 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:48 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2112}\n",
      "[04/02/2024 09:13:48 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:48 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:48 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4626 , Training Loss : 0.0106\n",
      "[04/02/2024 09:13:48 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2339 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:49 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2292 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:49 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2306 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:49 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2334 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:49 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2344 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:49 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2320 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:50 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2344 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:50 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2353 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:50 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2353 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:50 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2348 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:50 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2348 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:50 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2348 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:51 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2344 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:51 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2344 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:51 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2339 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:51 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2348 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:51 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2348 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:51 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2363 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:52 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2348 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:52 PM : DEBUG : model_trai : ] : Average training loss : 0.006202060317359917\n",
      "[04/02/2024 09:13:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:52 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:13:52 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : Training error of trained model : 23.01\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : Test error of the model         : 50.45\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:52 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7134\n",
      "[04/02/2024 09:13:52 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:52 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23311617213487626\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:52 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8008858561515808 for class 0   \n",
      "[04/02/2024 09:13:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:52 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.162\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.80088586, inf]\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1252 \n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 324\n",
      "[04/02/2024 09:13:52 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : =============================== END Epoch 102 =======================\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9648562300319489, 'coverage_1': 0.1565, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7134\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : cur_query_count= 866 and max_query_count=1000\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 103 ============================\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : Number of unalabeled points  :7134\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : Current Available Query Budget: 134\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:52 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:52 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7126\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : Training data size : 2126\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2112}\n",
      "[04/02/2024 09:13:52 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:52 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:52 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2126}\n",
      "[04/02/2024 09:13:52 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:52 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:53 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2244 , Training Loss : 0.0076\n",
      "[04/02/2024 09:13:53 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2267 , Training Loss : 0.0067\n",
      "[04/02/2024 09:13:53 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2328 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:53 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2342 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:53 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2352 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:53 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:54 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2347 , Training Loss : 0.0063\n",
      "[04/02/2024 09:13:54 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:54 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:54 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:54 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:55 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:55 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2342 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:55 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:55 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:55 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:55 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:56 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:56 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:56 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:56 PM : DEBUG : model_trai : ] : Average training loss : 0.006197964357298044\n",
      "[04/02/2024 09:13:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:13:56 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.516\n",
      "[04/02/2024 09:13:56 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.516\n",
      "[04/02/2024 09:13:56 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:13:56 PM : INFO  : self_train : ] : Training error of trained model : 22.77\n",
      "[04/02/2024 09:13:56 PM : INFO  : self_train : ] : Test error of the model         : 50.55\n",
      "[04/02/2024 09:13:56 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:13:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:56 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:13:56 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:13:56 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:13:56 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:13:56 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:13:56 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:13:56 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7126\n",
      "[04/02/2024 09:13:56 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:13:56 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:13:56 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.19309029692411425\n",
      "[04/02/2024 09:13:56 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:13:56 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:13:56 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:13:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7513222694396973 for class 0   \n",
      "[04/02/2024 09:13:57 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:13:57 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:13:57 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.75132227, inf]\n",
      "[04/02/2024 09:13:57 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1248 \n",
      "[04/02/2024 09:13:57 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:13:57 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : =============================== END Epoch 103 =======================\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9647435897435898, 'coverage_1': 0.156, 'coverage_2': 0}\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7126\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : cur_query_count= 874 and max_query_count=1000\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 104 ============================\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : Number of unalabeled points  :7126\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : Current Available Query Budget: 126\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:13:57 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:13:57 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7118\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : Training data size : 2130\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2126}\n",
      "[04/02/2024 09:13:57 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:57 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:13:57 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2130}\n",
      "[04/02/2024 09:13:57 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:13:57 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:13:57 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2277 , Training Loss : 0.0081\n",
      "[04/02/2024 09:13:57 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2216 , Training Loss : 0.0067\n",
      "[04/02/2024 09:13:57 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2296 , Training Loss : 0.0066\n",
      "[04/02/2024 09:13:57 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2329 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:58 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2357 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:58 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2371 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:58 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2366 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:58 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2362 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:58 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2366 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:59 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2366 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:59 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2357 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:59 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2366 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:59 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2366 , Training Loss : 0.0065\n",
      "[04/02/2024 09:13:59 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2366 , Training Loss : 0.0064\n",
      "[04/02/2024 09:13:59 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2371 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:00 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2362 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:00 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2362 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:00 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2366 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:00 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2362 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:00 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2362 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:00 PM : DEBUG : model_trai : ] : Average training loss : 0.0062356406697458315\n",
      "[04/02/2024 09:14:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:00 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5165\n",
      "[04/02/2024 09:14:00 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5165\n",
      "[04/02/2024 09:14:00 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : Training error of trained model : 22.86\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:01 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7118\n",
      "[04/02/2024 09:14:01 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:01 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23390710276365284\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:01 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:01 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8053485751152039 for class 0   \n",
      "[04/02/2024 09:14:01 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:01 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8053486, inf]\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1245 \n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:14:01 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : =============================== END Epoch 104 =======================\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9646586345381526, 'coverage_1': 0.155625, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7118\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : cur_query_count= 882 and max_query_count=1000\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 105 ============================\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : Number of unalabeled points  :7118\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : Current Available Query Budget: 118\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:01 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:01 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7110\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : Training data size : 2135\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2130}\n",
      "[04/02/2024 09:14:01 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:01 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:01 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2135}\n",
      "[04/02/2024 09:14:01 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:01 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:01 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2609 , Training Loss : 0.0084\n",
      "[04/02/2024 09:14:02 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2244 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:02 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2314 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:02 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2347 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:02 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2365 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:02 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2379 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:02 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2379 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:03 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2370 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:03 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2384 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:03 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2384 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:03 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2379 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:03 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2389 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:04 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2375 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:04 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2379 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:04 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2379 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:04 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2379 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:04 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2379 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:04 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2375 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:05 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2384 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:05 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2375 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:05 PM : DEBUG : model_trai : ] : Average training loss : 0.006247037789741062\n",
      "[04/02/2024 09:14:05 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:05 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:05 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.52\n",
      "[04/02/2024 09:14:05 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.52\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : Training error of trained model : 22.11\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : Test error of the model         : 51.50\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:05 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7110\n",
      "[04/02/2024 09:14:05 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:05 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.19239506393671035\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:05 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7578650116920471 for class 0   \n",
      "[04/02/2024 09:14:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:05 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1585\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.757865, inf]\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1184 \n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 317\n",
      "[04/02/2024 09:14:05 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:05 PM : DEBUG : self_train : ] : =============================== END Epoch 105 =======================\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9831081081081081, 'coverage_1': 0.148, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:05 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7110\n",
      "[04/02/2024 09:14:05 PM : DEBUG : self_train : ] : cur_query_count= 890 and max_query_count=1000\n",
      "[04/02/2024 09:14:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:05 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 106 ============================\n",
      "[04/02/2024 09:14:05 PM : DEBUG : self_train : ] : Number of unalabeled points  :7110\n",
      "[04/02/2024 09:14:05 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:05 PM : DEBUG : self_train : ] : Current Available Query Budget: 110\n",
      "[04/02/2024 09:14:05 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:05 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:06 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:06 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:06 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7102\n",
      "[04/02/2024 09:14:06 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:06 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:06 PM : INFO  : self_train : ] : Training data size : 2082\n",
      "[04/02/2024 09:14:06 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:06 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2135}\n",
      "[04/02/2024 09:14:06 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:06 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:06 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2082}\n",
      "[04/02/2024 09:14:06 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:06 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:06 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3429 , Training Loss : 0.0093\n",
      "[04/02/2024 09:14:06 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2248 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:06 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2224 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:06 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2209 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:06 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2214 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:07 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2200 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:07 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2205 , Training Loss : 0.0063\n",
      "[04/02/2024 09:14:07 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2209 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:07 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2262 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:07 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2257 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:07 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2229 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:08 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2224 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:08 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2248 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:08 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2243 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:08 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2224 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:08 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2262 , Training Loss : 0.0063\n",
      "[04/02/2024 09:14:08 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2238 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:09 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2248 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:09 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2262 , Training Loss : 0.0063\n",
      "[04/02/2024 09:14:09 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2257 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:09 PM : DEBUG : model_trai : ] : Average training loss : 0.006225732731421627\n",
      "[04/02/2024 09:14:09 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:09 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:09 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.518\n",
      "[04/02/2024 09:14:09 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.518\n",
      "[04/02/2024 09:14:09 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:09 PM : INFO  : self_train : ] : Training error of trained model : 22.38\n",
      "[04/02/2024 09:14:09 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:14:09 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:09 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:09 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:09 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:09 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:09 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:09 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:09 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7102\n",
      "[04/02/2024 09:14:09 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:09 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:09 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.27718084889650346\n",
      "[04/02/2024 09:14:09 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:09 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:09 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:10 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8642838597297668 for class 0   \n",
      "[04/02/2024 09:14:10 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:10 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.161\n",
      "[04/02/2024 09:14:10 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.86428386, inf]\n",
      "[04/02/2024 09:14:10 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1248 \n",
      "[04/02/2024 09:14:10 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 322\n",
      "[04/02/2024 09:14:10 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : =============================== END Epoch 106 =======================\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9671474358974359, 'coverage_1': 0.156, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7102\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : cur_query_count= 898 and max_query_count=1000\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 107 ============================\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : Number of unalabeled points  :7102\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : Current Available Query Budget: 102\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:10 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:10 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7094\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : Training data size : 2154\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2082}\n",
      "[04/02/2024 09:14:10 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:10 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:10 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2154}\n",
      "[04/02/2024 09:14:10 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:10 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:10 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3050 , Training Loss : 0.0091\n",
      "[04/02/2024 09:14:10 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2247 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:10 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2293 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:10 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2331 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:11 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2335 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:11 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2354 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:11 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2368 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:11 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2377 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:11 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2372 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:11 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2363 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:12 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2372 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:12 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2368 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:12 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2377 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:12 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2377 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:12 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2368 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:13 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2363 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:13 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2391 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:13 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2377 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:13 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2363 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:13 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2377 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:13 PM : DEBUG : model_trai : ] : Average training loss : 0.006239494882438692\n",
      "[04/02/2024 09:14:13 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:13 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:13 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:14:13 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:14:13 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : Training error of trained model : 23.21\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : Test error of the model         : 50.60\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:14 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7094\n",
      "[04/02/2024 09:14:14 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:14 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.22906384018063544\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:14 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:14 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8003806471824646 for class 0   \n",
      "[04/02/2024 09:14:14 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:14 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.80038065, inf]\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1247 \n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:14:14 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : =============================== END Epoch 107 =======================\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9647153167602245, 'coverage_1': 0.155875, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7094\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : cur_query_count= 906 and max_query_count=1000\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 108 ============================\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : Number of unalabeled points  :7094\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : Current Available Query Budget: 94\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:14 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:14 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7086\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : Training data size : 2161\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2154}\n",
      "[04/02/2024 09:14:14 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:14 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:14 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2161}\n",
      "[04/02/2024 09:14:14 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:14 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:14 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2790 , Training Loss : 0.0083\n",
      "[04/02/2024 09:14:14 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2397 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:15 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2402 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:15 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2406 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:15 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2379 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:15 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2365 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:15 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2392 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:16 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2402 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:16 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2402 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:16 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2406 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:16 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2402 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:16 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2406 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:16 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2402 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:17 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2402 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:17 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2397 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:17 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2397 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:17 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2402 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:17 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2397 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:17 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2402 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:18 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2388 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:18 PM : DEBUG : model_trai : ] : Average training loss : 0.006228773555970807\n",
      "[04/02/2024 09:14:18 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:18 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:18 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:14:18 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : Training error of trained model : 23.88\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : Test error of the model         : 50.55\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:18 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7086\n",
      "[04/02/2024 09:14:18 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:18 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2675334285199642\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:18 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:18 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8462045192718506 for class 0   \n",
      "[04/02/2024 09:14:18 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:18 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.162\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8462045, inf]\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1267 \n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 324\n",
      "[04/02/2024 09:14:18 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : =============================== END Epoch 108 =======================\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9644830307813733, 'coverage_1': 0.158375, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7086\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : cur_query_count= 914 and max_query_count=1000\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 109 ============================\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : Number of unalabeled points  :7086\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : Current Available Query Budget: 86\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:18 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:18 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7078\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : Training data size : 2189\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2161}\n",
      "[04/02/2024 09:14:18 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:18 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:18 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2189}\n",
      "[04/02/2024 09:14:18 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:18 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:19 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2426 , Training Loss : 0.0080\n",
      "[04/02/2024 09:14:19 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2344 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:19 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2371 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:19 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2394 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:19 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2389 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:19 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2385 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:20 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2380 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:20 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2389 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:20 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2380 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:20 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2371 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:20 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2380 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:20 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2389 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:21 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2385 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:21 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2389 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:21 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2385 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:21 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2380 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:21 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2389 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:22 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2385 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:22 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2380 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:22 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2380 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:22 PM : DEBUG : model_trai : ] : Average training loss : 0.006296871115619408\n",
      "[04/02/2024 09:14:22 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:22 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:22 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.513\n",
      "[04/02/2024 09:14:22 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.513\n",
      "[04/02/2024 09:14:22 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:22 PM : INFO  : self_train : ] : Training error of trained model : 22.66\n",
      "[04/02/2024 09:14:22 PM : INFO  : self_train : ] : Test error of the model         : 50.60\n",
      "[04/02/2024 09:14:22 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:22 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:22 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:22 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:22 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:22 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:22 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:22 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:22 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7078\n",
      "[04/02/2024 09:14:22 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:22 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:22 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.20537710747122764\n",
      "[04/02/2024 09:14:22 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:22 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:22 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:22 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7638289928436279 for class 0   \n",
      "[04/02/2024 09:14:22 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:22 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1595\n",
      "[04/02/2024 09:14:22 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.763829, inf]\n",
      "[04/02/2024 09:14:23 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1239 \n",
      "[04/02/2024 09:14:23 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 319\n",
      "[04/02/2024 09:14:23 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : =============================== END Epoch 109 =======================\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9685230024213075, 'coverage_1': 0.154875, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7078\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : cur_query_count= 922 and max_query_count=1000\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 110 ============================\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : Number of unalabeled points  :7078\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : Current Available Query Budget: 78\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:23 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:23 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7070\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : Training data size : 2169\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2189}\n",
      "[04/02/2024 09:14:23 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:23 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:23 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2169}\n",
      "[04/02/2024 09:14:23 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:23 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:23 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4315 , Training Loss : 0.0107\n",
      "[04/02/2024 09:14:23 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2264 , Training Loss : 0.0069\n",
      "[04/02/2024 09:14:23 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2278 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:23 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2310 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:23 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2365 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:24 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2365 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:24 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2333 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:24 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2370 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:24 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2342 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:24 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2337 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:25 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2365 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:25 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2374 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:25 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2356 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:25 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:25 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2361 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:25 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2333 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:26 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:26 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2333 , Training Loss : 0.0064\n",
      "[04/02/2024 09:14:26 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:26 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2347 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:26 PM : DEBUG : model_trai : ] : Average training loss : 0.006372069062934141\n",
      "[04/02/2024 09:14:26 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:26 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:26 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.519\n",
      "[04/02/2024 09:14:26 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.519\n",
      "[04/02/2024 09:14:26 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:26 PM : INFO  : self_train : ] : Training error of trained model : 22.45\n",
      "[04/02/2024 09:14:26 PM : INFO  : self_train : ] : Test error of the model         : 51.00\n",
      "[04/02/2024 09:14:26 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:26 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:26 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:26 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:26 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:27 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7070\n",
      "[04/02/2024 09:14:27 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:27 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1493487439751625\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:27 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:27 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7012848854064941 for class 0   \n",
      "[04/02/2024 09:14:27 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:27 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.159\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7012849, inf]\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1179 \n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 318\n",
      "[04/02/2024 09:14:27 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : =============================== END Epoch 110 =======================\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9804919423240034, 'coverage_1': 0.147375, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7070\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : cur_query_count= 930 and max_query_count=1000\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 111 ============================\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : Number of unalabeled points  :7070\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : Current Available Query Budget: 70\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:27 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:27 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7062\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : Training data size : 2117\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2169}\n",
      "[04/02/2024 09:14:27 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:27 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:27 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2117}\n",
      "[04/02/2024 09:14:27 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:27 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:27 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2305 , Training Loss : 0.0074\n",
      "[04/02/2024 09:14:27 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2286 , Training Loss : 0.0070\n",
      "[04/02/2024 09:14:28 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2291 , Training Loss : 0.0069\n",
      "[04/02/2024 09:14:28 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2286 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:28 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2282 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:28 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2310 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:28 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2296 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:28 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2296 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:29 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2305 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:29 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2291 , Training Loss : 0.0069\n",
      "[04/02/2024 09:14:29 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2296 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:29 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2305 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:29 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2315 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:29 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2296 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:30 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2277 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:30 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2296 , Training Loss : 0.0069\n",
      "[04/02/2024 09:14:30 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2343 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:30 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2324 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:30 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2324 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:31 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2300 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:31 PM : DEBUG : model_trai : ] : Average training loss : 0.006422231776557406\n",
      "[04/02/2024 09:14:31 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:31 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:31 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:14:31 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : Training error of trained model : 23.10\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:31 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7062\n",
      "[04/02/2024 09:14:31 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:31 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2712079999446869\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:31 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:31 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8558266162872314 for class 0   \n",
      "[04/02/2024 09:14:31 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:31 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.162\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8558266, inf]\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1248 \n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 324\n",
      "[04/02/2024 09:14:31 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : =============================== END Epoch 111 =======================\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.967948717948718, 'coverage_1': 0.156, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7062\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : cur_query_count= 938 and max_query_count=1000\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 112 ============================\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : Number of unalabeled points  :7062\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : Current Available Query Budget: 62\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:31 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:31 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7054\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : Training data size : 2194\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2117}\n",
      "[04/02/2024 09:14:31 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:31 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:31 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2194}\n",
      "[04/02/2024 09:14:31 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:31 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:32 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2521 , Training Loss : 0.0083\n",
      "[04/02/2024 09:14:32 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2325 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:32 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2379 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:32 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2375 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:32 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2366 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:32 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2397 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:33 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2379 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:33 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2370 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:33 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2393 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:33 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2388 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:33 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2375 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:34 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2375 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:34 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2416 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:34 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2420 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:34 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2407 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:34 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2402 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:34 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2384 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:35 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2411 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:35 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2402 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:35 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2388 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:35 PM : DEBUG : model_trai : ] : Average training loss : 0.0063373842483418165\n",
      "[04/02/2024 09:14:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:35 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:35 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5195\n",
      "[04/02/2024 09:14:35 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5195\n",
      "[04/02/2024 09:14:35 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:35 PM : INFO  : self_train : ] : Training error of trained model : 22.93\n",
      "[04/02/2024 09:14:35 PM : INFO  : self_train : ] : Test error of the model         : 51.55\n",
      "[04/02/2024 09:14:35 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:35 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:35 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:35 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:35 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:35 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:35 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:35 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:35 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7054\n",
      "[04/02/2024 09:14:35 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:35 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:35 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.19486377638578414\n",
      "[04/02/2024 09:14:35 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:35 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:35 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:35 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.7595689296722412 for class 0   \n",
      "[04/02/2024 09:14:35 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:35 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.158\n",
      "[04/02/2024 09:14:35 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.7595689, inf]\n",
      "[04/02/2024 09:14:36 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1203 \n",
      "[04/02/2024 09:14:36 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 316\n",
      "[04/02/2024 09:14:36 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : =============================== END Epoch 112 =======================\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9775561097256857, 'coverage_1': 0.150375, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7054\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : cur_query_count= 946 and max_query_count=1000\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 113 ============================\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : Number of unalabeled points  :7054\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : Current Available Query Budget: 54\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:36 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:36 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7046\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : Training data size : 2157\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2194}\n",
      "[04/02/2024 09:14:36 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:36 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:36 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2157}\n",
      "[04/02/2024 09:14:36 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:36 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:36 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4372 , Training Loss : 0.0111\n",
      "[04/02/2024 09:14:36 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2286 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:36 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2323 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:36 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2337 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:37 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2323 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:37 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2318 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:37 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2327 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:37 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2327 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:37 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2364 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:37 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2355 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:38 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2355 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:38 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2337 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:38 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2341 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:38 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2355 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:38 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2364 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:38 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2369 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:39 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2392 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:39 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2355 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:39 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2369 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:39 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2364 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:39 PM : DEBUG : model_trai : ] : Average training loss : 0.006445092548175971\n",
      "[04/02/2024 09:14:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:39 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:39 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.518\n",
      "[04/02/2024 09:14:39 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.518\n",
      "[04/02/2024 09:14:39 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : Training error of trained model : 23.60\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:40 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7046\n",
      "[04/02/2024 09:14:40 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:40 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2704872430562973\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:40 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8556007146835327 for class 0   \n",
      "[04/02/2024 09:14:40 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:40 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8556007, inf]\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1248 \n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:14:40 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : =============================== END Epoch 113 =======================\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9671474358974359, 'coverage_1': 0.156, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7046\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : cur_query_count= 954 and max_query_count=1000\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 114 ============================\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : Number of unalabeled points  :7046\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : Current Available Query Budget: 46\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:40 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:40 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7038\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : Training data size : 2210\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2157}\n",
      "[04/02/2024 09:14:40 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:40 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:40 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2210}\n",
      "[04/02/2024 09:14:40 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:40 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:40 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2462 , Training Loss : 0.0076\n",
      "[04/02/2024 09:14:40 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2385 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:41 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2385 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:41 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2389 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:42 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2403 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:42 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2421 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:43 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2416 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:43 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2394 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:43 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2443 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:44 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2412 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:44 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2407 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:44 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2416 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:45 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2448 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:45 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2421 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:45 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2425 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:46 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2403 , Training Loss : 0.0065\n",
      "[04/02/2024 09:14:46 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2407 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:46 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2425 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:47 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2430 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:47 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2425 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:47 PM : DEBUG : model_trai : ] : Average training loss : 0.006311297065108223\n",
      "[04/02/2024 09:14:47 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:47 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:47 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5145\n",
      "[04/02/2024 09:14:47 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5145\n",
      "[04/02/2024 09:14:47 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : Training error of trained model : 23.89\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : Test error of the model         : 50.45\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:48 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7038\n",
      "[04/02/2024 09:14:48 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:48 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.23793914252519607\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:48 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8081253170967102 for class 0   \n",
      "[04/02/2024 09:14:48 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:48 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8081253, inf]\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1250 \n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:14:48 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : =============================== END Epoch 114 =======================\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9648, 'coverage_1': 0.15625, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7038\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : cur_query_count= 962 and max_query_count=1000\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 115 ============================\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : Number of unalabeled points  :7038\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : Current Available Query Budget: 38\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:48 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:48 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7030\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : Training data size : 2220\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2210}\n",
      "[04/02/2024 09:14:48 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:48 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:48 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2220}\n",
      "[04/02/2024 09:14:48 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:48 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:48 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4275 , Training Loss : 0.0101\n",
      "[04/02/2024 09:14:49 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2423 , Training Loss : 0.0069\n",
      "[04/02/2024 09:14:49 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2455 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:49 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2432 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:49 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2464 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:49 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2477 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:49 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2477 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:50 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2486 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:50 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2477 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:50 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2450 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:50 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2468 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:50 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2473 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:50 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2486 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:51 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2482 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:51 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2482 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:51 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2473 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:51 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2473 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:51 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2473 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:52 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2468 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:52 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2468 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:52 PM : DEBUG : model_trai : ] : Average training loss : 0.006455849674907891\n",
      "[04/02/2024 09:14:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:52 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:52 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5145\n",
      "[04/02/2024 09:14:52 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5145\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : Training error of trained model : 24.68\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : Test error of the model         : 50.60\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:52 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7030\n",
      "[04/02/2024 09:14:52 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:52 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2705408755838871\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:52 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8506959080696106 for class 0   \n",
      "[04/02/2024 09:14:52 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:52 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1625\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.8506959, inf]\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1269 \n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 325\n",
      "[04/02/2024 09:14:52 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : =============================== END Epoch 115 =======================\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9645390070921985, 'coverage_1': 0.158625, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7030\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : cur_query_count= 970 and max_query_count=1000\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 116 ============================\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : Number of unalabeled points  :7030\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : Current Available Query Budget: 30\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:52 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:52 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7022\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:52 PM : INFO  : self_train : ] : Training data size : 2247\n",
      "[04/02/2024 09:14:53 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:53 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2220}\n",
      "[04/02/2024 09:14:53 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:53 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2247}\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2421 , Training Loss : 0.0077\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2443 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2470 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2474 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2466 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:53 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2457 , Training Loss : 0.0069\n",
      "[04/02/2024 09:14:54 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2457 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:54 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2466 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:54 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2448 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:54 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2443 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:54 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2470 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:55 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2470 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:55 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2448 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:55 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2461 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:55 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2457 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:55 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2452 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:55 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2466 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:56 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2457 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:56 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2497 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:56 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2457 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:56 PM : DEBUG : model_trai : ] : Average training loss : 0.006451055203524063\n",
      "[04/02/2024 09:14:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:56 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:14:56 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.513\n",
      "[04/02/2024 09:14:56 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.513\n",
      "[04/02/2024 09:14:56 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:14:56 PM : INFO  : self_train : ] : Training error of trained model : 24.70\n",
      "[04/02/2024 09:14:56 PM : INFO  : self_train : ] : Test error of the model         : 50.75\n",
      "[04/02/2024 09:14:56 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:14:56 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:56 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:14:56 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:14:56 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:14:56 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:14:56 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:14:56 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:14:56 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7022\n",
      "[04/02/2024 09:14:56 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:14:56 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:14:56 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.25759945634007453\n",
      "[04/02/2024 09:14:56 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:14:56 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:14:56 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:14:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8318807482719421 for class 0   \n",
      "[04/02/2024 09:14:56 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:14:56 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1615\n",
      "[04/02/2024 09:14:56 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.83188075, inf]\n",
      "[04/02/2024 09:14:57 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1267 \n",
      "[04/02/2024 09:14:57 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 323\n",
      "[04/02/2024 09:14:57 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : =============================== END Epoch 116 =======================\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9652722967640095, 'coverage_1': 0.158375, 'coverage_2': 0}\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7022\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : cur_query_count= 978 and max_query_count=1000\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 117 ============================\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : Number of unalabeled points  :7022\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : Current Available Query Budget: 22\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:14:57 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:14:57 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7014\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : Training data size : 2253\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2247}\n",
      "[04/02/2024 09:14:57 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:57 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:14:57 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2253}\n",
      "[04/02/2024 09:14:57 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:14:57 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:14:57 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5011 , Training Loss : 0.0123\n",
      "[04/02/2024 09:14:57 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2428 , Training Loss : 0.0072\n",
      "[04/02/2024 09:14:57 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2468 , Training Loss : 0.0068\n",
      "[04/02/2024 09:14:57 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2472 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:58 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2486 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:58 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2468 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:58 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2477 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:58 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2472 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:58 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2468 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:59 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2472 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:59 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2468 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:59 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2463 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:59 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2472 , Training Loss : 0.0066\n",
      "[04/02/2024 09:14:59 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2468 , Training Loss : 0.0067\n",
      "[04/02/2024 09:14:59 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2463 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:00 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2463 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:00 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2459 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:00 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2463 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:00 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2468 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:00 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2468 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:00 PM : DEBUG : model_trai : ] : Average training loss : 0.006648045688703165\n",
      "[04/02/2024 09:15:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:15:00 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:15:00 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.514\n",
      "[04/02/2024 09:15:00 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.514\n",
      "[04/02/2024 09:15:00 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : Training error of trained model : 23.48\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : Test error of the model         : 50.50\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:15:01 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7014\n",
      "[04/02/2024 09:15:01 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:15:01 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.1496340550482273\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:15:01 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:15:01 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.6941301822662354 for class 0   \n",
      "[04/02/2024 09:15:01 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:15:01 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.6941302, inf]\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1236 \n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:15:01 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : =============================== END Epoch 117 =======================\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9692556634304207, 'coverage_1': 0.1545, 'coverage_2': 0}\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7014\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : cur_query_count= 986 and max_query_count=1000\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 118 ============================\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : Number of unalabeled points  :7014\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : Current Available Query Budget: 14\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : Query Batch Size = 8\n",
      "[04/02/2024 09:15:01 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : Queried 8 pts to add in training pool\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:15:01 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7006\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : Training data size : 2230\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2253}\n",
      "[04/02/2024 09:15:01 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:15:01 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:15:01 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2230}\n",
      "[04/02/2024 09:15:01 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:15:01 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:15:01 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2794 , Training Loss : 0.0082\n",
      "[04/02/2024 09:15:01 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2462 , Training Loss : 0.0068\n",
      "[04/02/2024 09:15:02 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2399 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:02 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2435 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:02 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2444 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:02 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2426 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:02 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2422 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:03 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2439 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:03 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2430 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:03 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2426 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:03 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2435 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:03 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2426 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:03 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2413 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:04 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2430 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:04 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2439 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:04 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2408 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:04 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2422 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:04 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2422 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:05 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2417 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:05 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2413 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:05 PM : DEBUG : model_trai : ] : Average training loss : 0.006360959389730062\n",
      "[04/02/2024 09:15:05 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:15:05 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:15:05 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.518\n",
      "[04/02/2024 09:15:05 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.518\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : Training error of trained model : 24.44\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : Test error of the model         : 50.60\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:15:05 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7006\n",
      "[04/02/2024 09:15:05 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:15:05 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.2373462354540825\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:15:05 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:15:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8118759393692017 for class 0   \n",
      "[04/02/2024 09:15:05 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:15:05 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1605\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.81187594, inf]\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1246 \n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 321\n",
      "[04/02/2024 09:15:05 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:15:05 PM : DEBUG : self_train : ] : =============================== END Epoch 118 =======================\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9646869983948636, 'coverage_1': 0.15575, 'coverage_2': 0}\n",
      "[04/02/2024 09:15:05 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7006\n",
      "[04/02/2024 09:15:05 PM : DEBUG : self_train : ] : cur_query_count= 994 and max_query_count=1000\n",
      "[04/02/2024 09:15:05 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:15:05 PM : DEBUG : self_train : ] : ========================= BEGIN EPOCH 119 ============================\n",
      "[04/02/2024 09:15:05 PM : DEBUG : self_train : ] : Number of unalabeled points  :7006\n",
      "[04/02/2024 09:15:05 PM : DEBUG : self_train : ] : Querying next training batch\n",
      "[04/02/2024 09:15:05 PM : DEBUG : self_train : ] : Current Available Query Budget: 6\n",
      "[04/02/2024 09:15:05 PM : DEBUG : self_train : ] : Query Batch Size = 6\n",
      "[04/02/2024 09:15:05 PM : DEBUG : margin_ran : ] : running infernce\n",
      "[04/02/2024 09:15:06 PM : INFO  : self_train : ] : Queried 6 pts to add in training pool\n",
      "[04/02/2024 09:15:06 PM : DEBUG : self_train : ] : Validation Count For Current round 2000\n",
      "[04/02/2024 09:15:06 PM : DEBUG : self_train : ] : Num Unlabeled Points After Querying :7000\n",
      "[04/02/2024 09:15:06 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:15:06 PM : INFO  : self_train : ] : ========================== Begin Model Training ===========================\n",
      "[04/02/2024 09:15:06 PM : INFO  : self_train : ] : Training data size : 2246\n",
      "[04/02/2024 09:15:06 PM : INFO  : self_train : ] : --------------- Begin Model Training ------------\n",
      "[04/02/2024 09:15:06 PM : INFO  : self_train : ] : Training conf :{'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2230}\n",
      "[04/02/2024 09:15:06 PM : INFO  : self_train : ] : Model conf : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:15:06 PM : INFO  : model_fact : ] : {'name': 'binary_logistic_regression', 'input_dimension': 2, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[04/02/2024 09:15:06 PM : DEBUG : model_trai : ] : Training conf : {'loss_function': 'std_cross_entropy', 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0.0, 'learning_rate': 0.01, 'loss_tolerance': 1e-06, 'max_epochs': 20, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'ckpt_load_path': 'None', 'ckpt_save_path': 'None', 'train_from_scratch': True, 'train_from_ckpt': False, 'log_batch_loss_freq': -1, 'device': 'cuda:0', 'store_embedding': False, 'save_ckpt': False, 'num_trials': 1, 'shuffle': True, 'use_lr_schedule': True, 'nesterov': False, 'loss_tol': 1e-06, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'mixup_alpha': 0, 'num_train_pts': 2246}\n",
      "[04/02/2024 09:15:06 PM : DEBUG : model_trai : ] : Using loss function : <class 'src.classifiers.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[04/02/2024 09:15:06 PM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[04/02/2024 09:15:06 PM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.3606 , Training Loss : 0.0099\n",
      "[04/02/2024 09:15:06 PM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2382 , Training Loss : 0.0072\n",
      "[04/02/2024 09:15:06 PM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2453 , Training Loss : 0.0069\n",
      "[04/02/2024 09:15:06 PM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2427 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:06 PM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2444 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:07 PM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2467 , Training Loss : 0.0068\n",
      "[04/02/2024 09:15:07 PM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2458 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:07 PM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2462 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:07 PM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2476 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:07 PM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2480 , Training Loss : 0.0068\n",
      "[04/02/2024 09:15:07 PM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2476 , Training Loss : 0.0068\n",
      "[04/02/2024 09:15:08 PM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2453 , Training Loss : 0.0068\n",
      "[04/02/2024 09:15:08 PM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2427 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:08 PM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2444 , Training Loss : 0.0068\n",
      "[04/02/2024 09:15:08 PM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2440 , Training Loss : 0.0068\n",
      "[04/02/2024 09:15:08 PM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2484 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:09 PM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2489 , Training Loss : 0.0067\n",
      "[04/02/2024 09:15:09 PM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2444 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:09 PM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2427 , Training Loss : 0.0068\n",
      "[04/02/2024 09:15:09 PM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2467 , Training Loss : 0.0066\n",
      "[04/02/2024 09:15:09 PM : DEBUG : model_trai : ] : Average training loss : 0.006594799211607257\n",
      "[04/02/2024 09:15:09 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:15:09 PM : INFO  : model_trai : ] : Loading best model from path: None\n",
      "[04/02/2024 09:15:09 PM : DEBUG : model_trai : ] : Validation accuracy from epoch loop : 0.5175\n",
      "[04/02/2024 09:15:09 PM : DEBUG : model_trai : ] : Validation accuracy after loaded : 0.5175\n",
      "[04/02/2024 09:15:09 PM : INFO  : self_train : ] : --------------- End Model Training ------------\n",
      "[04/02/2024 09:15:09 PM : INFO  : self_train : ] : Training error of trained model : 24.35\n",
      "[04/02/2024 09:15:09 PM : INFO  : self_train : ] : Test error of the model         : 50.65\n",
      "[04/02/2024 09:15:09 PM : INFO  : self_train : ] : ========================= End Model Training   =========================\n",
      "[04/02/2024 09:15:09 PM : INFO  : self_train : ] : ===========================================================================\n",
      "[04/02/2024 09:15:09 PM : INFO  : self_train : ] : =========================    No Post-hoc Calibration     =========================\n",
      "[04/02/2024 09:15:09 PM : INFO  : self_train : ] : ==========================================================================\n",
      "[04/02/2024 09:15:09 PM : INFO  : self_train : ] : ========================= Begin Pseudo labeling Procedure ==================\n",
      "[04/02/2024 09:15:09 PM : INFO  : pseudo_lab : ] : xxxxxxxxxxxxxxxxxxxxx  Pseudo-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:15:09 PM : INFO  : pseudo_lab : ] : ========================= Begin Pseudo-Labeling selective ==========================\n",
      "[04/02/2024 09:15:09 PM : DEBUG : pseudo_lab : ] : Pseudo Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'pseudo_label_err_threshold': 0.05, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fixed_threshold': 0.95}\n",
      "[04/02/2024 09:15:09 PM : INFO  : pseudo_lab : ] : Number of unlabeled points : 7000\n",
      "[04/02/2024 09:15:09 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:15:09 PM : INFO  : pseudo_lab : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:15:10 PM : DEBUG : pseudo_lab : ] : Expected Calibration Error on Validation set : 0.22870943474769592\n",
      "[04/02/2024 09:15:10 PM : INFO  : pseudo_lab : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:15:10 PM : INFO  : pseudo_lab : ] : Using Pseudo-Labeling Error Threshold = 0.05\n",
      "[04/02/2024 09:15:10 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:15:10 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.799778938293457 for class 0   \n",
      "[04/02/2024 09:15:10 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:15:10 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.16\n",
      "[04/02/2024 09:15:10 PM : INFO  : pseudo_lab : ] : pseudo-labeling thresholds from val set: [0.79977894, inf]\n",
      "[04/02/2024 09:15:10 PM : INFO  : pseudo_lab : ] : Num pseudo labeled points : 1245 \n",
      "[04/02/2024 09:15:10 PM : INFO  : pseudo_lab : ] : Num validation pts to remove : 320\n",
      "[04/02/2024 09:15:10 PM : INFO  : pseudo_lab : ] : ============================== Done Pseudo-Labeling ==============================\n",
      "[04/02/2024 09:15:10 PM : INFO  : self_train : ] : ========================= End Pseudo labeling Procedure  ===================\n",
      "[04/02/2024 09:15:10 PM : DEBUG : self_train : ] : =============================== END Epoch 119 =======================\n",
      "[04/02/2024 09:15:10 PM : INFO  : self_train : ] : {'pseudo_labeled_acc': 0.9670682730923694, 'coverage_1': 0.155625, 'coverage_2': 0}\n",
      "[04/02/2024 09:15:10 PM : DEBUG : self_train : ] : Unlabeled count in check_stop_criterion 7000\n",
      "[04/02/2024 09:15:10 PM : DEBUG : self_train : ] : cur_query_count= 1000 and max_query_count=1000\n",
      "[04/02/2024 09:15:10 PM : INFO  : 187494373 : ] : Self Training Loop Done\n"
     ]
    }
   ],
   "source": [
    "set_seed(conf['random_seed'])\n",
    "\n",
    "dm = DataManager(conf,logger,lib=conf['model_conf']['lib'])\n",
    "\n",
    "logger.info('Loaded dataset {}'.format(conf['data_conf']['name']))\n",
    "logger.info(f' std_train_size : {len(dm.ds_std_train)} and  std_val_size: {len(dm.ds_std_val)}')\n",
    "\n",
    "st = SelfTraining(conf,dm,logger)\n",
    "\n",
    "st.init()\n",
    "\n",
    "lst_epoch_out = st.run_al_loop()\n",
    "\n",
    "logger.info('Self Training Loop Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : xxxxxxxxxxxxxxxxxxxxx  Auto-labeling actual remaining unlabeled data  xxxxxxxxxxxxxxxxxxxxx\n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : ========================= Begin Auto-Labeling selective ==========================\n",
      "[04/02/2024 09:15:18 PM : DEBUG : auto_label : ] : Auto Labeling Conf : {'method_name': 'selective', 'score_type': 'confidence', 'class_wise': 'independent', 'auto_label_err_threshold': 0.01, 'C_1': 0.25, 'ucb': 'sigma', 'threshold_estimation': 'val_estimate', 'fast': True}\n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : Number of unlabeled points : 5831\n",
      "[04/02/2024 09:15:18 PM : INFO  : data_manag : ] :  Cur calib ds size : 0\n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : Using number of validation points : 2000\n",
      "[04/02/2024 09:15:18 PM : DEBUG : auto_label : ] : Expected Calibration Error on Validation set : 0.22870943474769592\n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : Determining Thresholds : Class Wise : independent\n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : Using Auto-Labeling Error Threshold = 0.01\n",
      "[04/02/2024 09:15:18 PM : DEBUG : threshold_ : ] : C_1 = 0.25 UCB = sigma\n",
      "[04/02/2024 09:15:18 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=0.8120412826538086 for class 0   \n",
      "[04/02/2024 09:15:18 PM : INFO  : threshold_ : ] : auto-labeling threshold t_i=inf for class 1   \n",
      "[04/02/2024 09:15:18 PM : INFO  : threshold_ : ] : coverage while threshold estimation : 0.1535\n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : auto-labeling thresholds from val set: [0.8120413, inf]\n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : Num auto labeled points : 0 \n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : Num validation pts to remove : 307\n",
      "[04/02/2024 09:15:18 PM : INFO  : auto_label : ] : ============================== Done Auto-Labeling ==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auto_labeled_acc': 0.9897348160821214,\n",
       " 'coverage_1': 0.146125,\n",
       " 'coverage_2': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "auto_labeler = AutoLabeling(conf,dm,st.cur_clf,logger)\n",
    "out = auto_labeler.run()\n",
    "dm.get_auto_labeling_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "act-lbl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
