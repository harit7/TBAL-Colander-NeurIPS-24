{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "from core.run_lib import * \n",
    "from core.passive_learning import * \n",
    "conf = OmegaConf.load('../../../configs/test/temp_conf.yaml')\n",
    "#run_conf(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/05/2023 12:03:27 AM : DEBUG : data_manag : ] : (6000, 30)\n",
      "[09/05/2023 12:03:27 AM : INFO  : data_manag : ] : Loaded dataset unif_unit_ball\n",
      "[09/05/2023 12:03:27 AM : INFO  : data_manag : ] : Std train size: 6000 and Std. Val. Size:4000\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : Unlabeled count in check_stop_criterion 6000\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : cur_query_count= 0 and max_query_count=500\n",
      "[09/05/2023 12:03:27 AM : INFO  : active_lab : ] : ===========================================================================\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : ========================= BEGIN EPOCH 0 ============================\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : Number of unalabeled points  :6000\n",
      "[09/05/2023 12:03:27 AM : INFO  : active_lab : ] : Querying first batches of training and validation samples.\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : Querying 100 seed training points\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : Queried 100 seed points for training\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : Validation Data Size :1000\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : Validation Count For Current round 1000\n",
      "[09/05/2023 12:03:27 AM : DEBUG : active_lab : ] : Num Unlabeled Points After Querying :5900\n",
      "[09/05/2023 12:03:27 AM : INFO  : active_lab : ] : ===========================================================================\n",
      "[09/05/2023 12:03:27 AM : INFO  : active_lab : ] : ========================== Begin Model Training ===========================\n",
      "[09/05/2023 12:03:27 AM : INFO  : pytorch_cl : ] : {'model_name': 'binary_logistic_regression', 'input_dimension': 30, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[09/05/2023 12:03:27 AM : DEBUG : model_trai : ] : Training conf : {'optimizer': 'sgd', 'learning_rate': 2.0, 'loss_tolerance': 1e-06, 'max_epochs': 40, 'normalize_weights': False, 'batch_size': 64, 'train_err_tol': -1, 'device': 'cuda:0', 'store_embedding': False, 'ckpt_load_path': None, 'save_ckpt': False, 'num_trials': 1, 'ckpt_save_path': None, 'train_from_scratch': True, 'train_from_ckpt': False, 'loss_function': 'std_cross_entropy', 'weight_decay': 0.0001, 'momentum': 0.9, 'optimizer_name': 'sgd', 'loss_tol': 1e-06, 'max_max_epochs': 10000, 'shuffle': False, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'use_lr_schedule': True, 'log_batch_loss_freq': 20, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'nesterov': False, 'num_train_pts': 100}\n",
      "[09/05/2023 12:03:27 AM : DEBUG : model_trai : ] : Using loss function : <class 'models.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[09/05/2023 12:03:27 AM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[09/05/2023 12:03:28 AM : DEBUG : model_trai : ] : Train Epoch: 0 [0/100 (0%)]\tLoss: 0.714316 \t result: {'loss': 0.7143158316612244}\n",
      "[09/05/2023 12:03:28 AM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.4800 , Training Loss : 0.0137\n",
      "[09/05/2023 12:03:28 AM : DEBUG : model_trai : ] : Train Epoch: 1 [0/100 (0%)]\tLoss: 0.530077 \t result: {'loss': 0.530076801776886}\n",
      "[09/05/2023 12:03:28 AM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1000 , Training Loss : 0.0099\n",
      "[09/05/2023 12:03:28 AM : DEBUG : model_trai : ] : Train Epoch: 2 [0/100 (0%)]\tLoss: 0.345905 \t result: {'loss': 0.34590476751327515}\n",
      "[09/05/2023 12:03:28 AM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0800 , Training Loss : 0.0066\n",
      "[09/05/2023 12:03:28 AM : DEBUG : model_trai : ] : Train Epoch: 3 [0/100 (0%)]\tLoss: 0.248513 \t result: {'loss': 0.24851290881633759}\n",
      "[09/05/2023 12:03:28 AM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0900 , Training Loss : 0.0048\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Train Epoch: 4 [0/100 (0%)]\tLoss: 0.197406 \t result: {'loss': 0.1974058598279953}\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0800 , Training Loss : 0.0037\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Train Epoch: 5 [0/100 (0%)]\tLoss: 0.164317 \t result: {'loss': 0.1643172949552536}\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0500 , Training Loss : 0.0030\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Train Epoch: 6 [0/100 (0%)]\tLoss: 0.139421 \t result: {'loss': 0.13942117989063263}\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0500 , Training Loss : 0.0025\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Train Epoch: 7 [0/100 (0%)]\tLoss: 0.120133 \t result: {'loss': 0.1201326996088028}\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0300 , Training Loss : 0.0021\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Train Epoch: 8 [0/100 (0%)]\tLoss: 0.105627 \t result: {'loss': 0.10562735050916672}\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0100 , Training Loss : 0.0018\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Train Epoch: 9 [0/100 (0%)]\tLoss: 0.095009 \t result: {'loss': 0.09500861912965775}\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0100 , Training Loss : 0.0016\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Train Epoch: 10 [0/100 (0%)]\tLoss: 0.087199 \t result: {'loss': 0.08719887584447861}\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0000 , Training Loss : 0.0014\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Train Epoch: 11 [0/100 (0%)]\tLoss: 0.081237 \t result: {'loss': 0.08123708516359329}\n",
      "[09/05/2023 12:03:29 AM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0000 , Training Loss : 0.0013\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Train Epoch: 12 [0/100 (0%)]\tLoss: 0.076444 \t result: {'loss': 0.0764438807964325}\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0100 , Training Loss : 0.0012\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Train Epoch: 13 [0/100 (0%)]\tLoss: 0.072423 \t result: {'loss': 0.0724232867360115}\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0000 , Training Loss : 0.0012\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Train Epoch: 14 [0/100 (0%)]\tLoss: 0.068983 \t result: {'loss': 0.06898267567157745}\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0000 , Training Loss : 0.0011\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Train Epoch: 15 [0/100 (0%)]\tLoss: 0.066040 \t result: {'loss': 0.06604035198688507}\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0000 , Training Loss : 0.0011\n",
      "[09/05/2023 12:03:30 AM : DEBUG : model_trai : ] : Train Epoch: 16 [0/100 (0%)]\tLoss: 0.063556 \t result: {'loss': 0.06355591863393784}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/hdd2/harit/workspace/TBAL-calib/experiments/Calib-Exp/Test/test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcastle/hdd2/harit/workspace/TBAL-calib/experiments/Calib-Exp/Test/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m act_lbl \u001b[39m=\u001b[39m ActiveLabeling(conf,dm,logger)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcastle/hdd2/harit/workspace/TBAL-calib/experiments/Calib-Exp/Test/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m act_lbl\u001b[39m.\u001b[39minit()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcastle/hdd2/harit/workspace/TBAL-calib/experiments/Calib-Exp/Test/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m lst_epoch_out \u001b[39m=\u001b[39m act_lbl\u001b[39m.\u001b[39;49mrun_al_loop()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcastle/hdd2/harit/workspace/TBAL-calib/experiments/Calib-Exp/Test/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mAL Loop Done\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcastle/hdd2/harit/workspace/TBAL-calib/experiments/Calib-Exp/Test/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#test_err = al.get_test_error(al.cur_clf,test_set,conf['inference_conf'])\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/TBAL-calib/experiments/Calib-Exp/Test/../../../core/active_labeling.py:254\u001b[0m, in \u001b[0;36mActiveLabeling.run_al_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m prev_q \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    250\u001b[0m \u001b[39mwhile\u001b[39;00m(\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_stopping_criterion()):\n\u001b[1;32m    251\u001b[0m     \n\u001b[1;32m    252\u001b[0m     \u001b[39m#self.cur_query_count += prev_q\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     epoch_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_one_epoch()\n\u001b[1;32m    255\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    256\u001b[0m     \u001b[39m#print(epoch_out)\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/TBAL-calib/experiments/Calib-Exp/Test/../../../core/active_labeling.py:161\u001b[0m, in \u001b[0;36mActiveLabeling.run_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# go to next epoch and query more points.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m epoch_out \n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_clf \u001b[39m=\u001b[39m train_model(cur_train_ds,conf\u001b[39m.\u001b[39;49mmodel_conf, conf\u001b[39m.\u001b[39;49mtraining_conf, conf\u001b[39m.\u001b[39;49minference_conf, \n\u001b[1;32m    162\u001b[0m                            logger,cur_val_ds)\n\u001b[1;32m    164\u001b[0m train_err    \u001b[39m=\u001b[39m get_test_error(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_clf,cur_train_ds, conf\u001b[39m.\u001b[39minference_conf)\n\u001b[1;32m    166\u001b[0m test_err     \u001b[39m=\u001b[39m get_test_error(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_clf,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds_std_test, conf\u001b[39m.\u001b[39minference_conf)\n",
      "File \u001b[0;32m~/workspace/TBAL-calib/experiments/Calib-Exp/Test/../../../core/model_utils.py:20\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_dataset, model_conf, training_conf, infernce_conf, logger, cur_val_ds)\u001b[0m\n\u001b[1;32m     17\u001b[0m S \u001b[39m=\u001b[39m training_conf[\u001b[39m'\u001b[39m\u001b[39mnum_trials\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[39m#if(S==1):\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m clf\u001b[39m.\u001b[39;49mfit(train_dataset, training_conf,cur_val_ds)\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m(S\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     23\u001b[0m     min_train_err \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n",
      "File \u001b[0;32m~/workspace/TBAL-calib/experiments/Calib-Exp/Test/../../../models/torch/pytorch_clf.py:91\u001b[0m, in \u001b[0;36mPyTorchClassifier.fit\u001b[0;34m(self, dataset, training_conf, val_set)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39melif\u001b[39;00m(method\u001b[39m==\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m method\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvanila\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     90\u001b[0m     model_training \u001b[39m=\u001b[39m ModelTraining(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger)\n\u001b[0;32m---> 91\u001b[0m     out \u001b[39m=\u001b[39m model_training\u001b[39m.\u001b[39;49mtrain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,dataset,training_conf,val_set\u001b[39m=\u001b[39;49mval_set)\n\u001b[1;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/workspace/TBAL-calib/experiments/Calib-Exp/Test/../../../models/torch/model_training.py:216\u001b[0m, in \u001b[0;36mModelTraining.train\u001b[0;34m(self, model, dataset, train_params, val_set)\u001b[0m\n\u001b[1;32m    213\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mTraining Epoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Begins \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch))\n\u001b[1;32m    214\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mEpoch:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Using learning rate : \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch,lr))\n\u001b[0;32m--> 216\u001b[0m epoch_loss, training_err \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_one_epoch(model,train_data_loader,train_params,epoch_state)\n\u001b[1;32m    218\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m Training Error : \u001b[39m\u001b[39m{\u001b[39;00mtraining_err\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m , Training Loss : \u001b[39m\u001b[39m{\u001b[39;00mepoch_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    220\u001b[0m stop \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \n",
      "File \u001b[0;32m~/workspace/TBAL-calib/experiments/Calib-Exp/Test/../../../models/torch/model_training.py:109\u001b[0m, in \u001b[0;36mModelTraining.train_one_epoch\u001b[0;34m(self, model, train_data_loader, train_params, epoch_state)\u001b[0m\n\u001b[1;32m    105\u001b[0m y_hat \u001b[39m=\u001b[39m []\n\u001b[1;32m    106\u001b[0m y_true \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 109\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target, idx) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data_loader):\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data,torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    112\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/act-learn-2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/act-learn-2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1317\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1317\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \n\u001b[1;32m   1322\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/act-learn-2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1438\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1439\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1443\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1444\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/anaconda3/envs/act-learn-2/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/act-learn-2/lib/python3.10/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/act-learn-2/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/act-learn-2/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "logger   = get_logger('../../../temp/logs/act_lbl_test.log',stdout_redirect=True,level=logging.DEBUG)\n",
    "\n",
    "set_seed(conf['random_seed'])\n",
    "\n",
    "dm = DataManager(conf,logger)\n",
    "len(dm.ds_std_train), len(dm.ds_std_val)\n",
    "\n",
    "act_lbl = ActiveLabeling(conf,dm,logger)\n",
    "\n",
    "act_lbl.init()\n",
    "\n",
    "lst_epoch_out = act_lbl.run_al_loop()\n",
    "\n",
    "logger.info('AL Loop Done')\n",
    "#test_err = al.get_test_error(al.cur_clf,test_set,conf['inference_conf'])\n",
    "out =  dm.get_auto_labeling_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf['train_pts_query_conf']['seed_train_size']= 10 \n",
    "conf['train_pts_query_conf']['max_num_train_pts']= 50\n",
    "\n",
    "conf['training_conf']['train_err_tol'] = -1\n",
    "conf['training_conf']['max_epochs'] = 50\n",
    "conf['training_conf']['weight_decay'] = 0.0\n",
    "conf['training_conf']['learning_rate'] = 1.0\n",
    "conf['training_conf']['use_lr_schedule'] = False \n",
    "conf['training_conf']['optimizer_name'] = 'sgd'\n",
    "conf['training_conf']['batch_size'] = 32\n",
    "conf['training_conf']['momentum'] = 0.9\n",
    "conf['training_conf']['log_batch_loss_freq']=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/05/2023 12:07:55 AM : DEBUG : data_manag : ] : (6000, 30)\n",
      "[09/05/2023 12:07:55 AM : INFO  : data_manag : ] : Loaded dataset unif_unit_ball\n",
      "[09/05/2023 12:07:55 AM : INFO  : data_manag : ] : Std train size: 6000 and Std. Val. Size:4000\n",
      "[09/05/2023 12:07:55 AM : DEBUG : passive_le : ] : Querying 10 seed training points\n",
      "[09/05/2023 12:07:55 AM : DEBUG : passive_le : ] : Queried 10 seed points for training\n",
      "[09/05/2023 12:07:55 AM : DEBUG : passive_le : ] : Validation Data Size :1000\n",
      "[09/05/2023 12:07:55 AM : DEBUG : passive_le : ] : Querying rest of the training points 40 in single batch\n",
      "[09/05/2023 12:07:55 AM : INFO  : passive_le : ] : Labeled data size for training: 50\n",
      "[09/05/2023 12:07:55 AM : INFO  : pytorch_cl : ] : {'model_name': 'binary_logistic_regression', 'input_dimension': 30, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[09/05/2023 12:07:55 AM : INFO  : passive_le : ] : --------------- Begin Model Training ------------\n",
      "[09/05/2023 12:07:55 AM : INFO  : passive_le : ] : Training conf :{'optimizer': 'sgd', 'learning_rate': 1.0, 'loss_tolerance': 1e-06, 'max_epochs': 50, 'normalize_weights': False, 'batch_size': 32, 'train_err_tol': -1, 'device': 'cuda:0', 'store_embedding': False, 'ckpt_load_path': None, 'save_ckpt': False, 'num_trials': 1, 'ckpt_save_path': None, 'train_from_scratch': True, 'train_from_ckpt': False, 'weight_decay': 0.0, 'use_lr_schedule': False, 'optimizer_name': 'sgd', 'momentum': 0.9, 'log_batch_loss_freq': -1}\n",
      "[09/05/2023 12:07:55 AM : INFO  : passive_le : ] : Model conf : {'model_name': 'binary_logistic_regression', 'input_dimension': 30, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[09/05/2023 12:07:55 AM : INFO  : pytorch_cl : ] : {'model_name': 'binary_logistic_regression', 'input_dimension': 30, 'num_classes': 2, 'fit_intercept': False, 'lib': 'pytorch'}\n",
      "[09/05/2023 12:07:55 AM : DEBUG : model_trai : ] : Training conf : {'optimizer': 'sgd', 'learning_rate': 1.0, 'loss_tolerance': 1e-06, 'max_epochs': 50, 'normalize_weights': False, 'batch_size': 32, 'train_err_tol': -1, 'device': 'cuda:0', 'store_embedding': False, 'ckpt_load_path': None, 'save_ckpt': False, 'num_trials': 1, 'ckpt_save_path': None, 'train_from_scratch': True, 'train_from_ckpt': False, 'weight_decay': 0.0, 'use_lr_schedule': False, 'optimizer_name': 'sgd', 'momentum': 0.9, 'log_batch_loss_freq': -1, 'loss_function': 'std_cross_entropy', 'loss_tol': 1e-06, 'max_max_epochs': 10000, 'shuffle': False, 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'log_train_ece': False, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'log_train_ece_freq': 5, 'nesterov': False, 'num_train_pts': 50}\n",
      "[09/05/2023 12:07:55 AM : DEBUG : model_trai : ] : Using loss function : <class 'models.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[09/05/2023 12:07:55 AM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[09/05/2023 12:07:57 AM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.5200 , Training Loss : 0.0284\n",
      "[09/05/2023 12:07:57 AM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.1800 , Training Loss : 0.0236\n",
      "[09/05/2023 12:07:57 AM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.0600 , Training Loss : 0.0176\n",
      "[09/05/2023 12:07:57 AM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.0200 , Training Loss : 0.0129\n",
      "[09/05/2023 12:07:57 AM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.0200 , Training Loss : 0.0098\n",
      "[09/05/2023 12:07:57 AM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.0200 , Training Loss : 0.0077\n",
      "[09/05/2023 12:07:58 AM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.0200 , Training Loss : 0.0062\n",
      "[09/05/2023 12:07:58 AM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.0200 , Training Loss : 0.0050\n",
      "[09/05/2023 12:07:58 AM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.0200 , Training Loss : 0.0042\n",
      "[09/05/2023 12:07:58 AM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.0000 , Training Loss : 0.0035\n",
      "[09/05/2023 12:07:58 AM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.0000 , Training Loss : 0.0030\n",
      "[09/05/2023 12:07:58 AM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.0000 , Training Loss : 0.0026\n",
      "[09/05/2023 12:07:58 AM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.0000 , Training Loss : 0.0023\n",
      "[09/05/2023 12:07:58 AM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.0000 , Training Loss : 0.0021\n",
      "[09/05/2023 12:07:59 AM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.0000 , Training Loss : 0.0019\n",
      "[09/05/2023 12:07:59 AM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.0000 , Training Loss : 0.0017\n",
      "[09/05/2023 12:07:59 AM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.0000 , Training Loss : 0.0016\n",
      "[09/05/2023 12:07:59 AM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.0000 , Training Loss : 0.0015\n",
      "[09/05/2023 12:07:59 AM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.0000 , Training Loss : 0.0014\n",
      "[09/05/2023 12:07:59 AM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.0000 , Training Loss : 0.0013\n",
      "[09/05/2023 12:07:59 AM : DEBUG : model_trai : ] : Epoch: 20 Training Error : 0.0000 , Training Loss : 0.0013\n",
      "[09/05/2023 12:07:59 AM : DEBUG : model_trai : ] : Epoch: 21 Training Error : 0.0000 , Training Loss : 0.0012\n",
      "[09/05/2023 12:08:00 AM : DEBUG : model_trai : ] : Epoch: 22 Training Error : 0.0000 , Training Loss : 0.0012\n",
      "[09/05/2023 12:08:00 AM : DEBUG : model_trai : ] : Epoch: 23 Training Error : 0.0000 , Training Loss : 0.0011\n",
      "[09/05/2023 12:08:00 AM : DEBUG : model_trai : ] : Epoch: 24 Training Error : 0.0000 , Training Loss : 0.0011\n",
      "[09/05/2023 12:08:00 AM : DEBUG : model_trai : ] : Epoch: 25 Training Error : 0.0000 , Training Loss : 0.0011\n",
      "[09/05/2023 12:08:00 AM : DEBUG : model_trai : ] : Epoch: 26 Training Error : 0.0000 , Training Loss : 0.0010\n",
      "[09/05/2023 12:08:00 AM : DEBUG : model_trai : ] : Epoch: 27 Training Error : 0.0000 , Training Loss : 0.0010\n",
      "[09/05/2023 12:08:00 AM : DEBUG : model_trai : ] : Epoch: 28 Training Error : 0.0000 , Training Loss : 0.0010\n",
      "[09/05/2023 12:08:00 AM : DEBUG : model_trai : ] : Epoch: 29 Training Error : 0.0000 , Training Loss : 0.0010\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 30 Training Error : 0.0000 , Training Loss : 0.0009\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 31 Training Error : 0.0000 , Training Loss : 0.0009\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 32 Training Error : 0.0000 , Training Loss : 0.0009\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 33 Training Error : 0.0000 , Training Loss : 0.0009\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 34 Training Error : 0.0000 , Training Loss : 0.0009\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 35 Training Error : 0.0000 , Training Loss : 0.0008\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 36 Training Error : 0.0000 , Training Loss : 0.0008\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 37 Training Error : 0.0000 , Training Loss : 0.0008\n",
      "[09/05/2023 12:08:01 AM : DEBUG : model_trai : ] : Epoch: 38 Training Error : 0.0000 , Training Loss : 0.0008\n",
      "[09/05/2023 12:08:02 AM : DEBUG : model_trai : ] : Epoch: 39 Training Error : 0.0000 , Training Loss : 0.0008\n",
      "[09/05/2023 12:08:02 AM : DEBUG : model_trai : ] : Epoch: 40 Training Error : 0.0000 , Training Loss : 0.0008\n",
      "[09/05/2023 12:08:02 AM : DEBUG : model_trai : ] : Epoch: 41 Training Error : 0.0000 , Training Loss : 0.0008\n",
      "[09/05/2023 12:08:02 AM : DEBUG : model_trai : ] : Epoch: 42 Training Error : 0.0000 , Training Loss : 0.0007\n",
      "[09/05/2023 12:08:02 AM : DEBUG : model_trai : ] : Epoch: 43 Training Error : 0.0000 , Training Loss : 0.0007\n",
      "[09/05/2023 12:08:02 AM : DEBUG : model_trai : ] : Epoch: 44 Training Error : 0.0000 , Training Loss : 0.0007\n",
      "[09/05/2023 12:08:02 AM : DEBUG : model_trai : ] : Epoch: 45 Training Error : 0.0000 , Training Loss : 0.0007\n",
      "[09/05/2023 12:08:02 AM : DEBUG : model_trai : ] : Epoch: 46 Training Error : 0.0000 , Training Loss : 0.0007\n",
      "[09/05/2023 12:08:03 AM : DEBUG : model_trai : ] : Epoch: 47 Training Error : 0.0000 , Training Loss : 0.0007\n",
      "[09/05/2023 12:08:03 AM : DEBUG : model_trai : ] : Epoch: 48 Training Error : 0.0000 , Training Loss : 0.0007\n",
      "[09/05/2023 12:08:03 AM : DEBUG : model_trai : ] : Epoch: 49 Training Error : 0.0000 , Training Loss : 0.0007\n",
      "[09/05/2023 12:08:03 AM : DEBUG : model_trai : ] : Average training loss : 0.003234871028758148\n",
      "[09/05/2023 12:08:03 AM : INFO  : passive_le : ] : --------------- End Model Training ------------\n",
      "tensor(17.4029)\n",
      "0.22150000000000003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger   = get_logger('../../../temp/logs/act_lbl_test.log',stdout_redirect=True,level=logging.DEBUG)\n",
    "\n",
    "set_seed(conf['random_seed'])\n",
    "\n",
    "dm = DataManager(conf,logger)\n",
    "len(dm.ds_std_train), len(dm.ds_std_val)\n",
    "\n",
    "\n",
    "pl = PassiveLearning(conf,dm,logger)\n",
    "\n",
    "out = pl.run()\n",
    "\n",
    "w = pl.cur_clf.get_weights()\n",
    "print(torch.norm(w))\n",
    "test_err = get_test_error(pl.cur_clf,dm.ds_std_test,conf['inference_conf'])\n",
    "print(test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11834545367956159\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_val_ds,cur_val_idcs=dm.get_current_validation_data()\n",
    "\n",
    "val_set_subset = cur_val_ds\n",
    "\n",
    "val_inf_out = pl.cur_clf.predict(val_set_subset,conf['inference_conf'])\n",
    "cal_out = compute_calibration(val_set_subset.Y.numpy(), val_inf_out['labels'].numpy(), val_inf_out['confidence'].numpy(), num_bins=10)\n",
    "print(cal_out['expected_calibration_error'])\n",
    "ax = plt.subplot(111)\n",
    "reliability_diagram_subplot(ax,cal_out)\n",
    "\n",
    "plt.figure() \n",
    "o = val_inf_out\n",
    "\n",
    "m = len(o['confidence'])\n",
    "S = np.zeros((m,4))\n",
    "S[:,0] = o['confidence']\n",
    "S[:,1] = o['labels'] \n",
    "S[:,2] = val_set_subset.Y\n",
    "S[:,3] = S[:,1]==S[:,2]\n",
    "\n",
    "S = S[(-S[:,0]).argsort()]\n",
    " \n",
    "bins = np.arange(0.1,1.1,0.05)\n",
    "labels = ['corrects','incorrects']\n",
    "plt.hist([S[S[:,3]==1,0],S[S[:,3]==0,0]],bins=bins,rwidth=0.5, histtype ='bar',label=labels)\n",
    "plt.legend()\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Confidence')\n",
    "plt.grid() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/05/2023 12:12:43 AM : INFO  : pytorch_cl : ] : {'model_name': 'temp_scaling'}\n",
      "[09/05/2023 12:12:43 AM : INFO  : pytorch_cl : ] : {'model_name': 'temp_scaling'}\n",
      "[09/05/2023 12:12:43 AM : INFO  : pytorch_cl : ] : {'model_name': 'temp_scaling'}\n",
      "[09/05/2023 12:12:43 AM : INFO  : pytorch_cl : ] : {'model_name': 'temp_scaling'}\n",
      "[09/05/2023 12:12:43 AM : INFO  : pytorch_cl : ] : {'model_name': 'temp_scaling'}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Training conf : {'optimizer': 'lbfgs', 'learning_rate': 1.0, 'batch_size': 64, 'shuffle': True, 'max_epochs': 20, 'normalize_weights': False, 'log_train_ece': True, 'log_train_ece_freq': 1, 'loss_function': 'std_cross_entropy', 'weight_decay': 0.0001, 'momentum': 0.9, 'optimizer_name': 'sgd', 'loss_tol': 1e-06, 'max_max_epochs': 10000, 'device': 'cpu', 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'use_lr_schedule': True, 'train_err_tol': 0.001, 'log_batch_loss_freq': 20, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'nesterov': False, 'num_train_pts': 1000}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Training conf : {'optimizer': 'lbfgs', 'learning_rate': 1.0, 'batch_size': 64, 'shuffle': True, 'max_epochs': 20, 'normalize_weights': False, 'log_train_ece': True, 'log_train_ece_freq': 1, 'loss_function': 'std_cross_entropy', 'weight_decay': 0.0001, 'momentum': 0.9, 'optimizer_name': 'sgd', 'loss_tol': 1e-06, 'max_max_epochs': 10000, 'device': 'cpu', 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'use_lr_schedule': True, 'train_err_tol': 0.001, 'log_batch_loss_freq': 20, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'nesterov': False, 'num_train_pts': 1000}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Training conf : {'optimizer': 'lbfgs', 'learning_rate': 1.0, 'batch_size': 64, 'shuffle': True, 'max_epochs': 20, 'normalize_weights': False, 'log_train_ece': True, 'log_train_ece_freq': 1, 'loss_function': 'std_cross_entropy', 'weight_decay': 0.0001, 'momentum': 0.9, 'optimizer_name': 'sgd', 'loss_tol': 1e-06, 'max_max_epochs': 10000, 'device': 'cpu', 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'use_lr_schedule': True, 'train_err_tol': 0.001, 'log_batch_loss_freq': 20, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'nesterov': False, 'num_train_pts': 1000}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Training conf : {'optimizer': 'lbfgs', 'learning_rate': 1.0, 'batch_size': 64, 'shuffle': True, 'max_epochs': 20, 'normalize_weights': False, 'log_train_ece': True, 'log_train_ece_freq': 1, 'loss_function': 'std_cross_entropy', 'weight_decay': 0.0001, 'momentum': 0.9, 'optimizer_name': 'sgd', 'loss_tol': 1e-06, 'max_max_epochs': 10000, 'device': 'cpu', 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'use_lr_schedule': True, 'train_err_tol': 0.001, 'log_batch_loss_freq': 20, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'nesterov': False, 'num_train_pts': 1000}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Training conf : {'optimizer': 'lbfgs', 'learning_rate': 1.0, 'batch_size': 64, 'shuffle': True, 'max_epochs': 20, 'normalize_weights': False, 'log_train_ece': True, 'log_train_ece_freq': 1, 'loss_function': 'std_cross_entropy', 'weight_decay': 0.0001, 'momentum': 0.9, 'optimizer_name': 'sgd', 'loss_tol': 1e-06, 'max_max_epochs': 10000, 'device': 'cpu', 'stopping_criterion': 'max_epochs', 'log_val_err': False, 'log_val_ece': False, 'use_lr_schedule': True, 'train_err_tol': 0.001, 'log_batch_loss_freq': 20, 'log_val_err_freq': 5, 'log_val_ece_freq': 5, 'verbose_logging': False, 'nesterov': False, 'num_train_pts': 1000}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using loss function : <class 'models.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using loss function : <class 'models.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using loss function : <class 'models.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using loss function : <class 'models.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using loss function : <class 'models.torch.losses.common_losses.StdCrossEntropyLoss'>\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Using stopping criterion max_epochs\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Train Epoch: 0 [0/1000 (0%)]\tLoss: 0.917136 \t result: {'loss': 0.9171356558799744}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Train Epoch: 0 [0/1000 (0%)]\tLoss: 0.917136 \t result: {'loss': 0.9171356558799744}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Train Epoch: 0 [0/1000 (0%)]\tLoss: 0.917136 \t result: {'loss': 0.9171356558799744}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Train Epoch: 0 [0/1000 (0%)]\tLoss: 0.917136 \t result: {'loss': 0.9171356558799744}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Train Epoch: 0 [0/1000 (0%)]\tLoss: 0.917136 \t result: {'loss': 0.9171356558799744}\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2010 , Training Loss : 0.0075\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2010 , Training Loss : 0.0075\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2010 , Training Loss : 0.0075\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2010 , Training Loss : 0.0075\n",
      "[09/05/2023 12:12:43 AM : DEBUG : model_trai : ] : Epoch: 0 Training Error : 0.2010 , Training Loss : 0.0075\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:0 Expected Calibration Error on Train Set : 0.11697940576076507\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:0 Expected Calibration Error on Train Set : 0.11697940576076507\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:0 Expected Calibration Error on Train Set : 0.11697940576076507\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:0 Expected Calibration Error on Train Set : 0.11697940576076507\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:0 Expected Calibration Error on Train Set : 0.11697940576076507\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 1 [0/1000 (0%)]\tLoss: 0.443592 \t result: {'loss': 0.4435921311378479}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 1 [0/1000 (0%)]\tLoss: 0.443592 \t result: {'loss': 0.4435921311378479}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 1 [0/1000 (0%)]\tLoss: 0.443592 \t result: {'loss': 0.4435921311378479}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 1 [0/1000 (0%)]\tLoss: 0.443592 \t result: {'loss': 0.4435921311378479}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 1 [0/1000 (0%)]\tLoss: 0.443592 \t result: {'loss': 0.4435921311378479}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2010 , Training Loss : 0.0074\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2010 , Training Loss : 0.0074\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2010 , Training Loss : 0.0074\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2010 , Training Loss : 0.0074\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 1 Training Error : 0.2010 , Training Loss : 0.0074\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:1 Expected Calibration Error on Train Set : 0.07668452948331833\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:1 Expected Calibration Error on Train Set : 0.07668452948331833\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:1 Expected Calibration Error on Train Set : 0.07668452948331833\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:1 Expected Calibration Error on Train Set : 0.07668452948331833\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:1 Expected Calibration Error on Train Set : 0.07668452948331833\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.488220 \t result: {'loss': 0.48821985721588135}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.488220 \t result: {'loss': 0.48821985721588135}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.488220 \t result: {'loss': 0.48821985721588135}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.488220 \t result: {'loss': 0.48821985721588135}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.488220 \t result: {'loss': 0.48821985721588135}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2010 , Training Loss : 0.0067\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2010 , Training Loss : 0.0067\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2010 , Training Loss : 0.0067\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2010 , Training Loss : 0.0067\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 2 Training Error : 0.2010 , Training Loss : 0.0067\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:2 Expected Calibration Error on Train Set : 0.022193007767200474\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:2 Expected Calibration Error on Train Set : 0.022193007767200474\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:2 Expected Calibration Error on Train Set : 0.022193007767200474\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:2 Expected Calibration Error on Train Set : 0.022193007767200474\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:2 Expected Calibration Error on Train Set : 0.022193007767200474\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.393119 \t result: {'loss': 0.39311909675598145}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.393119 \t result: {'loss': 0.39311909675598145}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.393119 \t result: {'loss': 0.39311909675598145}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.393119 \t result: {'loss': 0.39311909675598145}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.393119 \t result: {'loss': 0.39311909675598145}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 3 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:3 Expected Calibration Error on Train Set : 0.026573154568672205\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:3 Expected Calibration Error on Train Set : 0.026573154568672205\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:3 Expected Calibration Error on Train Set : 0.026573154568672205\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:3 Expected Calibration Error on Train Set : 0.026573154568672205\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch:3 Expected Calibration Error on Train Set : 0.026573154568672205\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.398490 \t result: {'loss': 0.39848950505256653}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.398490 \t result: {'loss': 0.39848950505256653}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.398490 \t result: {'loss': 0.39848950505256653}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.398490 \t result: {'loss': 0.39848950505256653}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.398490 \t result: {'loss': 0.39848950505256653}\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:44 AM : DEBUG : model_trai : ] : Epoch: 4 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:4 Expected Calibration Error on Train Set : 0.022675323069095598\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:4 Expected Calibration Error on Train Set : 0.022675323069095598\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:4 Expected Calibration Error on Train Set : 0.022675323069095598\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:4 Expected Calibration Error on Train Set : 0.022675323069095598\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:4 Expected Calibration Error on Train Set : 0.022675323069095598\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.380075 \t result: {'loss': 0.3800748586654663}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.380075 \t result: {'loss': 0.3800748586654663}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.380075 \t result: {'loss': 0.3800748586654663}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.380075 \t result: {'loss': 0.3800748586654663}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.380075 \t result: {'loss': 0.3800748586654663}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 5 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:5 Expected Calibration Error on Train Set : 0.0219488676190376\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:5 Expected Calibration Error on Train Set : 0.0219488676190376\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:5 Expected Calibration Error on Train Set : 0.0219488676190376\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:5 Expected Calibration Error on Train Set : 0.0219488676190376\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:5 Expected Calibration Error on Train Set : 0.0219488676190376\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.274502 \t result: {'loss': 0.2745019197463989}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.274502 \t result: {'loss': 0.2745019197463989}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.274502 \t result: {'loss': 0.2745019197463989}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.274502 \t result: {'loss': 0.2745019197463989}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.274502 \t result: {'loss': 0.2745019197463989}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 6 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:6 Expected Calibration Error on Train Set : 0.02101408016681672\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:6 Expected Calibration Error on Train Set : 0.02101408016681672\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:6 Expected Calibration Error on Train Set : 0.02101408016681672\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:6 Expected Calibration Error on Train Set : 0.02101408016681672\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:6 Expected Calibration Error on Train Set : 0.02101408016681672\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.439473 \t result: {'loss': 0.43947288393974304}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.439473 \t result: {'loss': 0.43947288393974304}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.439473 \t result: {'loss': 0.43947288393974304}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.439473 \t result: {'loss': 0.43947288393974304}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.439473 \t result: {'loss': 0.43947288393974304}\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch: 7 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:7 Expected Calibration Error on Train Set : 0.0210483969449997\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:7 Expected Calibration Error on Train Set : 0.0210483969449997\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:7 Expected Calibration Error on Train Set : 0.0210483969449997\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:7 Expected Calibration Error on Train Set : 0.0210483969449997\n",
      "[09/05/2023 12:12:45 AM : DEBUG : model_trai : ] : Epoch:7 Expected Calibration Error on Train Set : 0.0210483969449997\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.409426 \t result: {'loss': 0.40942585468292236}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.409426 \t result: {'loss': 0.40942585468292236}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.409426 \t result: {'loss': 0.40942585468292236}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.409426 \t result: {'loss': 0.40942585468292236}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.409426 \t result: {'loss': 0.40942585468292236}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 8 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:8 Expected Calibration Error on Train Set : 0.02296099805831911\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:8 Expected Calibration Error on Train Set : 0.02296099805831911\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:8 Expected Calibration Error on Train Set : 0.02296099805831911\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:8 Expected Calibration Error on Train Set : 0.02296099805831911\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:8 Expected Calibration Error on Train Set : 0.02296099805831911\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.477360 \t result: {'loss': 0.4773598611354828}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.477360 \t result: {'loss': 0.4773598611354828}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.477360 \t result: {'loss': 0.4773598611354828}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.477360 \t result: {'loss': 0.4773598611354828}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.477360 \t result: {'loss': 0.4773598611354828}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 9 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:9 Expected Calibration Error on Train Set : 0.02266318726539612\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:9 Expected Calibration Error on Train Set : 0.02266318726539612\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:9 Expected Calibration Error on Train Set : 0.02266318726539612\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:9 Expected Calibration Error on Train Set : 0.02266318726539612\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:9 Expected Calibration Error on Train Set : 0.02266318726539612\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.400166 \t result: {'loss': 0.4001659154891968}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.400166 \t result: {'loss': 0.4001659154891968}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.400166 \t result: {'loss': 0.4001659154891968}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.400166 \t result: {'loss': 0.4001659154891968}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.400166 \t result: {'loss': 0.4001659154891968}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 10 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:10 Expected Calibration Error on Train Set : 0.021943832397460908\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:10 Expected Calibration Error on Train Set : 0.021943832397460908\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:10 Expected Calibration Error on Train Set : 0.021943832397460908\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:10 Expected Calibration Error on Train Set : 0.021943832397460908\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch:10 Expected Calibration Error on Train Set : 0.021943832397460908\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 11 [0/1000 (0%)]\tLoss: 0.443735 \t result: {'loss': 0.4437348544597626}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 11 [0/1000 (0%)]\tLoss: 0.443735 \t result: {'loss': 0.4437348544597626}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 11 [0/1000 (0%)]\tLoss: 0.443735 \t result: {'loss': 0.4437348544597626}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 11 [0/1000 (0%)]\tLoss: 0.443735 \t result: {'loss': 0.4437348544597626}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Train Epoch: 11 [0/1000 (0%)]\tLoss: 0.443735 \t result: {'loss': 0.4437348544597626}\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:46 AM : DEBUG : model_trai : ] : Epoch: 11 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:11 Expected Calibration Error on Train Set : 0.02659809136390685\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:11 Expected Calibration Error on Train Set : 0.02659809136390685\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:11 Expected Calibration Error on Train Set : 0.02659809136390685\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:11 Expected Calibration Error on Train Set : 0.02659809136390685\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:11 Expected Calibration Error on Train Set : 0.02659809136390685\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 12 [0/1000 (0%)]\tLoss: 0.407471 \t result: {'loss': 0.4074714183807373}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 12 [0/1000 (0%)]\tLoss: 0.407471 \t result: {'loss': 0.4074714183807373}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 12 [0/1000 (0%)]\tLoss: 0.407471 \t result: {'loss': 0.4074714183807373}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 12 [0/1000 (0%)]\tLoss: 0.407471 \t result: {'loss': 0.4074714183807373}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 12 [0/1000 (0%)]\tLoss: 0.407471 \t result: {'loss': 0.4074714183807373}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 12 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:12 Expected Calibration Error on Train Set : 0.024152698397636407\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:12 Expected Calibration Error on Train Set : 0.024152698397636407\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:12 Expected Calibration Error on Train Set : 0.024152698397636407\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:12 Expected Calibration Error on Train Set : 0.024152698397636407\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:12 Expected Calibration Error on Train Set : 0.024152698397636407\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 13 [0/1000 (0%)]\tLoss: 0.374257 \t result: {'loss': 0.3742571771144867}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 13 [0/1000 (0%)]\tLoss: 0.374257 \t result: {'loss': 0.3742571771144867}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 13 [0/1000 (0%)]\tLoss: 0.374257 \t result: {'loss': 0.3742571771144867}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 13 [0/1000 (0%)]\tLoss: 0.374257 \t result: {'loss': 0.3742571771144867}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 13 [0/1000 (0%)]\tLoss: 0.374257 \t result: {'loss': 0.3742571771144867}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 13 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:13 Expected Calibration Error on Train Set : 0.023738286435604074\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:13 Expected Calibration Error on Train Set : 0.023738286435604074\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:13 Expected Calibration Error on Train Set : 0.023738286435604074\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:13 Expected Calibration Error on Train Set : 0.023738286435604074\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:13 Expected Calibration Error on Train Set : 0.023738286435604074\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 14 [0/1000 (0%)]\tLoss: 0.470811 \t result: {'loss': 0.47081127762794495}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 14 [0/1000 (0%)]\tLoss: 0.470811 \t result: {'loss': 0.47081127762794495}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 14 [0/1000 (0%)]\tLoss: 0.470811 \t result: {'loss': 0.47081127762794495}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 14 [0/1000 (0%)]\tLoss: 0.470811 \t result: {'loss': 0.47081127762794495}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 14 [0/1000 (0%)]\tLoss: 0.470811 \t result: {'loss': 0.47081127762794495}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch: 14 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:14 Expected Calibration Error on Train Set : 0.02427446150779725\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:14 Expected Calibration Error on Train Set : 0.02427446150779725\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:14 Expected Calibration Error on Train Set : 0.02427446150779725\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:14 Expected Calibration Error on Train Set : 0.02427446150779725\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Epoch:14 Expected Calibration Error on Train Set : 0.02427446150779725\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 15 [0/1000 (0%)]\tLoss: 0.379796 \t result: {'loss': 0.37979623675346375}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 15 [0/1000 (0%)]\tLoss: 0.379796 \t result: {'loss': 0.37979623675346375}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 15 [0/1000 (0%)]\tLoss: 0.379796 \t result: {'loss': 0.37979623675346375}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 15 [0/1000 (0%)]\tLoss: 0.379796 \t result: {'loss': 0.37979623675346375}\n",
      "[09/05/2023 12:12:47 AM : DEBUG : model_trai : ] : Train Epoch: 15 [0/1000 (0%)]\tLoss: 0.379796 \t result: {'loss': 0.37979623675346375}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 15 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:15 Expected Calibration Error on Train Set : 0.021034953355789178\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:15 Expected Calibration Error on Train Set : 0.021034953355789178\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:15 Expected Calibration Error on Train Set : 0.021034953355789178\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:15 Expected Calibration Error on Train Set : 0.021034953355789178\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:15 Expected Calibration Error on Train Set : 0.021034953355789178\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 16 [0/1000 (0%)]\tLoss: 0.470693 \t result: {'loss': 0.4706926643848419}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 16 [0/1000 (0%)]\tLoss: 0.470693 \t result: {'loss': 0.4706926643848419}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 16 [0/1000 (0%)]\tLoss: 0.470693 \t result: {'loss': 0.4706926643848419}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 16 [0/1000 (0%)]\tLoss: 0.470693 \t result: {'loss': 0.4706926643848419}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 16 [0/1000 (0%)]\tLoss: 0.470693 \t result: {'loss': 0.4706926643848419}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 16 Training Error : 0.2010 , Training Loss : 0.0066\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:16 Expected Calibration Error on Train Set : 0.023118181109428412\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:16 Expected Calibration Error on Train Set : 0.023118181109428412\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:16 Expected Calibration Error on Train Set : 0.023118181109428412\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:16 Expected Calibration Error on Train Set : 0.023118181109428412\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:16 Expected Calibration Error on Train Set : 0.023118181109428412\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 17 [0/1000 (0%)]\tLoss: 0.451850 \t result: {'loss': 0.4518497586250305}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 17 [0/1000 (0%)]\tLoss: 0.451850 \t result: {'loss': 0.4518497586250305}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 17 [0/1000 (0%)]\tLoss: 0.451850 \t result: {'loss': 0.4518497586250305}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 17 [0/1000 (0%)]\tLoss: 0.451850 \t result: {'loss': 0.4518497586250305}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 17 [0/1000 (0%)]\tLoss: 0.451850 \t result: {'loss': 0.4518497586250305}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 17 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:17 Expected Calibration Error on Train Set : 0.023122327506542212\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:17 Expected Calibration Error on Train Set : 0.023122327506542212\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:17 Expected Calibration Error on Train Set : 0.023122327506542212\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:17 Expected Calibration Error on Train Set : 0.023122327506542212\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch:17 Expected Calibration Error on Train Set : 0.023122327506542212\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 18 [0/1000 (0%)]\tLoss: 0.488052 \t result: {'loss': 0.4880523979663849}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 18 [0/1000 (0%)]\tLoss: 0.488052 \t result: {'loss': 0.4880523979663849}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 18 [0/1000 (0%)]\tLoss: 0.488052 \t result: {'loss': 0.4880523979663849}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 18 [0/1000 (0%)]\tLoss: 0.488052 \t result: {'loss': 0.4880523979663849}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Train Epoch: 18 [0/1000 (0%)]\tLoss: 0.488052 \t result: {'loss': 0.4880523979663849}\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:48 AM : DEBUG : model_trai : ] : Epoch: 18 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:18 Expected Calibration Error on Train Set : 0.023745000660419485\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:18 Expected Calibration Error on Train Set : 0.023745000660419485\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:18 Expected Calibration Error on Train Set : 0.023745000660419485\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:18 Expected Calibration Error on Train Set : 0.023745000660419485\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:18 Expected Calibration Error on Train Set : 0.023745000660419485\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.565363 \t result: {'loss': 0.5653630495071411}\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.565363 \t result: {'loss': 0.5653630495071411}\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.565363 \t result: {'loss': 0.5653630495071411}\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.565363 \t result: {'loss': 0.5653630495071411}\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.565363 \t result: {'loss': 0.5653630495071411}\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch: 19 Training Error : 0.2010 , Training Loss : 0.0065\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:19 Expected Calibration Error on Train Set : 0.023677184045314784\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:19 Expected Calibration Error on Train Set : 0.023677184045314784\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:19 Expected Calibration Error on Train Set : 0.023677184045314784\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:19 Expected Calibration Error on Train Set : 0.023677184045314784\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Epoch:19 Expected Calibration Error on Train Set : 0.023677184045314784\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Average training loss : 0.006320440680498168\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Average training loss : 0.006320440680498168\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Average training loss : 0.006320440680498168\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Average training loss : 0.006320440680498168\n",
      "[09/05/2023 12:12:49 AM : DEBUG : model_trai : ] : Average training loss : 0.006320440680498168\n"
     ]
    }
   ],
   "source": [
    "from calibration.calibrators import * \n",
    "\n",
    "conf['calibrate_clf'] = True \n",
    "calib_train_conf = {} \n",
    "\n",
    "calib_train_conf['optimizer']='lbfgs'\n",
    "calib_train_conf['learning_rate']= 1.0\n",
    "\n",
    "calib_train_conf['batch_size']= 64 #len(train_set)\n",
    "calib_train_conf['shuffle']= True\n",
    "calib_train_conf['max_epochs'] = 20\n",
    "calib_train_conf['normalize_weights']=False\n",
    "\n",
    "calib_train_conf['log_train_ece'] = True \n",
    "calib_train_conf['log_train_ece_freq']= 1\n",
    "calib_conf = {'name':'temperature_scaling'}\n",
    "\n",
    "calib_conf['training_conf'] = calib_train_conf\n",
    "\n",
    "conf['calibration_conf'] = calib_conf \n",
    "\n",
    "val_set_subset = cur_val_ds\n",
    "\n",
    "inf_out = pl.cur_clf.predict(val_set_subset,conf['inference_conf'])\n",
    "\n",
    "\n",
    "logger = get_logger('../../../temp/logs/pl2.log','PL2',level=logging.DEBUG)\n",
    "calib= TemperatureScalingCalibrator(clf=pl.cur_clf,calib_conf=calib_conf,logger=logger)\n",
    "calib.fit(val_set_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.disabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023677184045314784\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_set_subset = cur_val_ds\n",
    "val_inf_out = calib.predict(val_set_subset,conf['inference_conf'])\n",
    "cal_out = compute_calibration(val_set_subset.Y.numpy(), val_inf_out['labels'].numpy(), val_inf_out['confidence'].numpy(), num_bins=10)\n",
    "print(cal_out['expected_calibration_error'])\n",
    "ax = plt.subplot(111)\n",
    "reliability_diagram_subplot(ax,cal_out)\n",
    "\n",
    "plt.figure() \n",
    "o = val_inf_out\n",
    "\n",
    "m = len(o['confidence'])\n",
    "S = np.zeros((m,4))\n",
    "S[:,0] = o['confidence']\n",
    "S[:,1] = o['labels'] \n",
    "S[:,2] = val_set_subset.Y\n",
    "S[:,3] = S[:,1]==S[:,2]\n",
    "\n",
    "S = S[(-S[:,0]).argsort()]\n",
    " \n",
    "bins = np.arange(0.1,1.1,0.05)\n",
    "labels = ['corrects','incorrects']\n",
    "plt.hist([S[S[:,3]==1,0],S[S[:,3]==0,0]],bins=bins,rwidth=0.5, histtype ='bar',label=labels)\n",
    "plt.legend()\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Confidence')\n",
    "plt.grid() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "act-learn-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
